# peer-up

Access your home server from anywhere. Share services with friends. No cloud, no account, no SaaS dependency.

**peer-up** connects your devices through firewalls and CGNAT using encrypted P2P tunnels with SSH-style authentication. One binary, zero configuration servers, works behind any NAT.

## News

| Date | What's New |
|------|-----------|
| 2026-02-18 | **Private DHT** — Peer discovery now runs on `/peerup/kad/1.0.0`, fully isolated from the public IPFS network |
| 2026-02-17 | **Daemon mode** — Background service with Unix socket API, cookie auth, and 14 REST endpoints |
| 2026-02-17 | **Network tools** — P2P ping, traceroute, and name resolution (standalone or via daemon) |
| 2026-02-16 | **Service management** — `peerup service add/remove/enable/disable` from the CLI |
| 2026-02-16 | **Config self-healing** — Archive, rollback, and commit-confirmed pattern for safe remote changes |
| 2026-02-16 | **AutoNAT v2** — Per-address reachability detection with nonce verification |
| 2026-02-16 | **Headless pairing** — `--non-interactive` flag for scripted invite/join workflows |
| 2026-02-15 | **Structured logging** — `log/slog` throughout, sentinel errors, build version embedding |

## What Can I Do With peer-up?

| Use Case | Command |
|----------|---------|
| SSH to your home machine behind CGNAT | `peerup proxy home ssh 2222` → `ssh -p 2222 localhost` |
| Remote desktop through NAT | `peerup proxy home xrdp 13389` → connect to `localhost:13389` |
| Share Jellyfin with a friend | `peerup invite` on your side, `peerup join <code>` on theirs |
| AI inference on a friend's GPU | `peerup proxy friend ollama 11434` → `curl localhost:11434` |
| Any TCP service, zero port forwarding | `peerup proxy <peer> <service> <local-port>` |
| Check connectivity | `peerup ping home` or `peerup traceroute home` |

peer-up works with **two machines and zero network effect** — useful from day one.

## Quick Start

### Path A: Joining someone's network

If someone shared an invite code with you:

```bash
# Install (or build from source: go build -o peerup ./cmd/peerup)
peerup join <invite-code> --name laptop
```

That's it. You're connected and mutually authorized.

### Path B: Setting up your own network

**1. Set up both machines:**
```bash
go build -o peerup ./cmd/peerup
peerup init
```

**2. Pair them (on the first machine):**
```bash
peerup invite --name home
# Shows invite code + QR code, waits for the other side...
```

**3. Join (on the second machine):**
```bash
peerup join <invite-code> --name laptop
```

**4. Use it:**
```bash
# On the server — start the daemon with services exposed
peerup daemon

# On the client — connect to a service
peerup proxy home ssh 2222
ssh -p 2222 user@localhost
```

> **Relay server**: Both machines connect through a relay for NAT traversal. See [relay-server/README.md](relay-server/README.md) for deploying your own. Run `peerup relay serve` to start a relay. A shared relay is used by default during development.

## The Problem

Your devices are behind firewalls and NAT that block inbound connections. This affects:

- **Satellite ISPs** with Carrier-Grade NAT (CGNAT)
- **Mobile networks** (4G/5G) — almost universally behind CGNAT
- **Many broadband providers** worldwide applying CGNAT to conserve IPv4 addresses
- **University and corporate networks** with strict firewalls
- **Double-NAT setups** — router behind router

Traditional solutions require either port forwarding (impossible with CGNAT), a VPN service (another dependency), or a cloud intermediary (defeats self-hosting). peer-up solves this with a lightweight relay that both sides connect to **outbound**, then upgrades to a direct connection when possible.

## Features

| Feature | Description |
|---------|-------------|
| **NAT Traversal** | Circuit relay v2 + DCUtR hole-punching. Works behind CGNAT, symmetric NAT, double-NAT |
| **SSH-Style Auth** | `authorized_keys` peer allowlist — only explicitly trusted peers can connect |
| **60-Second Pairing** | `peerup invite` + `peerup join` — exchanges keys, adds auth, maps names automatically |
| **TCP Service Proxy** | Forward any TCP port through P2P tunnels (SSH, XRDP, HTTP, databases, AI inference) |
| **Daemon Mode** | Background service with Unix socket API, cookie auth, hot-reload of auth keys |
| **Config Self-Healing** | Last-known-good archive, rollback, and commit-confirmed pattern for safe remote changes |
| **Private DHT** | Kademlia peer discovery on `/peerup/kad/1.0.0` — isolated from public networks |
| **Friendly Names** | Map names to peer IDs in config — `home`, `laptop`, `gpu-server` instead of raw peer IDs |
| **Reusable Library** | `pkg/p2pnet` — import into your own Go projects for P2P networking |
| **Single Binary** | One `peerup` binary with 15 subcommands. No runtime dependencies |
| **Cross-Platform** | Go cross-compiles to Linux, macOS, Windows, ARM, and more |
| **systemd + launchd** | Service files included for both Linux and macOS |

## How It Works

```
┌──────────┐         ┌──────────────┐         ┌──────────────┐
│  Client   │───────▶│ Relay Server │◀────────│    Server    │
│  (Phone)  │ outbound    (VPS)   outbound   │  (Linux/Mac) │
└──────────┘         └──────────────┘         └──────────────┘
                           │
                     Both connect OUTBOUND
                     Relay bridges the connection
                     DCUtR upgrades to direct P2P
```

1. **Server** runs `peerup daemon` behind CGNAT — connects outbound to a relay and reserves a slot
2. **Client** runs `peerup proxy` — connects outbound to the same relay and reaches the server through a circuit address
3. **DCUtR** (Direct Connection Upgrade through Relay) attempts hole-punching. If successful, traffic flows directly without the relay

Peer discovery uses a **private Kademlia DHT** — the relay server acts as bootstrap peer. Authentication is enforced at both the connection level (ConnectionGater) and the protocol level.

For the full architecture: [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md)

## Commands

### Daemon

| Command | Description |
|---------|-------------|
| `peerup daemon` | Start the daemon (P2P host + Unix socket control API) |
| `peerup daemon status [--json]` | Query running daemon status |
| `peerup daemon stop` | Graceful shutdown |
| `peerup daemon ping <target> [-c N] [--json]` | Ping a peer via daemon |
| `peerup daemon services [--json]` | List exposed services via daemon |
| `peerup daemon peers [--all] [--json]` | List connected peers (peerup-only by default) |
| `peerup daemon connect --peer <p> --service <s> --listen <addr>` | Create a TCP proxy via daemon |
| `peerup daemon disconnect <id>` | Tear down a proxy |

### Network Tools (standalone, no daemon required)

| Command | Description |
|---------|-------------|
| `peerup ping <target> [-c N] [--interval 1s] [--json]` | P2P ping with stats |
| `peerup traceroute <target> [--json]` | P2P traceroute through relay hops |
| `peerup resolve <name> [--json]` | Resolve a name to peer ID and addresses |
| `peerup proxy <target> <service> <local-port>` | Forward a local TCP port to a remote service |

### Identity & Access

| Command | Description |
|---------|-------------|
| `peerup whoami` | Show your peer ID |
| `peerup auth add <peer-id> [--comment "..."]` | Authorize a peer |
| `peerup auth list` | List authorized peers |
| `peerup auth remove <peer-id>` | Revoke a peer |
| `peerup auth validate` | Validate authorized_keys format |

### Configuration & Setup

| Command | Description |
|---------|-------------|
| `peerup init` | Interactive setup wizard (config, keys, authorized_keys) |
| `peerup config validate` | Validate config file |
| `peerup config show` | Show resolved configuration |
| `peerup config rollback` | Restore last-known-good config |
| `peerup config apply <file> [--confirm-timeout 5m]` | Apply config with auto-revert safety net |
| `peerup config confirm` | Confirm applied config (cancels auto-revert) |
| `peerup relay add/list/remove` | Manage relay server addresses |
| `peerup service add/remove/enable/disable/list` | Manage exposed services |

### Pairing

| Command | Description |
|---------|-------------|
| `peerup invite [--name "home"] [--non-interactive]` | Generate invite code + QR, wait for join |
| `peerup join <code> [--name "laptop"] [--non-interactive]` | Accept invite, auto-configure both sides |
| `peerup status` | Show local config, identity, authorized peers, services |
| `peerup version` | Show version, commit, build date, Go version |

The `<target>` in network commands accepts either a peer ID or a name from the `names:` section of your config. All commands support `--config <path>`.

## Daemon Mode

The daemon runs `peerup daemon` as a long-lived background process. It starts the full P2P host, exposes configured services, and opens a Unix socket API for management.

**Key features:**
- Unix socket at `~/.config/peerup/.daemon.sock` (no TCP exposure)
- Cookie-based auth (`~/.config/peerup/.daemon-cookie`) — 32-byte random token, rotated per restart
- Hot-reload of authorized_keys via `daemon` auth endpoints
- 14 REST endpoints for status, peers, services, auth, proxies, ping, traceroute, resolve

**Example:**
```bash
# Start the daemon
peerup daemon

# In another terminal — query status
peerup daemon status

# Create a proxy through the daemon
peerup daemon connect --peer home --service ssh --listen localhost:2222
```

For the full API reference: [docs/DAEMON-API.md](docs/DAEMON-API.md)

## Configuration

### Config Search Order

1. `--config <path>` flag (explicit)
2. `./peerup.yaml` (current directory)
3. `~/.config/peerup/config.yaml` (standard location, created by `peerup init`)
4. `/etc/peerup/config.yaml` (system-wide)

### Essential Config

```yaml
identity:
  key_file: "identity.key"

network:
  listen_addresses:
    - "/ip4/0.0.0.0/tcp/0"
    - "/ip4/0.0.0.0/udp/0/quic-v1"
  force_private_reachability: false  # true for servers behind CGNAT

relay:
  addresses:
    - "/ip4/YOUR_VPS_IP/tcp/7777/p2p/YOUR_RELAY_PEER_ID"

security:
  authorized_keys_file: "authorized_keys"
  enable_connection_gating: true

# services:       # Uncomment to expose services (server only)
#   ssh:
#     enabled: true
#     local_address: "localhost:22"

names: {}         # Map friendly names to peer IDs
#  home: "12D3KooW..."
```

Full sample configs: [configs/](configs/)

## Running as a Service

### Linux (systemd)

A service file is provided at [deploy/peerup-daemon.service](deploy/peerup-daemon.service):

```bash
sudo cp deploy/peerup-daemon.service /etc/systemd/system/peerup.service
# Edit ExecStart path and --config as needed
sudo systemctl daemon-reload
sudo systemctl enable --now peerup
```

Both `peerup daemon` and `peerup relay serve` send `sd_notify` signals (`READY=1`, `WATCHDOG=1`, `STOPPING=1`).

### macOS (launchd)

A plist is provided at [deploy/com.peerup.daemon.plist](deploy/com.peerup.daemon.plist).

### Relay Server

See [relay-server/README.md](relay-server/README.md) for the full VPS deployment guide (user creation, SSH hardening, firewall, systemd, health checks).

## Building

```bash
# Build peerup
go build -o peerup ./cmd/peerup

# Build with version info
go build -ldflags "-X main.version=0.1.0 \
  -X main.commit=$(git rev-parse --short HEAD) \
  -X main.buildDate=$(date -u +%Y-%m-%dT%H:%M:%SZ)" \
  -o peerup ./cmd/peerup

# Cross-compile for Linux
GOOS=linux GOARCH=amd64 go build -o peerup ./cmd/peerup

# Run tests
go test -race -count=1 ./...
```

## Library (`pkg/p2pnet`)

The `pkg/p2pnet` package is an importable Go library for building P2P applications:

```go
import "github.com/satindergrewal/peer-up/pkg/p2pnet"

// Create a P2P network
net, _ := p2pnet.New(&p2pnet.Config{
    KeyFile:     "myapp.key",
    EnableRelay: true,
    RelayAddrs:  []string{"/ip4/.../tcp/7777/p2p/..."},
})

// Expose a local service
net.ExposeService("api", "localhost:8080")

// Connect to a peer's service
conn, _ := net.ConnectToService(peerID, "api")

// Name resolution
net.LoadNames(map[string]string{"home": "12D3KooW..."})
peerID, _ := net.ResolveName("home")
```

## Project Structure

```
cmd/
├── peerup/                    # Single binary with subcommands
│   ├── main.go                # Command dispatch (15 subcommands)
│   ├── cmd_daemon.go          # Daemon mode (start, stop, status, ping, peers, ...)
│   ├── cmd_proxy.go           # TCP proxy client
│   ├── cmd_ping.go            # Standalone P2P ping
│   ├── cmd_traceroute.go      # P2P traceroute
│   ├── cmd_resolve.go         # Name resolution
│   ├── cmd_init.go            # Interactive setup wizard
│   ├── cmd_invite.go          # Generate invite code + QR + P2P handshake
│   ├── cmd_join.go            # Accept invite, auto-configure
│   ├── cmd_auth.go            # Auth add/list/remove/validate
│   ├── cmd_relay.go           # Relay add/list/remove (client config)
│   ├── cmd_relay_serve.go     # Relay server: serve/authorize/info/config
│   ├── cmd_config.go          # Config validate/show/rollback/apply/confirm
│   ├── cmd_service.go         # Service add/remove/enable/disable/list
│   ├── cmd_status.go          # Local status display
│   ├── cmd_whoami.go          # Show peer ID
│   ├── serve_common.go        # Shared P2P runtime (used by daemon + standalone tools)
│   ├── config_template.go     # Config YAML template
│   ├── flag_helpers.go        # CLI flag reordering for natural usage
│   └── relay_input.go         # Flexible relay address parsing
pkg/p2pnet/                    # Importable P2P networking library
├── network.go                 # Core: host setup, relay, DHT, name resolution
├── service.go                 # Service registry
├── proxy.go                   # Bidirectional TCP↔Stream proxy with half-close
├── naming.go                  # Local name resolution (name → peer ID)
├── identity.go                # Identity helpers
├── ping.go                    # PingPeer() with streaming results
├── traceroute.go              # P2P traceroute
└── errors.go                  # Sentinel errors
internal/
├── config/                    # YAML configuration + self-healing
│   ├── config.go              # Config structs
│   ├── loader.go              # Auto-discovery, path resolution, validation
│   ├── archive.go             # Last-known-good archive/rollback
│   ├── confirm.go             # Commit-confirmed pattern
│   └── errors.go
├── auth/                      # Connection gating + authorized_keys
│   ├── gater.go               # ConnectionGater (blocks unauthorized at network level)
│   ├── authorized_keys.go     # File parser
│   ├── manage.go              # AddPeer/RemovePeer/ListPeers
│   └── errors.go
├── daemon/                    # Daemon API server + client library
│   ├── server.go              # Unix socket HTTP server with cookie auth
│   ├── handlers.go            # 14 REST endpoint handlers
│   ├── client.go              # Go client (auto-reads cookie, Unix transport)
│   ├── types.go               # Request/response types
│   └── errors.go
├── identity/                  # Ed25519 identity management
├── invite/                    # Invite code encoding (binary → base32 + dash groups)
├── validate/                  # Input validation (service names, DNS-label format)
├── watchdog/                  # Health monitoring + systemd sd_notify (pure Go)
├── qr/                        # QR code generation (zero dependencies)
└── termcolor/                 # Terminal color output
relay-server/                  # Deployment artifacts
├── setup.sh                   # Full VPS setup (build, permissions, systemd, health)
├── relay-server.service       # systemd unit file
└── README.md                  # VPS deployment guide
deploy/                        # Client service files
├── peerup-daemon.service      # systemd unit for peerup daemon
└── com.peerup.daemon.plist    # launchd plist for macOS
configs/                       # Sample configuration files
├── peerup.sample.yaml
├── relay-server.sample.yaml
└── authorized_keys.sample
docs/                          # Documentation
├── ARCHITECTURE.md            # Full architecture deep dive
├── DAEMON-API.md              # Daemon REST API reference
├── FAQ.md                     # Frequently asked questions
├── NETWORK-TOOLS.md           # Ping, traceroute, resolve guide
├── ROADMAP.md                 # Multi-phase implementation plan
├── TESTING.md                 # Test strategy and coverage
└── ENGINEERING-JOURNAL.md     # Architecture decision records (ADRs)
```

## Security

**Two layers of defense:**

1. **ConnectionGater** (network level) — Blocks unauthorized peers during the connection handshake, before any data is exchanged
2. **Protocol handler** (application level) — Secondary authorization check before processing requests

**Fail-safe defaults:**
- Connection gating enabled + no authorized_keys file → **refuses to start**
- Empty authorized_keys → **warns loudly** (allows for initial setup)
- All outbound connections allowed (required for DHT and relay)
- All unauthorized inbound connections blocked

**File permissions:**
```
chmod 600 *.key              # Private keys: owner read/write only
chmod 600 authorized_keys    # Peer allowlist: owner read/write only
chmod 644 *.yaml             # Configs: readable
```

For security details, relay hardening, and threat model: [docs/FAQ.md](docs/FAQ.md)

## Troubleshooting

| Issue | Solution |
|-------|----------|
| `no config file found` | Run `peerup init` or use `--config <path>` |
| `Cannot resolve target` | Add name mapping to `names:` in config |
| `DENIED inbound connection` | Add peer ID to `authorized_keys`, restart daemon |
| `Invalid invite code` | Paste the full code as one argument (quote if spaces) |
| `Failed to connect to inviter` | Ensure `peerup invite` is still running |
| No `/p2p-circuit` addresses | Check `force_private_reachability: true` and relay address |
| `protocols not supported` | Relay server not running or unreachable |
| Bad config edit broke startup | `peerup config rollback` restores last-known-good |
| Remote config change went wrong | `peerup config apply new.yaml --confirm-timeout 5m`, then `config confirm` |
| `failed to sufficiently increase receive buffer size` | QUIC works but suboptimal — see UDP buffer tuning below |
| Daemon won't start (socket exists) | Stale socket from crash — daemon auto-detects and cleans up |

### UDP Buffer Tuning (QUIC)

QUIC works with default buffers but performs better with increased limits:

```bash
# Linux (persistent)
echo "net.core.rmem_max=7500000" | sudo tee -a /etc/sysctl.d/99-quic.conf
echo "net.core.wmem_max=7500000" | sudo tee -a /etc/sysctl.d/99-quic.conf
sudo sysctl --system
```

## Engineering Philosophy

This is not a weekend hobby project. peer-up is built as critical infrastructure — the kind where failure has real consequences for real people: financial, psychological, and potentially physical.

Think of it like a bubble in outer space. If it breaks, the people inside don't get a second chance. That standard guides everything here — from code quality to deployment to security decisions.

## Development

### AI-Assisted Development

peer-up is developed with significant AI assistance (Claude). All AI-generated code is reviewed, tested, and committed by a human maintainer. The architecture, vision, and engineering decisions are human-directed.

### No Cryptocurrency / No Token

peer-up is a networking tool. It has no token, no coin, no blockchain dependency, and no plans to add one. If someone tells you otherwise, they're not affiliated with this project.

### Contributing

Issues and PRs are welcome.

**Testing checklist:**
- [ ] `go build ./...` succeeds
- [ ] `go vet ./...` passes
- [ ] `go test -race -count=1 ./...` passes
- [ ] Unauthorized peer is denied, authorized peer connects
- [ ] Service proxy works end-to-end

## Documentation

| Document | Description |
|----------|-------------|
| [ARCHITECTURE.md](docs/ARCHITECTURE.md) | Full architecture: relay circuit, DHT, proxy, auth system |
| [DAEMON-API.md](docs/DAEMON-API.md) | Daemon REST API reference (14 endpoints) |
| [FAQ.md](docs/FAQ.md) | Security FAQ, relay hardening, troubleshooting |
| [NETWORK-TOOLS.md](docs/NETWORK-TOOLS.md) | Ping, traceroute, resolve usage guide |
| [ROADMAP.md](docs/ROADMAP.md) | Multi-phase implementation plan |
| [TESTING.md](docs/TESTING.md) | Test strategy, coverage, integration tests |
| [ENGINEERING-JOURNAL.md](docs/ENGINEERING-JOURNAL.md) | Architecture decision records: why every design choice was made |

## Dependencies

- [go-libp2p](https://github.com/libp2p/go-libp2p) v0.47.0
- [go-libp2p-kad-dht](https://github.com/libp2p/go-libp2p-kad-dht) v0.28.1
- [go-multiaddr](https://github.com/multiformats/go-multiaddr)
- [gopkg.in/yaml.v3](https://gopkg.in/yaml.v3) v3.0.1

## License

MIT


---

# Network Diagnostic Tools

peer-up provides P2P network diagnostic commands that mirror familiar system utilities. These work both standalone (create a temporary P2P host) and through the daemon API (use the existing host for faster operation).

## Table of Contents

- [ping](#ping)
- [traceroute](#traceroute)
- [resolve](#resolve)
- [Standalone vs Daemon](#standalone-vs-daemon)

---

## ping

P2P `ping` — measures round-trip time and connection path to a peer.

### Usage

```bash
# Standalone (creates temp host, pings, exits)
peerup ping <peer> [-c N] [--interval 1s] [--json] [--config path]

# Via daemon (reuses existing host — faster)
peerup daemon ping <peer> [-c N] [--interval 1s] [--json]
```

### Behavior

| Mode | Behavior |
|------|----------|
| `-c N` (N > 0) | Send N pings, print per-ping line, summary at end |
| No `-c` flag | Continuous pinging until Ctrl+C, summary on exit |
| `--interval 1s` | Time between pings (default `1s`) |
| `--json` | JSON output (one line per ping result + final stats) |

### Output

**Plain text (default)**:

```
PING home-server (12D3KooWDRDM...):
seq=1 rtt=45.2ms path=[RELAYED]
seq=2 rtt=42.1ms path=[DIRECT]
seq=3 rtt=43.0ms path=[DIRECT]
^C
--- home-server ping statistics ---
3 sent, 3 received, 0% loss, rtt min/avg/max = 42.1/43.4/45.2 ms
```

**JSON (`--json`)**:

```json
{"seq":1,"peer_id":"12D3KooWDRDM...","rtt_ms":45.2,"path":"RELAYED"}
{"seq":2,"peer_id":"12D3KooWDRDM...","rtt_ms":42.1,"path":"DIRECT"}
{"seq":3,"peer_id":"12D3KooWDRDM...","rtt_ms":43.0,"path":"DIRECT"}
{"sent":3,"received":3,"lost":0,"loss_pct":0.0,"min_ms":42.1,"avg_ms":43.4,"max_ms":45.2}
```

### Connection Path

Each ping shows whether the connection went through the relay or directly:

| Path | Meaning |
|------|---------|
| `[DIRECT]` | Peer-to-peer (hole-punched or same LAN) |
| `[RELAYED]` | Via circuit relay server |

Direct connections have lower latency. If pings start as `RELAYED` and switch to `DIRECT`, DCUtR hole-punching succeeded.

### Ping Allow/Deny

Peers can disable ping responses in their config:

```yaml
protocols:
  ping:
    enabled: false   # silently drop ping requests
```

When disabled, the peer doesn't register the ping-pong stream handler. Pings will time out — same behavior as a firewall dropping ICMP.

### How It Works

1. Open a libp2p stream to the target peer using the ping-pong protocol (`/peerup/ping/1.0.0`)
2. Send `"ping\n"` on the stream
3. Wait for `"pong\n"` response
4. Measure round-trip time
5. Check connection type (direct vs relayed) from stream metadata

---

## traceroute

P2P `traceroute` — shows the network path to a peer with per-hop latency.

### Usage

```bash
# Standalone
peerup traceroute <peer> [--json] [--config path]

# Via daemon API
curl -X POST -H "Authorization: Bearer $(cat ~/.config/peerup/.daemon-cookie)" \
     -d '{"peer":"home-server"}' \
     --unix-socket ~/.config/peerup/peerup.sock \
     http://localhost/v1/traceroute
```

### Path Visualization

![Traceroute paths: relayed (2 hops via relay with latency) vs direct (1 hop, lower latency)](images/tools-traceroute-paths.svg)

### Output

**Relayed connection**:

```
traceroute to home-server (12D3KooWDRDM...), max 3 hops:
 1  12D3KooWK... (relay)  203.0.113.50:7777  23.0ms
 2  12D3KooWDRDM... (home-server)  via relay  45.0ms
--- path: [RELAYED via relay-server/0.1.0] ---
```

**Direct connection**:

```
traceroute to home-server (12D3KooWDRDM...), max 3 hops:
 1  12D3KooWDRDM... (home-server)  10.0.1.50:9000  2.0ms
--- path: [DIRECT] ---
```

### What It Shows

- Whether the connection is direct or through a relay
- Latency to each hop (relay, then peer)
- Relay server's software version (from peerstore AgentVersion)
- Peer addresses

### Implementation

This is not true multi-hop tracing (libp2p doesn't support TTL). Instead, it inspects connection metadata:

1. Check if the connection to the peer goes through a relay (multiaddr contains `/p2p-circuit`)
2. If relayed: measure RTT to relay separately, then RTT to peer through relay
3. If direct: single hop with measured RTT
4. Report the agent version of intermediate nodes from the peerstore

This gives the real diagnostic information needed: **where is my traffic going, and how fast is each segment**.

---

## resolve

P2P `nslookup` — resolves peer names to peer IDs.

### Usage

```bash
# Standalone (no network needed)
peerup resolve <name> [--json] [--config path]

# Via daemon API
curl -X POST -H "Authorization: Bearer $(cat ~/.config/peerup/.daemon-cookie)" \
     -d '{"name":"home-server"}' \
     --unix-socket ~/.config/peerup/peerup.sock \
     http://localhost/v1/resolve
```

### Output

**Plain text**:

```
home-server → 12D3KooWPrmh163sTHW3mYQm7YsLsSR2wr71fPp4g6yjuGv3sGQt (source: local_config)
```

**JSON (`--json`)**:

```json
{
  "name": "home-server",
  "peer_id": "12D3KooWPrmh163sTHW3mYQm7YsLsSR2wr71fPp4g6yjuGv3sGQt",
  "source": "local_config"
}
```

### Resolution Sources

| Source | Meaning |
|--------|---------|
| `local_config` | Resolved from `names:` section in `config.yaml` |
| `peer_id` | Input was already a valid peer ID (direct parse) |

### No Network Required

`resolve` reads from local config only — it doesn't contact the network or start a P2P host. Resolution is instant.

Names are configured in `config.yaml`:

```yaml
names:
  home-server: "12D3KooWPrmh163sTHW3mYQm7YsLsSR2wr71fPp4g6yjuGv3sGQt"
  laptop: "12D3KooWNq8c1fNjXwhRoWxSXT419bumWQFoTbowCwHEa96RJRg6"
```

---

## Standalone vs Daemon

All network tools work in two modes:

| Mode | Command | Speed | When to Use |
|------|---------|-------|-------------|
| Standalone | `peerup ping home-server` | Slower (creates temp host, bootstraps DHT) | One-off diagnostics, daemon not running |
| Daemon | `peerup daemon ping home-server` | Faster (reuses existing host + connections) | Repeated diagnostics, scripting |

### Standalone Startup

When running standalone, the tool:

1. Loads config to find relay addresses, bootstrap peers, and names
2. Creates a temporary libp2p host
3. Bootstraps into the DHT (client mode)
4. Connects to relay servers
5. Finds the target peer via DHT or relay fallback
6. Runs the diagnostic
7. Shuts down the host

This takes 5-15 seconds for initial setup. The daemon mode skips all of this.

### Shared Logic

Both modes use the same underlying functions:
- `p2pnet.PingPeer()` — streaming ping with configurable count and interval
- `p2pnet.ComputePingStats()` — min/avg/max/loss statistics
- `p2pnet.TracePeer()` — connection path analysis

---

## System Utility Comparison

| System Tool | peer-up Equivalent | What It Does |
|-------------|-------------------|--------------|
| `ping` | `peerup ping` | Measure RTT to a peer |
| `traceroute` | `peerup traceroute` | Show path to a peer (direct vs relay) |
| `nslookup` / `dig` | `peerup resolve` | Resolve name to peer ID |
| `ss` / `netstat` | `peerup daemon peers` | Show connected peers |
| `systemctl status` | `peerup daemon status` | Show daemon status |

---

**Last Updated**: 2026-02-16


---

# peer-up FAQ & Technical Comparison

> **Note on comparisons**: All technical comparisons in this document are based on publicly available documentation, specifications, and published benchmarks as of the date listed at the bottom. Software evolves — details may be outdated by the time you read this. If you spot an inaccuracy, corrections are welcome via [GitHub issues](https://github.com/satindergrewal/peer-up/issues) or pull requests.

## How does peer-up compare to Tailscale?

peer-up is not a cheaper Tailscale. It's the **self-sovereign alternative** for people who care about owning their network.

### Architecture

| Aspect | **peer-up** | **Tailscale** |
|--------|------------|---------------|
| **Foundation** | libp2p (circuit relay v2, DHT, QUIC) | WireGuard (kernel-level crypto) |
| **Topology** | Client → Relay → Server (with DCUtR upgrade to direct) | Full mesh, point-to-point |
| **NAT Traversal** | Circuit relay + hole-punching (DCUtR) | DERP relay servers + STUN/hole-punching |
| **Encryption** | libp2p Noise protocol (Ed25519) | WireGuard (Curve25519) |
| **Control Plane** | None — fully decentralized (DHT + config files) | Centralized coordination server |

### Privacy & Sovereignty

| | **peer-up** | **Tailscale** |
|---|---|---|
| **Accounts** | None — no email, no OAuth | Required (Google, GitHub, etc.) |
| **Telemetry** | Zero — no data leaves your network | Coordination server sees device graph |
| **Control plane** | None — relay only forwards bytes | Centralized coordination server |
| **Key custody** | You generate, you store, you control | Keys managed via their control plane |
| **Source** | Fully open, self-hosted | Open source client, proprietary control plane |

### Features

| Feature | **peer-up** | **Tailscale** |
|---------|------------|---------------|
| **Service tunneling** | SSH, XRDP, generic TCP | Full IP-layer VPN (any protocol) |
| **Auth model** | SSH-style `authorized_keys` (peer ID allowlist) | SSO (Google, Okta, GitHub), ACLs |
| **DNS** | Friendly names in config + private DNS on relay (planned) | MagicDNS (auto device names) |
| **Platforms** | Linux, macOS (Go binary) | Linux, Windows, macOS, iOS, Android, containers |
| **Setup** | `peerup init` wizard | Download → sign in → done |
| **Admin UI** | CLI only | Web dashboard, admin console |
| **Exit nodes** | Not yet | Yes |
| **Subnet routing** | Not yet | Yes |
| **Multi-user/team** | Invite/join flow + `peerup auth` CLI | Built-in team management, SSO |

### Where peer-up wins

- **No central authority** — No account, no coordination server, no vendor dependency
- **Importable library** — `pkg/p2pnet` can be embedded into any Go application
- **CGNAT/Starlink proven** — Relay-based architecture works through symmetric NAT
- **Self-hosted relay** — You run your own relay on a $5 VPS
- **GPU inference use case** — Purpose-built for exposing Ollama/vLLM through CGNAT

### Where Tailscale wins

- **IP-layer VPN** — Virtual network interface; any protocol works transparently
- **Mature ecosystem** — Mobile apps, web dashboard, ACLs, SSO, subnet routing, Funnel
- **Performance** — WireGuard is kernel-level and extremely fast
- **Scale** — Handles thousands of devices in an organization
- **Zero config** — "Install and sign in" onboarding
- **Platform coverage** — Runs everywhere including iOS, Android, containers

---

## How does peer-up compare to other P2P projects?

### Direct Competitors

#### Hyprspace — Most similar in the libp2p ecosystem

- **Stack**: Go + libp2p + IPFS DHT (same as peer-up)
- **What it does**: Lightweight VPN that creates TUN interfaces, uses DHT for discovery, NAT hole-punching via libp2p
- **Key features**: Virtual IP addresses, IPv6 routing, Service Network (subdomain-based service addressing)
- **Difference**: Hyprspace operates at the IP layer (TUN/TAP VPN), not TCP service proxy. No invite/onboarding flow, no relay-first architecture.
- **Link**: https://github.com/hyprspace/hyprspace

#### connet — Similar concept, different stack

- **Stack**: Go + QUIC (not libp2p)
- **What it does**: P2P reverse proxy with NAT traversal, inspired by frp/ngrok/rathole
- **Key features**: Source + destination clients, QUIC protocol, NAT-PMP support, certificate-based auth
- **Difference**: Uses QUIC directly instead of libp2p. No DHT discovery, no friendly naming, no init wizard.
- **Link**: https://github.com/connet-dev/connet

#### SomajitDey/tunnel — Simpler alternative

- **Stack**: Bash scripts + HTTP relay (piping-server)
- **What it does**: P2P TCP/UDP port forwarding through an HTTP relay
- **Difference**: Much simpler (bash scripts), no libp2p, no DHT, no connection gating.
- **Link**: https://github.com/SomajitDey/tunnel

### Adjacent Projects

#### Hyperswarm / Holepunch — DHT-assisted hole punching

- **Stack**: Node.js / C, HyperDHT, UTP + TCP
- **What it does**: P2P networking library powering [Keet](https://keet.io/) (encrypted P2P video/chat). DHT nodes actively assist with hole punching coordination.
- **Key features**: HyperDHT for discovery and relay-assisted hole punching, Noise protocol encryption, Hypercore for data replication
- **Difference**: Smaller ecosystem, fewer transports (no QUIC, no WebSocket), no anti-censorship story. Tightly coupled to the Hypercore/Dat ecosystem. Node.js-native (not Go). Hole punching may have higher success rates in some NAT scenarios because DHT nodes actively broker the handshake.
- **Link**: https://github.com/holepunchto/hyperswarm

#### Iroh — Library competitor to libp2p itself

- **Stack**: Rust, QUIC, custom relay protocol
- **What it does**: "Dial by public key" — P2P connectivity library with higher NAT traversal success rate than libp2p (~90%+ vs ~70%)
- **Difference**: A library, not an end-user tool. There's a `libp2p-iroh` transport adapter for using Iroh's NAT traversal within libp2p.
- **Link**: https://github.com/n0-computer/iroh

#### Nebula — Different stack, same goal

- **Stack**: Go, custom protocol (not WireGuard, not libp2p)
- **What it does**: P2P overlay network from Slack, full mesh with lighthouse nodes
- **Difference**: Certificate-authority model. **No relay fallback** — if hole-punching fails (e.g., CGNAT/Starlink), the connection simply doesn't work.
- **Link**: https://github.com/slackhq/nebula

#### Headscale / NetBird — Self-hosted Tailscale alternatives

- **Headscale**: Open source Tailscale control server — uses official Tailscale clients
- **NetBird**: Full self-hosted mesh with WireGuard, management service, signal server, relay
- **Difference**: Both are WireGuard-based, not libp2p. Different philosophy — they replicate Tailscale's architecture, peer-up builds something different.

### Comparison Table

| Project | Stack | Layer | Relay fallback | CGNAT works | Onboarding | Self-sovereign |
|---------|-------|-------|---------------|-------------|------------|----------------|
| **peer-up** | Go + libp2p | TCP service proxy | Yes (circuit relay v2) | Yes | `init` wizard + invite/join | Yes |
| **Hyprspace** | Go + libp2p | IP layer (TUN) | Yes (circuit relay) | Yes | Manual config | Yes |
| **Hyperswarm** | Node.js + HyperDHT | Library | Yes (DHT-assisted) | Yes | API only | Yes |
| **connet** | Go + QUIC | TCP proxy | Yes (control server) | Partial | Manual config | Yes |
| **tunnel** | Bash + HTTP | TCP/UDP proxy | Yes (HTTP relay) | Yes | CLI flags | Yes |
| **Iroh** | Rust + QUIC | Library | Yes (home relay) | Yes | API only | No (uses Iroh's relays) |
| **Nebula** | Go + custom | IP layer (TUN) | No | No | Certificate CA | Yes |
| **Tailscale** | Go + WireGuard | IP layer (TUN) | Yes (DERP) | Yes | SSO sign-in | No |
| **Headscale** | Go + WireGuard | IP layer (TUN) | Yes (DERP) | Yes | SSO sign-in | Partial (self-hosted control) |
| **NetBird** | Go + WireGuard | IP layer (TUN) | Yes | Yes | Dashboard | Partial (self-hosted control) |

### Blockchain P2P Networks

These are not competitors but useful reference points — their P2P stacks solve different problems (block propagation, consensus) but share underlying technology with peer-up:

| Network | P2P Stack | Discovery | NAT Traversal | Encryption | Key Insight |
|---------|-----------|-----------|---------------|------------|-------------|
| **Bitcoin** | Custom (TCP only) | DNS seeds + addr gossip | None | BIP 324 (added 2023 — was plaintext for 14 years) | Simplicity is strength; 17 years of adversarial hardening |
| **Ethereum (execution)** | devp2p / RLPx | discv5 (UDP) | None (public IPs expected) | ECIES | Legacy layer, pre-Merge |
| **Ethereum (consensus)** | **libp2p** (same as peer-up) | discv5 (chose over Kademlia) | Minimal | Noise protocol | Validates libp2p for critical infrastructure |
| **Filecoin** | libp2p | Kademlia DHT | Circuit relay | Noise / TLS 1.3 | Largest libp2p deployment by data volume |
| **Polkadot** | libp2p (Rust) | Kademlia DHT | Circuit relay | Noise | Multi-chain P2P; validates rust-libp2p |

---

## Circuit Relay v2 vs Iroh vs Tailscale DERP

### Hole-punching success (when no relay is needed)

| Protocol | NAT traversal success | Technique |
|----------|----------------------|-----------|
| **Circuit Relay v2 + DCUtR** | ~70% | STUN-like, coordinate via relay, single punch attempt |
| **Iroh** | ~90%+ | Tailscale-inspired, aggressive probing, multiple strategies |
| **Tailscale (DERP + STUN)** | ~92-94% | Most mature, years of iteration, birthday attack techniques |
| **WireGuard alone** | ~0% behind CGNAT | No relay, no hole-punching |
| **Nebula** | ~60-70% | Lighthouse-based, no relay fallback |

**Important**: With Starlink CGNAT (symmetric NAT), hole-punching success is **0% for all of them**. Every single one falls back to relay. The hole-punch success rates only matter for regular NAT (home routers, etc.).

### Relay quality (when traffic stays on relay)

| | **Circuit Relay v2 (self-hosted)** | **Iroh relay** | **Tailscale DERP** |
|---|---|---|---|
| **Throughput** | Your VPS bandwidth | Iroh's servers | Tailscale's servers |
| **Latency** | Your VPS location | Nearest Iroh relay | Nearest DERP node |
| **Protocol overhead** | Minimal (libp2p framing) | Minimal (UDP-over-HTTP) | Minimal (DERP framing) |
| **Encryption** | Noise protocol (libp2p) | QUIC TLS | WireGuard (ChaCha20) |
| **You control limits** | Yes — unlimited duration/data | No | No |
| **Relay sees content** | No (end-to-end encrypted) | No (end-to-end encrypted) | No (end-to-end encrypted) |

All three are roughly equivalent in relay quality. The relay is a dumb pipe forwarding encrypted bytes. Performance depends on infrastructure, not protocol.

### Connection establishment speed

| Protocol | Time to first byte | Why |
|----------|-------------------|-----|
| **Circuit Relay v2** | 5-15 seconds | Connect → reserve → DHT lookup → peer connects → DCUtR attempt |
| **Iroh** | 1-3 seconds | Persistent relay connection, peer dials by key, relay forwards immediately |
| **Tailscale DERP** | <1 second | Always-on DERP connection, peer dials by WireGuard key |

Circuit Relay v2 is slower because it involves a reservation step and DHT lookup. Iroh and Tailscale maintain persistent relay connections.

---

## Can I use public IPFS relay servers instead of my own?

Yes, public IPFS relays exist — thousands of them. Since Circuit Relay v2, every public IPFS node runs a relay by default. libp2p's AutoRelay can discover and use them automatically.

**But there's a catch.** Public relays have strict resource limits:

| Constraint | Public IPFS relay (v2 defaults) | Your self-hosted relay |
|-----------|-------------------------------|------------|
| **Duration** | 2 minutes per connection | Unlimited (you configure) |
| **Data cap** | 128 KB per relay session | Unlimited (you configure) |
| **Bandwidth** | ~1 Kbps (intentionally throttled) | Your VPS bandwidth |
| **Purpose** | Coordinate hole-punch, then disconnect | Full traffic relay |
| **Uptime** | Random node, could disappear | Your VPS, 99.9% uptime |
| **SSH session** | Drops after 2 min or 128 KB | Works indefinitely |

Public relays are designed as a **trampoline** — they help two peers find each other, attempt a hole-punch, and then drop off. They were never meant for sustained traffic like SSH sessions, XRDP, or LLM inference.

---

## Are Iroh's public relays the same as IPFS's public relays?

Conceptually yes — both are "someone else's relay you use for free." But the implementation differs significantly:

| | **IPFS public relays** | **Iroh's relays** |
|---|---|---|
| **Operator** | Thousands of random IPFS peers | n0 team (Iroh's company) |
| **Architecture** | Decentralized — any public node can be a relay | Centralized — Iroh runs them |
| **Data limit** | 128 KB per session | No hard cap |
| **Time limit** | 2 minutes | Persistent connection |
| **Purpose** | Trampoline for hole-punch coordination | Actual traffic fallback (like Tailscale's DERP) |
| **Reliability** | Random node could vanish anytime | Operated infrastructure |
| **Protocol** | libp2p Circuit Relay v2 | Custom protocol (UDP-over-HTTP) |

Iroh's relays are essentially **Tailscale's DERP servers for the Iroh ecosystem** — meant to carry real traffic when hole-punching fails. IPFS's public relays are just for the initial handshake.

---

## Why does peer-up use its own relay instead of public relays?

For Starlink/CGNAT (symmetric NAT) users, hole-punching **always fails**. Traffic must stay on the relay for the entire session. This means:

1. **Public IPFS relays** — Connection drops after 2 minutes or 128 KB. Unusable.
2. **Iroh's relays** — Would work, but you depend on Iroh's infrastructure and lose sovereignty.
3. **Tailscale's DERP** — Would work, but requires a Tailscale account and their control plane.
4. **Your own relay** — Works indefinitely, unlimited data, you control everything.

peer-up's self-hosted relay ($5/month VPS) is the only option that provides **both** unlimited traffic **and** full sovereignty.

---

## Why does Nebula fail with CGNAT?

Nebula uses **lighthouse nodes** (like STUN servers) to help peers discover each other's public IP:port. Then it attempts direct hole-punching.

With symmetric NAT (CGNAT), the mapped port **changes for every destination**:

![Why symmetric NAT breaks hole-punching: different mapped port per destination causes port mismatch](images/faq-symmetric-nat.svg)

The port the lighthouse tells Peer B to use was allocated for the lighthouse connection, not Peer B. The hole-punch fails.

**Nebula has no relay fallback.** If hole-punching fails, the connection simply doesn't work. Tailscale falls back to DERP. peer-up falls back to circuit relay. Nebula has nothing.

---

## Why Circuit Relay v2 is the right choice for peer-up

1. **Symmetric NAT** — Hole-punch success rates are irrelevant (all protocols fail against symmetric NAT, all fall back to relay)
2. **Self-hosted relay** — You control limits, so the 128KB/2min public relay caps don't apply
3. **No vendor dependency** — Matches the self-sovereign philosophy
4. **Native to libp2p** — No additional dependencies in the Go codebase
5. **Battle-tested** — Millions of IPFS nodes use it daily
6. **Configurable** — When you run your own relay, you set your own resource limits

The only area where alternatives genuinely outperform Circuit Relay v2:
- **Connection speed**: Iroh (1-3s) and Tailscale (<1s) are faster than Circuit Relay v2 (5-15s) due to persistent relay connections
- **Hole-punch success for regular NAT**: Iroh (~90%) and Tailscale (~92%) beat DCUtR (~70%) — but this doesn't matter for symmetric NAT

For Starlink CGNAT with a self-hosted relay, Circuit Relay v2 is **functionally equivalent** to Iroh and Tailscale in relay quality.

---

## What is Circuit Relay v2?

Circuit Relay v2 is libp2p's protocol for routing traffic through an intermediary relay node when peers can't connect directly (NAT, CGNAT, firewalls). It replaced v1 in 2021.

### How it works

![Circuit Relay v2 sequence: Peer A reserves slot on Relay, Peer B connects through Relay, streams bridged bidirectionally](images/faq-circuit-relay-sequence.svg)

The protocol splits into two sub-protocols:
- **Hop** (`/libp2p/circuit/relay/0.2.0/hop`) — client ↔ relay (reserve, connect)
- **Stop** (`/libp2p/circuit/relay/0.2.0/stop`) — relay ↔ target peer (deliver connection)

### Why v1 was replaced

v1 had no resource reservation — relays got overloaded with no way to limit usage. v2 introduced explicit reservations with configurable limits (duration, data caps, bandwidth), making it cheap to run "an army of relays for extreme horizontal scaling." Relays can reject connections with status codes like `RESOURCE_LIMIT_EXCEEDED` or `RESERVATION_REFUSED`.

### Known limitations

| Limitation | Detail |
|-----------|--------|
| **Setup latency** | 5-15 seconds (reservation + handshake + DHT lookup) |
| **No persistent connections** | Connections have hard TTL; each dial requires new reservation |
| **Reservation overhead** | Every peer must explicitly reserve before receiving relayed connections |
| **Throughput asymmetry** | Limited by relay's aggregate bandwidth, not peer bandwidth |
| **Default public limits** | 128 KB data cap, 2-minute duration (configurable on self-hosted) |

### Is there a Circuit Relay v3?

**No.** No v3 exists or is planned. libp2p's strategy is to reduce *dependence* on relays through better hole punching ([DCUtR](https://github.com/libp2p/specs/blob/master/relay/DCUtR.md) improvements, [AutoNAT v2](https://github.com/libp2p/specs/blob/master/autonat/autonat-v2.md)), not to replace the relay protocol itself.

The improvements come from upgrading everything *around* the relay — see the next FAQ entry.

**Source**: [Circuit Relay v2 Specification](https://github.com/libp2p/specs/blob/master/relay/circuit-v2.md)

---

## What libp2p improvements should peer-up adopt?

peer-up uses go-libp2p v0.47.0. Several improvements have shipped since then that would meaningfully improve performance, security, and reliability.

### AutoNAT v2 (go-libp2p v0.41.1+)

The old AutoNAT tested "is my node reachable?" as a binary yes/no. v2 tests **individual addresses**:

| | **AutoNAT v1** | **AutoNAT v2** |
|---|---|---|
| **Tests** | Whole node reachability | Each address independently |
| **Verification** | Trust the dialer's claim | Nonce-based proof (dial-back) |
| **Amplification risk** | Yes (could be spoofed) | No (client must transfer 30-100KB first) |
| **IPv4/IPv6** | Can't distinguish | Tests each separately |

A peer-up node could know "IPv4 is behind NAT but IPv6 is public" and make smarter connection decisions.

**Source**: [AutoNAT v2 Specification](https://github.com/libp2p/specs/blob/master/autonat/autonat-v2.md)

### Smart Dialing (go-libp2p v0.28.0+)

Old behavior: dial all peer addresses in parallel, abort on first success. Wasteful and creates network churn.

New behavior: ranks addresses intelligently, prioritizes QUIC over TCP, dials sequentially with fast failover. When a peer has both relay and direct addresses, smart dialing tries the direct path first.

### Resource Manager

DAG-based resource constraints at system, protocol, and per-peer levels. This is the proper replacement for peer-up's `WithInfiniteLimits()`:

- Per-peer connection and stream limits
- Per-peer bandwidth caps
- Memory and file descriptor budgets
- Rate limiting (1 connection per 5s per IP, 16-burst default)
- Prevents one peer from exhausting all relay resources

### QUIC Source Address Verification

Validates that the peer's source IP isn't spoofed. Prevents relay from being used as a DDoS reflector. Built into go-libp2p's QUIC transport since quic-go v0.54.0.

### DCUtR Hole Punching Improvements

No v2 of DCUtR, but continuous refinement:
- RTT measurement retries on each attempt (prevents one bad measurement from ruining all retries)
- TCP hole punching now achieves "statistically indistinguishable success rates" from UDP
- Measured success: **70% ± 7.1%** across 4.4M attempts from 85K+ networks in 167 countries

**Source**: [Large Scale NAT Traversal Measurement Study](https://arxiv.org/html/2510.27500v1), [libp2p Hole Punching blog](https://blog.ipfs.tech/2022-01-20-libp2p-hole-punching/)

### What peer-up plans to do (Phase 4C)

| Optimization | Impact | Effort |
|-------------|--------|--------|
| **Upgrade go-libp2p** to latest | Gains all of the above automatically | Low |
| **Replace `WithInfiniteLimits()`** with Resource Manager scopes | Eliminates relay resource exhaustion vulnerability | Medium |
| **Enable DCUtR** in proxy command | Bypasses relay entirely when hole punch succeeds | Low |
| **Connection warmup** | Pre-establish relay connection at startup (eliminates 5-15s per-session setup) | Low |
| **Stream pooling** | Reuse streams instead of fresh ones per TCP connection | Medium |
| **Persistent relay reservation** | Keep reservation alive with periodic refresh instead of re-reserving per connection | Medium |
| **QUIC as default transport** | 1 fewer RTT on connection setup (3 vs 4 for TCP) | Low |

Together, these changes would bring connection setup from 5-15 seconds closer to 1-3 seconds, matching Iroh's performance while keeping the self-sovereign architecture.

---

## Is Bitcoin's P2P faster than libp2p?

Bitcoin's P2P protocol has **less overhead per message**, but it can't do what peer-up needs.

### The Comparison

| | **Bitcoin P2P** | **libp2p** |
|---|---|---|
| **Transport** | Raw TCP only | TCP, QUIC, WebSocket, WebRTC |
| **Handshake** | 1.5-3 RTTs (~296 bytes) | 4+ RTTs (TCP) / 3 RTTs (QUIC) |
| **Per-message overhead** | 24 bytes (fixed header) | 12 bytes (Yamux) + encryption framing |
| **Encryption** | None | TLS 1.3 or Noise (mandatory) |
| **Multiplexing** | None (1 connection = 1 stream) | Yes (many streams per connection) |
| **NAT/CGNAT traversal** | No — requires port forwarding | Yes — relay, hole punching, AutoNAT |
| **Bulk data transfer** | Fast (minimal overhead) | Comparable once connected |

### Why Bitcoin P2P is "faster"

It's simpler — not fundamentally faster. Bitcoin uses raw TCP with a 24-byte binary header and zero encryption. No protocol negotiation, no multiplexing, no security handshake. It's lean because it *trusts nothing* at the network layer — blocks are verified cryptographically after receipt anyway.

### Why it doesn't matter for peer-up

**Bitcoin P2P cannot traverse NAT or CGNAT at all.** If both sides can't directly reach each other, Bitcoin nodes simply can't connect inbound. Users behind ISP CGNAT cannot run full Bitcoin nodes that accept inbound connections. Bitcoin originally had UPnP enabled by default but disabled it due to [miniupnpc vulnerabilities](https://bitcoin.org/en/alert/2015-10-12-upnp-vulnerability). It now uses PCP (Port Control Protocol), which ISP CGNAT equipment intentionally blocks.

NAT/CGNAT traversal is peer-up's entire reason for existing.

### The key research finding

A 2021 study implemented Bitcoin's block exchange protocol on top of libp2p and found:

> *"Setting up communication channels is time-consuming, but data transfers are fast"*

Once the connection is established, **bulk throughput is comparable**. The overhead is in the handshake, not the data flow. For peer-up's use case (long-lived connections proxying SSH, Ollama, XRDP), connection setup latency is a one-time cost that becomes irrelevant.

**Source**: Barbara Guidi, Andrea Michienzi, Laura Ricci. *"A libP2P Implementation of the Bitcoin Block Exchange Protocol."* Proceedings of the 2nd International Workshop on Distributed Infrastructure for Common Good (DICG '21), ACM, 2021. DOI: [10.1145/3493426.3493822](https://dl.acm.org/doi/10.1145/3493426.3493822)

### What peer-up does to close the gap

These optimizations are planned in Phase 4C (Core Hardening):

1. **QUIC transport** — saves 1 RTT on connection setup (3 RTTs vs 4 for TCP)
2. **Connection warmup** — pre-establish connection at `peerup proxy` startup
3. **Stream pooling** — reuse streams instead of fresh ones per TCP connection
4. **DCUtR hole punching** — bypass relay entirely for direct peer-to-peer (approaches Bitcoin-like raw TCP speed)

Once hole punching succeeds, peer-up is essentially just encrypted TCP with 12 bytes of Yamux framing per frame — very close to Bitcoin's raw TCP speed but with encryption and NAT traversal.

### Bottom line

Bitcoin P2P is lean but primitive. It solved a different problem: broadcasting blocks to publicly-reachable nodes. peer-up needs relay + hole punching + encryption — and libp2p is the right tool for that. The performance gap narrows dramatically with QUIC + connection pooling + DCUtR direct connections.

---

## How does Ethereum's P2P network compare to peer-up's?

Ethereum is the most relevant comparison because **its consensus layer uses the same libp2p stack** that peer-up is built on. Ethereum actually runs two separate P2P networks:

### Ethereum's two P2P layers

**Execution layer (devp2p/RLPx)** — the original Ethereum networking, predating The Merge:

| | **devp2p (Execution)** | **peer-up (libp2p)** |
|---|---|---|
| **Transport** | TCP only | QUIC + TCP + WebSocket |
| **Encryption** | ECIES (ECDH + AES) | Noise / TLS 1.3 |
| **Multiplexing** | Capability-based sub-protocols (eth, snap) | Yamux (any number of streams) |
| **Discovery** | discv5 (UDP-based DHT) | Kademlia DHT |
| **NAT traversal** | None — validators expected to have public IPs | AutoNAT v2 + circuit relay + DCUtR hole punching |
| **Identity** | ENR (Ethereum Node Records) | PeerID (Ed25519 multihash) |

**Consensus layer (libp2p)** — adopted for the Beacon Chain (post-Merge):

| | **Ethereum Consensus** | **peer-up** |
|---|---|---|
| **Stack** | libp2p (Go and Rust implementations) | libp2p (Go) |
| **libp2p version** | ~v0.30.x era | v0.47.0 (newer) |
| **Transports** | TCP primarily | QUIC → TCP → WebSocket |
| **Primary pattern** | gossipsub (topic-based pub/sub for blocks/attestations) | Point-to-point streams (service proxy) |
| **Discovery** | discv5 (custom, not libp2p Kademlia) | Kademlia DHT + relay bootstrap |
| **NAT traversal** | Minimal (validators run on servers) | Full: AutoNAT v2 + relay + hole punch |
| **Encryption** | Noise protocol | Noise / TLS 1.3 |

### Why Ethereum chose libp2p for consensus

When Ethereum needed a P2P networking stack for the Beacon Chain — the system securing hundreds of billions of dollars — they evaluated their options and chose libp2p. The reasons:

1. **Modularity** — swap transports, security, multiplexers independently
2. **Multi-language support** — Go (Prysm), Rust (Lighthouse), Java (Teku), .NET (Nethermind) all have libp2p implementations
3. **Stream multiplexing** — essential for gossipsub topic subscriptions
4. **Noise protocol** — mutual authentication during handshake

### Why Ethereum chose discv5 over libp2p's Kademlia for discovery

Ethereum's consensus layer uses libp2p for transport and encryption but **not** for peer discovery. They built discv5 instead:

| | **libp2p Kademlia DHT** | **Ethereum discv5** |
|---|---|---|
| **Protocol** | TCP-based | UDP-based |
| **Bandwidth** | Higher (DHT maintenance traffic) | Lower (lightweight probes) |
| **Topic advertisement** | Not built-in | Native topic-based discovery |
| **NAT handling** | Relies on relay/AutoNAT | Built-in PING/PONG with endpoint proof |
| **Purpose** | General content/peer routing | Pure peer discovery (minimal scope) |

The key reason: Kademlia DHT maintains routing tables and handles both content routing and peer discovery, which generates more background traffic than needed for pure discovery. discv5 does one thing — find peers — and does it with less bandwidth overhead.

**For peer-up**: Kademlia DHT is the right choice today because peer-up uses it for both peer discovery and rendezvous coordination, and the bandwidth overhead is negligible at current network sizes. The discv5 approach becomes interesting at larger scales where DHT maintenance traffic is measurable.

### What this means for peer-up

peer-up's libp2p foundation is **validated by Ethereum's consensus layer** — the same networking stack secures one of the largest decentralized networks in existence. peer-up also benefits from improvements driven by Ethereum's scale: gossipsub optimizations, Noise protocol hardening, and transport upgrades all flow back to the shared libp2p codebase.

Where peer-up goes further than Ethereum's usage:
- **Full NAT traversal** (AutoNAT v2, circuit relay, DCUtR) — Ethereum validators don't need this
- **QUIC as preferred transport** — Ethereum consensus still primarily uses TCP
- **WebSocket for anti-censorship** — Ethereum has no DPI evasion story
- **Point-to-point service proxy** — different use pattern than gossipsub broadcast

---

## What emerging technologies could benefit peer-up?

### Protocols to watch

| Protocol | What it gives peer-up | Status (2026) | Phase |
|----------|----------------------|---------------|-------|
| **MASQUE** ([RFC 9298](https://www.ietf.org/rfc/rfc9298.html)) | HTTP/3 relay that looks like HTTPS to deep packet inspection. 0-RTT session resumption for instant reconnection after network switch. | Production (Cloudflare deploys across 330+ datacenters) | Future |
| **Post-quantum Noise** (ML-KEM / FIPS 203) | Quantum-resistant handshakes. Regulatory mandates expected 2026-2028. | AWS KMS, Windows 11 shipping ML-KEM. libp2p not yet adopted. | Future |
| **QUIC v2** ([RFC 9369](https://datatracker.ietf.org/doc/rfc9369/)) | Anti-ossification — randomized version field prevents middleboxes from special-casing QUIC v1. | Finalized | 4C |
| **WebTransport** | Browser-native QUIC transport (replaces WebSocket for anti-censorship). Lower overhead, native datagrams. | Chrome/Firefox production, Safari flag-only | Future |
| **W3C DID v1.1** | Decentralized Identifiers — peer IDs in a standard, interoperable format (`did:key`, `did:peer`). | [First Public Draft 2025](https://www.w3.org/TR/did-1.1/) | Future |
| **eBPF / XDP** | Kernel-bypass packet filtering at millions of packets/sec. DDoS mitigation without userspace overhead. | Production (Cloudflare, Meta, Netflix) | 4C/Future |

### MASQUE: The next-generation relay transport

[MASQUE](https://www.ietf.org/rfc/rfc9298.html) (Multiplexed Application Substrate over QUIC Encryption) is an HTTP/3 proxying protocol with properties that directly address Circuit Relay v2's weaknesses:

| | **Circuit Relay v2** | **MASQUE** |
|---|---|---|
| **Looks like** | Custom libp2p protocol | Standard HTTPS traffic |
| **DPI evasion** | Requires WebSocket wrapping | Native — it IS HTTP/3 |
| **Session resume** | New reservation per connection | 0-RTT resume (TLS 1.3 tickets) |
| **Multiplexing** | Via Yamux (12-byte frames) | Native QUIC streams |
| **Infrastructure** | Self-hosted relay | Self-hosted or Cloudflare's global network |
| **Browser support** | No (requires native client) | Yes (WebTransport API) |

peer-up could offer MASQUE as an alternative relay transport alongside Circuit Relay v2 — giving users the choice between libp2p-native P2P and HTTP/3-based relay for environments where traffic must look like standard HTTPS.

### Post-quantum cryptography: The coming mandate

peer-up currently uses Noise protocol with Ed25519 (classical cryptography). Quantum computers could eventually break this. The industry is preparing:

- **NIST finalized** ML-KEM (FIPS 203) and ML-DSA (FIPS 204) as post-quantum standards
- **AWS** KMS, ACM, and Secrets Manager support ML-KEM (Nov 2025)
- **Windows 11/Server 2025** ship with built-in ML-KEM and ML-DSA
- **CRYSTALS-Kyber** being phased out in favor of ML-KEM (transition by 2026)
- **Hybrid approach**: Run classical + post-quantum in parallel during transition

For peer-up, the path is:
1. **Watch** libp2p's adoption of post-quantum Noise variants
2. **Design** cipher suite selection into the architecture (cryptographic agility)
3. **Implement** hybrid Noise + ML-KEM when libp2p support lands

**Sources**: [NIST PQC Standards](https://www.nist.gov/pqcrypto), [AWS ML-KEM Support](https://aws.amazon.com/blogs/security/ml-kem-post-quantum-tls-now-supported-in-aws-kms-acm-and-secrets-manager/)

### eBPF: Relay-server hardening at kernel speed

[eBPF](https://ebpf.io/) (extended Berkeley Packet Filter) allows running sandboxed programs in the Linux kernel without modifying kernel source. For peer-up's relay server:

- **XDP (eXpress Data Path)**: Process packets before they reach the network stack — millions of packets/sec DDoS mitigation
- **Rate limiting**: Per-IP connection throttling at kernel level (faster than iptables)
- **Runtime monitoring**: Detect exploitation attempts on the relay via syscall tracing (Falco, Tetragon)
- **Profiling**: Trace packet processing bottlenecks without instrumentation overhead

This complements the userspace hardening (Resource Manager, per-peer limits) with kernel-level defense. Requires Linux kernel >= 5.8.

### Zero-RTT proxy connection resume

**The problem**: When a laptop switches from WiFi to cellular (or WiFi flickers), all TCP connections through the proxy drop. The user must wait for reconnection (5-15 seconds with Circuit Relay v2).

**The solution**: QUIC 0-RTT session resumption. The client caches a session ticket from the previous connection. On reconnect, it sends encrypted data in the very first packet — before the server even processes the handshake.

**Who has this**: Cloudflare's MASQUE relays, QUIC-native applications.
**Who doesn't**: WireGuard (stateless, reconnects fast but not 0-RTT), all current P2P tunnel tools.

This is a future optimization for peer-up's QUIC transport — particularly valuable for mobile clients (Phase 4G).

---

## Why does peer-up use Go instead of Rust?

### The trade-off

| Factor | **Go** | **Rust** |
|--------|--------|----------|
| Development speed | Fast — the reason peer-up exists today | 2-3x slower initial development |
| GC pauses at scale | 10s pauses observed at 600K connections | None — no garbage collector |
| Memory per connection | ~28KB (GC overhead, interface boxing) | ~4-8KB (zero-cost abstractions) |
| libp2p ecosystem | Mature (go-libp2p, most examples) | Growing (rust-libp2p, Iroh) |
| Formal verification | Limited | Strong (s2n-quic has 300+ Kani harnesses) |
| Binary size | ~15-20MB | ~5-10MB |
| Cross-compilation | Trivial (`GOOS=linux GOARCH=arm64`) | Requires target toolchain setup |
| Concurrency model | Goroutines (simple, GC-managed) | async/await (no runtime overhead) |

### Why Go is right for now

Go's simplicity enabled rapid iteration through 7 phases of development. The libp2p Go ecosystem is the most mature, with the most examples and documentation. For a project with 1-100 concurrent connections (typical home use), Go's performance is more than adequate.

### When Rust becomes worth it

At scale — when a relay server handles thousands of concurrent circuits, or when the proxy loop becomes CPU-bound. The hot paths (packet forwarding in the relay, bidirectional proxy loop, SOCKS5 gateway) are candidates for selective Rust rewrite via FFI, not a full project rewrite.

### Rust libraries to watch

| Library | What it does | Why it matters |
|---------|-------------|----------------|
| **[Iroh](https://github.com/n0-computer/iroh)** | Rust P2P library, QUIC-native | ~90% NAT traversal success, QUIC multipath, approaching 1.0 |
| **[Quinn](https://github.com/quinn-rs/quinn)** | Pure Rust QUIC implementation | Used by Iroh, high performance, no C FFI |
| **[s2n-quic](https://github.com/aws/s2n-quic)** | AWS's Rust QUIC | Formal verification with Kani, production-tested in AWS |
| **[tokio](https://github.com/tokio-rs/tokio)** | Async runtime | LTS until Sept 2026, powers hyper (HTTP/2 + HTTP/3) |

### The hybrid strategy

peer-up's planned approach:
1. **Now through Phase 4E**: Ship in Go. Fix goroutine lifecycle, tune GC, add observability.
2. **Phase 4F+**: Profile hot paths under load. Selectively rewrite proxy loop / relay forwarding in Rust via FFI if performance demands it.
3. **Long-term**: Re-evaluate full Rust migration only if market demands 100x throughput and there's engineering capacity for it.

**Sources**: [Rust vs Go (Bitfield)](https://bitfieldconsulting.com/posts/rust-vs-go), [Go GC Guide](https://tip.golang.org/doc/gc-guide), [Iroh roadmap](https://www.iroh.computer/roadmap)

---

## What features does no existing P2P tool provide?

These are genuine gaps in every P2P/VPN/tunnel tool available today:

### 1. Zero-RTT proxy connection resume

When your network flickers (WiFi→cellular, WiFi dropout), every existing tool drops connections and requires a full reconnection handshake. QUIC 0-RTT session tickets could make reconnection instant — send encrypted data before the server processes the handshake.

**Who has it**: Nobody in the P2P tunnel space.
**Difficulty**: Medium (requires QUIC transport + session ticket caching).

### 2. Hardware-backed peer identity

No P2P tool stores peer private keys in TPM 2.0 (Linux servers) or Secure Enclave (macOS/iOS). Keys sit on disk, stealable by anyone with filesystem access.

**Who has it**: Nobody.
**Difficulty**: Medium (platform-specific APIs: `go-tpm`, `Security.framework`).

### 3. Kernel-bypass relay forwarding

Every relay server processes packets through the kernel network stack (syscalls per packet). eBPF/XDP or DPDK could forward relayed packets at line rate — benchmarks show [DPDK achieves 51% better throughput](https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/) than kernel stack, VPP uses 1/9th the CPUs.

**Who has it**: Nobody (Cloudflare uses XDP for DDoS, not for relay forwarding).
**Difficulty**: High (Linux-only, requires privileged access).

### 4. Built-in observability (OpenTelemetry)

No P2P tunnel tool ships with metrics, traces, or structured audit logs. DevOps teams bolt on monitoring after the fact, poorly. [OpenTelemetry](https://opentelemetry.io/) is table stakes for production infrastructure.

**Who has it**: Nobody in the P2P space.
**Difficulty**: Low (OpenTelemetry Go SDK, instrument key paths).

### 5. Formally verified protocol state machine

No P2P tool has mathematically proven that its handshake / invite / key exchange protocol is correct. Bugs in state machines cause security vulnerabilities. Formal verification tools like [Kani](https://github.com/model-checking/kani) (Rust) and [TLA+](https://lamport.azurewebsites.net/tla/tla.html) can prove correctness.

**Who has it**: AWS s2n-quic (QUIC only, not application layer). [Bert13](https://dl.acm.org/doi/10.1145/3719027.3765213) (first formally-verified post-quantum TLS 1.3 in Rust).
**Difficulty**: High (requires Rust migration for Kani, or TLA+ model of invite protocol).

### 6. Cryptographic agility (post-quantum ready)

No P2P tool supports cipher suite negotiation or hybrid classical + post-quantum handshakes. When ML-KEM mandates arrive (2026-2028), every tool will need emergency patches.

**Who has it**: Nobody in P2P. AWS and Microsoft are preparing at the infrastructure layer.
**Difficulty**: Medium (design cipher negotiation now, implement when libp2p adopts PQC).

---

## Is it safe for my home node to act as a relay?

This is the most important security question for peer-up's future. The short answer: **yes, with Circuit Relay v2's built-in protections, a home node can safely relay traffic for authorized peers without increasing its attack surface.**

Here's the full breakdown — because "trust us" is not a security argument.

### What "acting as a relay" actually means

When your home node enables relay service, it does one thing: accept a reservation from a peer (identified by their peer ID), then forward encrypted bytes between that peer and whoever connects to them through you. Your node never sees the content — it's end-to-end encrypted with Noise protocol. Your node never authenticates the remote peer's connections — that's the target peer's job.

Think of it as holding two tin cans connected by a string. You're the string. You can feel vibrations but not hear words.

### Resource limits are enforced by the protocol, not by trust

Circuit Relay v2 was specifically redesigned (from v1) because v1 relays had no resource controls and got overwhelmed. v2 has per-reservation resource budgets baked into the protocol:

| Protection | What it prevents | Default |
|-----------|-----------------|---------|
| **Max reservations** | Total peers using your relay | Configurable (128 default) |
| **Max circuits per peer** | One peer consuming all relay capacity | 16 |
| **Max reservations per IP** | IP address hoarding reservations | 8 |
| **Max reservations per ASN** | One ISP's network flooding your relay | 32 |
| **Reservation TTL** | Stale reservations consuming resources | 1 hour |
| **Session duration** | Indefinite relay connections | Configurable (10 min default) |
| **Session data limit** | Bandwidth theft | Configurable (64 MB default) |

When any limit is hit, the relay returns `RESOURCE_LIMIT_EXCEEDED` and the connection is refused. No crash, no OOM, no degradation. The peer simply can't connect.

### `require_auth: true` — only relay for people you chose

This is peer-up's critical addition: **relay service restricted to peers in your `authorized_keys` file.** An anonymous internet scanner hitting your relay's port gets rejected at the ConnectionGater before any relay protocol runs. The reservation request never reaches the relay service logic.

```yaml
# home-node config (future)
relay_service:
  enabled: true
  require_auth: true    # Only relay for peers in authorized_keys
  resources:
    max_reservations: 8
    session_duration: "15m"
    session_data_limit: "128MB"
```

With `require_auth: true`, the attack surface increase from enabling relay is **zero** for unauthenticated peers — they're rejected at the same layer they'd be rejected at today.

### "But my IP address becomes visible"

This concern has two parts:

**Part 1: Visible to peers you explicitly authorized.** Yes — when a peer connects directly (via hole punch or IPv6), they see your IP. But you already authorized them in `authorized_keys`. They already know where you are conceptually. And your IP is visible in any direct TCP/QUIC connection regardless of whether relay service is enabled.

**Part 2: Visible on the public DHT.** No — peer-up uses a **private Kademlia DHT** (`/peerup/kad/1.0.0`), completely isolated from the public IPFS Amino DHT. Your node only talks to other peer-up nodes for discovery, not the broader IPFS network. Your addresses are only discoverable by peers running peer-up software. Additional mitigations:
- **Relay-only advertising**: Advertise only your relay VPS address; your home IP only visible after authentication
- **IPv6 privacy extensions**: Use temporary IPv6 addresses that rotate

The relay VPS model today already exposes its public IP. A home relay with `require_auth: true` is no more exposed than the VPS — and arguably less, since the VPS has no auth requirement for relay service.

### What your relay CANNOT be used for

| Attack | Why it fails |
|--------|-------------|
| **Traffic sniffing** | End-to-end Noise encryption — relay sees ciphertext only |
| **Connection injection** | Both peers authenticate each other via peer ID (Ed25519) |
| **DDoS amplification** | QUIC source address verification; per-IP reservation limits |
| **Resource exhaustion** | Hard limits on reservations, circuits, duration, data |
| **Open relay abuse** | `require_auth: true` — only authorized peers can reserve |
| **Pivot to your LAN** | Relay forwards bytes, doesn't parse them. No routing to your network. |

### Why this is different from running an open service

Self-hosters know the pattern: expose a service on a home server, and within hours the port scanners find it. Firewall logs light up with probes from around the world. This happens because the service accepts connections from anyone — every participant on the network can reach it.

A peer-up relay with `require_auth` is fundamentally different:

| | **Typical exposed service** | **peer-up relay with `require_auth`** |
|---|---|---|
| **Who can connect** | Anyone who finds the port | Only peers in your `authorized_keys` |
| **What they can do** | Full protocol interaction | Forward encrypted bytes (nothing else) |
| **Discovery** | Port scanning, Shodan, service-specific gossip | Private — only authorized peers know about it |
| **Attack surface** | Full protocol parser (HTTP, SSH, etc.) | ConnectionGater rejection (zero protocol parsing for unauthorized) |

An open service is an open door with a bouncer inside. A peer-up relay with `require_auth` is a door that only opens with the right key — and even then, it only passes sealed envelopes.

### Comparison with other relay architectures

| Feature | **peer-up (require_auth)** | **Tailscale DERP** | **IPFS public relay** |
|---------|--------------------------|-------------------|---------------------|
| **Who can use it** | Explicit allowlist | Any Tailscale account holder | Anyone |
| **Authentication** | ConnectionGater (peer ID) | WireGuard keys | None |
| **Resource limits** | Per-peer, per-IP, per-ASN | Not published | 128 KB / 2 min |
| **E2E encryption** | Noise (Ed25519) | WireGuard (Curve25519) | Noise |
| **Relay sees content** | No | No | No |
| **Self-hosted** | Yes | No (Tailscale operates) | N/A (public nodes) |

### The path forward

The `require_auth` relay model is how peer-up eliminates dependency on the central relay VPS:

1. **Today**: One relay VPS → single point of failure
2. **Near-term**: Home nodes with public IPv6 or port-forwarding enable relay with `require_auth` → multiple relays across the network
3. **Medium-term**: Peers discover authorized relays via DHT (not a central endpoint) → no single point of failure
4. **End state**: Every publicly-reachable peer-up node relays for its authorized peers → relay VPS becomes **obsolete** (not just optional)

This follows the same decentralization path as Bitcoin: hardcoded seeds → DNS seeds → peer exchange → fully self-sustaining network.

**Sources**:
- [Circuit Relay v2 Specification](https://github.com/libp2p/specs/blob/master/relay/circuit-v2.md)
- [IPFS Hole Punching Blog — Relay as Last Resort](https://blog.ipfs.tech/2022-01-20-libp2p-hole-punching/)
- [libp2p Resource Manager](https://github.com/libp2p/go-libp2p/tree/master/p2p/host/resource-manager)

---

## Can NAT traversal improve without changes to peer-up?

Yes. NAT traversal success depends heavily on what the NAT device does, and router/OS vendors are starting to make NATs friendlier.

### FreeBSD PF: Endpoint-Independent Mapping (Sep 2024)

FreeBSD's packet filter (PF) now has an `endpoint-independent` NAT option for UDP. This makes the NAT behave as "full cone" — the mapped port stays the same regardless of destination. Full-cone NATs have near-100% hole-punch success because both peers can predict each other's mapped ports.

**Why this matters**: OPNsense (a popular firewall/router OS) is FreeBSD-based. If OPNsense adopts this option, a significant number of home and SMB routers get friendlier NAT behavior — and peer-up's DCUtR success rate improves automatically without any code changes.

**What to watch**: OPNsense releases, pfSense updates, and any Linux `nftables` equivalent. If this pattern spreads to consumer routers, the percentage of "hard NAT" cases (endpoint-dependent mapping) shrinks organically.

**Source**: [FreeBSD Status Report — Endpoint-Independent Mapping NAT](https://www.freebsd.org/status/report-2024-07-2024-09/eim-nat/)

### IPv6 eliminates NAT entirely

Many ISPs now provide globally routable public IPv6 addresses. IPv6 has no NAT — every device gets a public address. When two peers both have IPv6, they connect directly with zero NAT traversal, zero hole punching, zero relay dependency.

peer-up already supports IPv6 through libp2p's transport layer. AutoNAT v2 tests IPv4 and IPv6 reachability independently, so a node behind IPv4 CGNAT but with public IPv6 will correctly identify that its IPv6 addresses are directly reachable.

**Expected impact**: As IPv6 adoption grows (currently ~45% globally, higher on mobile networks), the percentage of connections requiring relay will decrease. For networks where both peers have IPv6, relay is already unnecessary today.

---

**Last Updated**: 2026-02-17


---

# Daemon API Reference

The peer-up daemon (`peerup daemon`) runs a long-lived P2P host with a Unix domain socket HTTP API for programmatic control.

## Table of Contents

- [Architecture](#architecture)
- [Authentication](#authentication)
- [Response Format](#response-format)
- [Endpoints](#endpoints)
  - [GET /v1/status](#get-v1status)
  - [GET /v1/services](#get-v1services)
  - [GET /v1/peers](#get-v1peers)
  - [GET /v1/auth](#get-v1auth)
  - [POST /v1/auth](#post-v1auth)
  - [DELETE /v1/auth/{peer_id}](#delete-v1authpeer_id)
  - [POST /v1/ping](#post-v1ping)
  - [POST /v1/traceroute](#post-v1traceroute)
  - [POST /v1/resolve](#post-v1resolve)
  - [POST /v1/connect](#post-v1connect)
  - [DELETE /v1/connect/{id}](#delete-v1connectid)
  - [POST /v1/expose](#post-v1expose)
  - [DELETE /v1/expose/{name}](#delete-v1exposename)
  - [POST /v1/shutdown](#post-v1shutdown)
- [Error Codes](#error-codes)
- [CLI Usage](#cli-usage)
- [Integration Examples](#integration-examples)
- [Socket Lifecycle](#socket-lifecycle)

---

## Architecture

The daemon runs the full P2P lifecycle (relay connection, DHT bootstrap, service exposure, watchdog) plus an HTTP server on a Unix socket.

![Daemon architecture: P2P Runtime (relay, DHT, services, watchdog) connected bidirectionally to Unix Socket API (HTTP/1.1, cookie auth, 14 endpoints), with P2P Network below left and CLI/Scripts below right](images/daemon-api-architecture.svg)

**Default paths**:
- Socket: `~/.config/peerup/peerup.sock` (permissions `0600`)
- Cookie: `~/.config/peerup/.daemon-cookie` (permissions `0600`)

---

## Authentication

The daemon uses cookie-based authentication (same pattern as Bitcoin Core, Docker, containerd).

### How It Works

1. On startup, the daemon generates a 32-byte random hex token
2. Token is written to `~/.config/peerup/.daemon-cookie` with `0600` permissions
3. Every API request must include `Authorization: Bearer <token>` header
4. Token is validated on every request — `401 Unauthorized` if missing or wrong
5. Cookie file is deleted on clean shutdown
6. Token rotates on every daemon restart (limits exposure window)

### Why Cookie Over Config-Based Password

- No plaintext passwords in config files
- Token rotates every daemon restart
- Same-user access only (cookie file is `0600`)
- Proven pattern used by Bitcoin Core, Docker, containerd

### Example

```bash
curl -H "Authorization: Bearer $(cat ~/.config/peerup/.daemon-cookie)" \
     --unix-socket ~/.config/peerup/peerup.sock \
     http://localhost/v1/status
```

The CLI client (`peerup daemon status`, etc.) reads the cookie file automatically — no manual auth needed.

> **Tip**: All curl examples in this document use inline `$(cat ~/.config/peerup/.daemon-cookie)` so they work as-is when copy-pasted. For scripts that make multiple API calls, read the token once into a variable — see [Integration Examples](#integration-examples).

### Unauthorized Response

```json
{
  "error": "unauthorized: invalid or missing auth token"
}
```

HTTP status: `401 Unauthorized`

---

## Response Format

Every endpoint supports two output formats:

### JSON (Default)

Success responses are wrapped in a `data` envelope:

```json
{"data": { ... }}
```

Error responses use an `error` envelope:

```json
{"error": "description of what went wrong"}
```

### Plain Text

Request plain text via:
- Query parameter: `?format=text`
- Accept header: `Accept: text/plain`

Plain text responses are single-line or tabular, designed for `grep`/`awk`/`cut`.

### CLI Format Selection

```bash
peerup daemon status          # human-readable text
peerup daemon status --json   # raw JSON
```

---

## Endpoints

### GET /v1/status

Returns daemon status: peer ID, version, uptime, connected peers, addresses, services count.

**Response (JSON)**:

```json
{
  "data": {
    "peer_id": "12D3KooWPrmh163sTHW3mYQm7YsLsSR2wr71fPp4g6yjuGv3sGQt",
    "version": "0.1.0",
    "uptime_seconds": 3600,
    "connected_peers": 2,
    "listen_addresses": [
      "/ip4/10.0.1.50/tcp/9000",
      "/ip4/10.0.1.50/udp/9000/quic-v1"
    ],
    "relay_addresses": [
      "/ip4/203.0.113.50/tcp/7777/p2p/12D3KooWK.../p2p-circuit"
    ],
    "services_count": 2
  }
}
```

**Response (Text)**:

```
peer_id: 12D3KooWPrmh163sTHW3mYQm7YsLsSR2wr71fPp4g6yjuGv3sGQt
version: 0.1.0
uptime: 3600s
connected_peers: 2
services: 2
listen_addresses: 2
  /ip4/10.0.1.50/tcp/9000
  /ip4/10.0.1.50/udp/9000/quic-v1
relay_addresses: 1
  /ip4/203.0.113.50/tcp/7777/p2p/12D3KooWK.../p2p-circuit
```

**curl**:

```bash
curl -H "Authorization: Bearer $(cat ~/.config/peerup/.daemon-cookie)" \
     --unix-socket ~/.config/peerup/peerup.sock \
     http://localhost/v1/status
```

---

### GET /v1/services

Lists all registered services.

**Response (JSON)**:

```json
{
  "data": [
    {
      "name": "ssh",
      "protocol": "/peerup/ssh/1.0.0",
      "local_address": "localhost:22",
      "enabled": true
    },
    {
      "name": "ollama",
      "protocol": "/peerup/ollama/1.0.0",
      "local_address": "localhost:11434",
      "enabled": true
    }
  ]
}
```

**Response (Text)** (tab-separated):

```
ssh	localhost:22	/peerup/ssh/1.0.0	enabled
ollama	localhost:11434	/peerup/ollama/1.0.0	enabled
```

---

### GET /v1/peers

Lists connected peers with their addresses and software version.

**By default, only peerup and relay-server peers are shown.** Peer-up uses a private Kademlia DHT (`/peerup/kad/1.0.0`), isolated from the public IPFS Amino network. Your node only communicates with other peer-up nodes for DHT peer discovery.

To see all connected peers (including DHT neighbors), add `?all=true`:

```
GET /v1/peers           → only peerup/relay-server peers
GET /v1/peers?all=true  → all connected peers (including DHT neighbors)
```

**CLI**:

```bash
peerup daemon peers          # only peerup peers
peerup daemon peers --all    # all peers including DHT neighbors
```

**Response (JSON)**:

```json
{
  "data": [
    {
      "id": "12D3KooWNq8c1fNjXwhRoWxSXT419bumWQFoTbowCwHEa96RJRg6",
      "addresses": [
        "/ip4/203.0.113.50/tcp/7777/p2p/12D3KooWK.../p2p-circuit/p2p/12D3KooWH..."
      ],
      "agent_version": "peerup/0.1.0"
    }
  ]
}
```

**Response (Text)**:

```
12D3KooWHoy98z8...	peerup/0.1.0	3 addrs
```

---

### GET /v1/auth

Lists authorized peers from the `authorized_keys` file.

**Response (JSON)**:

```json
{
  "data": [
    {
      "peer_id": "12D3KooWNq8c1fNjXwhRoWxSXT419bumWQFoTbowCwHEa96RJRg6",
      "comment": "laptop"
    }
  ]
}
```

**Response (Text)**:

```
12D3KooWNq8c1fNjXwhRoWxSXT419bumWQFoTbowCwHEa96RJRg6	# laptop
```

---

### POST /v1/auth

Adds a peer to `authorized_keys` and hot-reloads the connection gater. Takes effect immediately — no restart needed.

**Request Body**:

```json
{
  "peer_id": "12D3KooWNq8c1fNjXwhRoWxSXT419bumWQFoTbowCwHEa96RJRg6",
  "comment": "laptop"
}
```

**Response (JSON)**:

```json
{
  "data": {
    "status": "added"
  }
}
```

---

### DELETE /v1/auth/{peer_id}

Removes a peer from `authorized_keys` and hot-reloads the connection gater. Access revoked immediately.

**Response (JSON)**:

```json
{
  "data": {
    "status": "removed"
  }
}
```

**curl**:

```bash
curl -X DELETE \
     -H "Authorization: Bearer $(cat ~/.config/peerup/.daemon-cookie)" \
     --unix-socket ~/.config/peerup/peerup.sock \
     http://localhost/v1/auth/12D3KooWNq8c1fNjXwhRoWxSXT419bumWQFoTbowCwHEa96RJRg6
```

---

### POST /v1/ping

Pings a peer using the P2P ping-pong protocol. Returns per-ping results and summary statistics.

**Request Body**:

```json
{
  "peer": "home-server",
  "count": 4,
  "interval_ms": 1000
}
```

| Field | Type | Default | Description |
|-------|------|---------|-------------|
| `peer` | string | required | Peer name or ID |
| `count` | int | 4 | Number of pings (API defaults to 4) |
| `interval_ms` | int | 1000 | Milliseconds between pings |

**Response (JSON)**:

```json
{
  "data": {
    "results": [
      {"seq": 1, "peer_id": "12D3KooWDRDM...", "rtt_ms": 45.2, "path": "RELAYED"},
      {"seq": 2, "peer_id": "12D3KooWDRDM...", "rtt_ms": 42.1, "path": "DIRECT"},
      {"seq": 3, "peer_id": "12D3KooWDRDM...", "rtt_ms": 43.0, "path": "DIRECT"},
      {"seq": 4, "peer_id": "12D3KooWDRDM...", "rtt_ms": 41.8, "path": "DIRECT"}
    ],
    "stats": {
      "sent": 4,
      "received": 4,
      "lost": 0,
      "loss_pct": 0.0,
      "min_ms": 41.8,
      "avg_ms": 43.0,
      "max_ms": 45.2
    }
  }
}
```

**Response (Text)**:

```
PING home-server (12D3KooWDRDMuwQV...):
seq=1 rtt=45.2ms path=[RELAYED]
seq=2 rtt=42.1ms path=[DIRECT]
seq=3 rtt=43.0ms path=[DIRECT]
seq=4 rtt=41.8ms path=[DIRECT]
--- home-server ping statistics ---
4 sent, 4 received, 0% loss, rtt min/avg/max = 41.8/43.0/45.2 ms
```

---

### POST /v1/traceroute

Traces the network path to a peer. Shows whether the connection is direct or relayed, with per-hop latency.

**Request Body**:

```json
{
  "peer": "home-server"
}
```

**Response (JSON)**:

```json
{
  "data": {
    "target": "home-server",
    "target_peer_id": "12D3KooWDRDM...",
    "path": "RELAYED via relay-server/0.1.0",
    "hops": [
      {
        "hop": 1,
        "peer_id": "12D3KooWK...",
        "name": "relay",
        "address": "203.0.113.50:7777",
        "rtt_ms": 23.0
      },
      {
        "hop": 2,
        "peer_id": "12D3KooWDRDM...",
        "name": "home-server",
        "address": "via relay",
        "rtt_ms": 45.0
      }
    ]
  }
}
```

**Response (Text)**:

```
traceroute to home-server (12D3KooWDRDMuwQV...):
 1  12D3KooWK...  (relay)  203.0.113.50:7777  23.0ms
 2  12D3KooWDRDM...  (home-server)  via relay  45.0ms
--- path: [RELAYED via relay-server/0.1.0] ---
```

---

### POST /v1/resolve

Resolves a peer name to its peer ID. Shows the resolution source.

**Request Body**:

```json
{
  "name": "home-server"
}
```

**Response (JSON)**:

```json
{
  "data": {
    "name": "home-server",
    "peer_id": "12D3KooWPrmh163sTHW3mYQm7YsLsSR2wr71fPp4g6yjuGv3sGQt",
    "source": "local_config"
  }
}
```

| Source | Meaning |
|--------|---------|
| `local_config` | Resolved from `names:` section in config |
| `peer_id` | Input was already a valid peer ID |

**Response (Text)**:

```
home-server → 12D3KooWPrmh163sTHW3mYQm7YsLsSR2wr71fPp4g6yjuGv3sGQt (source: local_config)
```

---

### POST /v1/connect

Creates a dynamic TCP proxy to a peer's service. Returns a proxy ID and the local listen address.

**Request Body**:

```json
{
  "peer": "home-server",
  "service": "ssh",
  "listen": "127.0.0.1:2222"
}
```

| Field | Type | Description |
|-------|------|-------------|
| `peer` | string | Peer name or ID |
| `service` | string | Service name to connect to |
| `listen` | string | Local address:port to listen on |

**Response (JSON)**:

```json
{
  "data": {
    "id": "proxy-1",
    "listen_address": "127.0.0.1:2222"
  }
}
```

After this call, `ssh user@127.0.0.1 -p 2222` connects to the remote peer's SSH service through the P2P tunnel.

---

### DELETE /v1/connect/{id}

Tears down an active proxy by ID.

**Response (JSON)**:

```json
{
  "data": {
    "status": "disconnected"
  }
}
```

**curl**:

```bash
curl -X DELETE \
     -H "Authorization: Bearer $(cat ~/.config/peerup/.daemon-cookie)" \
     --unix-socket ~/.config/peerup/peerup.sock \
     http://localhost/v1/connect/proxy-1
```

---

### POST /v1/expose

Dynamically registers a service on the P2P host. Other peers can connect to it immediately.

**Request Body**:

```json
{
  "name": "jupyter",
  "local_address": "localhost:8888"
}
```

**Response (JSON)**:

```json
{
  "data": {
    "status": "exposed"
  }
}
```

---

### DELETE /v1/expose/{name}

Unregisters a service from the P2P host.

**Response (JSON)**:

```json
{
  "data": {
    "status": "unexposed"
  }
}
```

---

### POST /v1/shutdown

Requests a graceful shutdown of the daemon. The daemon closes all active proxies, shuts down the HTTP server, removes the socket and cookie files, then exits.

**Response (JSON)**:

```json
{
  "data": {
    "status": "shutting down"
  }
}
```

---

## Error Codes

| HTTP Status | Meaning |
|-------------|---------|
| `200` | Success |
| `400` | Bad request (missing/invalid fields) |
| `401` | Unauthorized (missing/wrong auth token) |
| `404` | Not found (unknown proxy ID, unresolvable name) |
| `500` | Internal error (file I/O failure, network error) |

All error responses use the envelope:

```json
{
  "error": "description of what went wrong"
}
```

### Sentinel Errors

| Error | Trigger |
|-------|---------|
| `daemon already running` | Socket is in use by another daemon instance |
| `daemon not running` | Socket file doesn't exist (client can't connect) |
| `proxy not found` | Disconnect called with unknown proxy ID |
| `unauthorized` | Missing or invalid auth token |

---

## CLI Usage

The CLI communicates with the daemon over the Unix socket. It reads the cookie file automatically.

### Starting the Daemon

```bash
peerup daemon              # Start daemon (foreground)
peerup daemon start        # Same as above
```

### Querying the Daemon

```bash
peerup daemon status               # Human-readable status
peerup daemon status --json        # JSON output
peerup daemon services             # List services
peerup daemon services --json
peerup daemon peers                # List connected peers
peerup daemon peers --json
```

### Network Diagnostics (via daemon)

```bash
peerup daemon ping home-server                 # 4 pings via daemon
peerup daemon ping home-server -c 10           # 10 pings
peerup daemon ping home-server --json          # JSON output
```

### Dynamic Proxy Management

```bash
# Create a proxy
peerup daemon connect --peer home-server --service ssh --listen 127.0.0.1:2222

# Use it
ssh user@127.0.0.1 -p 2222

# Tear it down
peerup daemon disconnect proxy-1
```

### Stopping the Daemon

```bash
peerup daemon stop          # Graceful shutdown via API
```

---

## Integration Examples

### Bash Script

```bash
#!/bin/bash
SOCKET=~/.config/peerup/peerup.sock
TOKEN=$(cat ~/.config/peerup/.daemon-cookie)

# Check if daemon is running
if [ ! -S "$SOCKET" ]; then
    echo "Daemon not running"
    exit 1
fi

# Get peer count
PEERS=$(curl -s -H "Authorization: Bearer $TOKEN" \
    --unix-socket "$SOCKET" \
    http://localhost/v1/status | jq '.data.connected_peers')

echo "Connected peers: $PEERS"

# Create SSH proxy to home server
PROXY=$(curl -s -X POST -H "Authorization: Bearer $TOKEN" \
    -d '{"peer":"home-server","service":"ssh","listen":"127.0.0.1:2222"}' \
    --unix-socket "$SOCKET" \
    http://localhost/v1/connect)

echo "Proxy: $(echo $PROXY | jq -r '.data.id')"
echo "Listen: $(echo $PROXY | jq -r '.data.listen_address')"
```

### Python (direct socket)

```python
import http.client
import json
import socket

SOCKET_PATH = os.path.expanduser("~/.config/peerup/peerup.sock")
COOKIE_PATH = os.path.expanduser("~/.config/peerup/.daemon-cookie")

# Read auth token
with open(COOKIE_PATH) as f:
    token = f.read().strip()

# Connect over Unix socket
conn = http.client.HTTPConnection("localhost")
conn.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
conn.sock.connect(SOCKET_PATH)

# Query status
conn.request("GET", "/v1/status", headers={
    "Authorization": f"Bearer {token}"
})
resp = conn.getresponse()
data = json.loads(resp.read())
print(f"Peer ID: {data['data']['peer_id']}")
print(f"Peers: {data['data']['connected_peers']}")
```

---

## Socket Lifecycle

### Startup

1. Generate 32-byte random hex token
2. Write token to `~/.config/peerup/.daemon-cookie` (`0600`)
3. Check for stale socket — dial the existing socket:
   - Connection succeeds → another daemon is alive → return `ErrDaemonAlreadyRunning`
   - Connection fails → stale socket → remove it and proceed
4. Create Unix socket at `~/.config/peerup/peerup.sock`
5. Set socket permissions to `0600`
6. Start HTTP server on the socket

### Stale Socket Detection

No PID files. The daemon dials the existing socket to determine if a daemon is alive:

- If the dial succeeds, another daemon is running — refuse to start.
- If the dial fails, the socket is stale (leftover from a crash) — remove it and start fresh.

This is more reliable than PID files, which can be stale themselves.

### Shutdown

1. HTTP server shutdown with 3s grace period
2. All active proxies cancelled and awaited
3. Socket file removed
4. Cookie file removed

---

**Last Updated**: 2026-02-20


---

# peer-up Architecture

This document describes the technical architecture of peer-up, from current implementation to future vision.

## Table of Contents

- [Current Architecture (Phase 4C Complete)](#current-architecture-phase-4c-complete) — what's built and working
- [Target Architecture (Phase 4D+)](#target-architecture-phase-4d) — planned additions
- [Core Concepts](#core-concepts) — implemented patterns
- [Security Model](#security-model) — implemented + planned extensions
- [Naming System](#naming-system) — local names implemented, network-scoped and blockchain planned
- [Federation Model](#federation-model) — planned (Phase 4H)
- [Mobile Architecture](#mobile-architecture) — planned (Phase 4G)

---

## Current Architecture (Phase 4C Complete)

### Component Overview

```
peer-up/
├── cmd/
│   ├── peerup/              # Single binary with subcommands
│   │   ├── main.go          # Command dispatch (daemon, ping, traceroute, resolve,
│   │   │                    #   proxy, whoami, auth, relay, config, service,
│   │   │                    #   invite, join, status, init, version)
│   │   ├── cmd_daemon.go    # Daemon mode + client subcommands (status, stop, ping, etc.)
│   │   ├── serve_common.go  # Shared P2P runtime (serveRuntime) — used by daemon
│   │   ├── cmd_init.go      # Interactive setup wizard
│   │   ├── cmd_proxy.go     # TCP proxy client
│   │   ├── cmd_ping.go      # Standalone P2P ping (continuous, stats)
│   │   ├── cmd_traceroute.go # Standalone P2P traceroute
│   │   ├── cmd_resolve.go   # Standalone name resolution
│   │   ├── cmd_whoami.go    # Show own peer ID
│   │   ├── cmd_auth.go      # Auth add/list/remove/validate subcommands
│   │   ├── cmd_relay.go     # Relay add/list/remove subcommands
│   │   ├── cmd_service.go   # Service add/list/remove subcommands
│   │   ├── cmd_config.go    # Config validate/show/rollback/apply/confirm
│   │   ├── cmd_invite.go    # Generate invite code + QR + P2P handshake (--non-interactive)
│   │   ├── cmd_join.go      # Decode invite, connect, auto-configure (--non-interactive, env var)
│   │   ├── cmd_status.go    # Local status: version, peer ID, config, services, peers
│   │   ├── config_template.go # Shared node config YAML template (single source of truth)
│   │   └── relay_input.go   # Flexible relay address parsing (IP, IP:PORT, multiaddr)
│   │   └── cmd_relay_serve.go # Relay server: serve/authorize/info/config
│
├── pkg/p2pnet/              # Importable P2P library
│   ├── network.go           # Core network setup, relay helpers, name resolution
│   ├── service.go           # Service registry (register/unregister, expose/unexpose)
│   ├── proxy.go             # Bidirectional TCP↔Stream proxy with half-close
│   ├── naming.go            # Local name resolution (name → peer ID)
│   ├── identity.go          # Identity helpers (delegates to internal/identity)
│   ├── ping.go              # Shared P2P ping logic (PingPeer, ComputePingStats)
│   ├── traceroute.go        # Shared P2P traceroute (TracePeer, hop analysis)
│   └── errors.go            # Sentinel errors
│
├── internal/
│   ├── config/              # YAML configuration loading + self-healing
│   │   ├── config.go           # Config structs (HomeNode, Client, Relay, unified NodeConfig)
│   │   ├── loader.go           # Load, validate, resolve paths, find config
│   │   ├── archive.go          # Last-known-good archive/rollback (atomic writes)
│   │   ├── confirm.go          # Commit-confirmed pattern (apply/confirm/enforce)
│   │   └── errors.go           # Sentinel errors (ErrConfigNotFound, ErrNoArchive, etc.)
│   ├── auth/                # SSH-style authentication
│   │   ├── authorized_keys.go  # Parser + ConnectionGater loader
│   │   ├── gater.go            # ConnectionGater implementation
│   │   ├── manage.go           # AddPeer/RemovePeer/ListPeers (shared by CLI commands)
│   │   └── errors.go           # Sentinel errors
│   ├── daemon/              # Daemon API server + client
│   │   ├── types.go            # JSON request/response types (StatusResponse, PingRequest, etc.)
│   │   ├── server.go           # Unix socket HTTP server, cookie auth, proxy tracking
│   │   ├── handlers.go         # HTTP handlers, format negotiation (JSON + text)
│   │   ├── client.go           # Client library for CLI → daemon communication
│   │   ├── errors.go           # Sentinel errors (ErrDaemonAlreadyRunning, etc.)
│   │   └── daemon_test.go      # Tests (auth, handlers, lifecycle, integration)
│   ├── identity/            # Ed25519 identity management (shared by peerup + relay-server)
│   │   └── identity.go      # CheckKeyFilePermissions, LoadOrCreateIdentity, PeerIDFromKeyFile
│   ├── invite/              # Invite code encoding/decoding
│   │   └── code.go          # Binary → base32 with dash grouping
│   ├── qr/                  # QR Code encoder for terminal display (inlined from skip2/go-qrcode)
│   │   ├── qrcode.go        # Public API: New(), Bitmap(), ToSmallString()
│   │   ├── encoder.go       # Data encoding (numeric, alphanumeric, byte modes)
│   │   ├── symbol.go        # Module matrix, pattern placement, penalty scoring
│   │   ├── version.go       # All 40 QR versions × 4 recovery levels
│   │   ├── gf.go            # GF(2^8) arithmetic + Reed-Solomon encoding
│   │   └── bitset.go        # Append-only bit array operations
│   ├── termcolor/           # Minimal ANSI terminal colors (replaces fatih/color)
│   │   └── color.go         # Green, Red, Yellow, Faint — respects NO_COLOR
│   ├── validate/            # Input validation helpers
│   │   └── validate.go      # ServiceName() — DNS-label format for protocol IDs
│   └── watchdog/            # Health monitoring + systemd integration
│       └── watchdog.go      # Health check loop, sd_notify (Ready/Watchdog/Stopping)
│
├── relay-server/            # Deployment artifacts
│   ├── setup.sh             # Deploy/verify/uninstall (builds peerup, runs relay serve)
│   ├── relay-server.service # systemd unit template (installed as peerup-relay.service)
│   └── relay-server.sample.yaml
│
├── deploy/                  # Service management files
│   ├── peerup-daemon.service   # systemd unit for daemon (Linux)
│   └── com.peerup.daemon.plist # launchd plist for daemon (macOS)
│
├── configs/                 # Sample configuration files
│   ├── peerup.sample.yaml
│   ├── relay-server.sample.yaml
│   └── authorized_keys.sample
│
├── docs/                    # Project documentation
│   ├── ARCHITECTURE.md      # This file
│   ├── DAEMON-API.md        # Daemon API reference
│   ├── NETWORK-TOOLS.md     # Network diagnostic tools guide
│   ├── FAQ.md
│   ├── ROADMAP.md
│   └── TESTING.md
│
└── examples/                # Example implementations
    └── basic-service/
```

### Network Topology (Current)

![Network topology: Client and Home Node behind NAT, connected through Relay with optional direct path via DCUtR hole-punching](images/arch-network-topology.svg)

### Authentication Flow

![Authentication flow: Client → Noise handshake → ConnectionGater check → authorized or denied → protocol handler defense-in-depth](images/arch-auth-flow.svg)

### Peer Authorization Methods

There are three ways to authorize peers:

**1. CLI — `peerup auth`**
```bash
peerup auth add <peer-id> --comment "label"
peerup auth list
peerup auth remove <peer-id>
```

**2. Invite/Join flow — zero-touch mutual authorization**
```
Machine A: peerup invite --name home     # Generates invite code + QR
Machine B: peerup join <code> --name laptop  # Decodes, connects, auto-authorizes both sides
```
The invite protocol uses a one-time token (16 random bytes, HMAC-verified) over a P2P stream. Both peers add each other to `authorized_keys` and `names` config automatically.

**3. Manual — edit `authorized_keys` file directly**
```bash
echo "12D3KooW... # home-server" >> ~/.config/peerup/authorized_keys
```

---

## Target Architecture (Phase 4D+)

### Planned Additions

Building on the current structure, future phases will add:

```
peer-up/
├── cmd/
│   ├── peerup/              # ✅ Single binary (daemon, serve, ping, traceroute, resolve,
│   │                        #   proxy, whoami, auth, relay, config, service, invite, join,
│   │                        #   status, init, version)
│   └── gateway/             # 🆕 Phase 4F: Multi-mode daemon (SOCKS, DNS, TUN)
│
├── pkg/p2pnet/              # ✅ Core library (importable)
│   ├── ...existing...
│   ├── interfaces.go        # 🆕 Phase 4D: Plugin interfaces
│   └── federation.go        # 🆕 Phase 4H: Network peering
│
├── internal/
│   ├── config/              # ✅ Configuration + self-healing (archive, commit-confirmed)
│   ├── auth/                # ✅ Authentication
│   ├── identity/            # ✅ Shared identity management
│   ├── validate/            # ✅ Input validation (service names, etc.)
│   ├── watchdog/            # ✅ Health checks + sd_notify
│   ├── transfer/            # 🆕 Phase 4D: File transfer plugin
│   └── tun/                 # 🆕 Phase 4F: TUN/TAP interface
│
├── mobile/                  # 🆕 Phase 4G: Mobile apps
│   ├── ios/
│   └── android/
│
└── ...existing (relay-server/, configs, docs, examples)
```

### Service Exposure Architecture

![Service exposure: 4-layer stack from Application (SSH/HTTP/SMB/Custom) through Service Registry and TCP-Stream Proxy to libp2p Network](images/arch-service-exposure.svg)

### Gateway Daemon Modes

> **Status: Planned (Phase 4F)** — not yet implemented. See [Roadmap Phase 4F](ROADMAP.md) for details.

![Gateway daemon modes: SOCKS Proxy (no root, app must be configured), DNS Server (resolve peer names to virtual IPs), and TUN/TAP (fully transparent, requires root)](images/arch-gateway-modes.svg)

---

## Daemon Architecture

### Daemon Architecture

`peerup daemon` is the single command for running a P2P host. It starts the full P2P lifecycle plus a Unix domain socket API for programmatic control (zero overhead if unused — it's just a listener).

### Shared P2P Runtime

To avoid code duplication, the P2P lifecycle is extracted into `serve_common.go`:

```go
// serveRuntime holds the shared P2P lifecycle state.
type serveRuntime struct {
    network    *p2pnet.Network
    config     *config.HomeNodeConfig
    configFile string
    gater      *auth.AuthorizedPeerGater  // nil if gating disabled
    authKeys   string                      // path to authorized_keys
    ctx        context.Context
    cancel     context.CancelFunc
    version    string
    startTime  time.Time
}
```

Methods: `newServeRuntime()`, `Bootstrap()`, `ExposeConfiguredServices()`, `SetupPingPong()`, `StartWatchdog()`, `StartStatusPrinter()`, `Shutdown()`.

### Daemon Server

The daemon server (`internal/daemon/`) is decoupled from the CLI via the `RuntimeInfo` interface:

```go
type RuntimeInfo interface {
    Network() *p2pnet.Network
    ConfigFile() string
    AuthKeysPath() string
    GaterForHotReload() GaterReloader  // nil if gating disabled
    Version() string
    StartTime() time.Time
    PingProtocolID() string
}
```

The `serveRuntime` struct implements this interface in `cmd_daemon.go`, keeping the daemon package importable without depending on CLI code.

### Cookie-Based Authentication

Every API request requires `Authorization: Bearer <token>`. The token is a 32-byte random hex string written to `~/.config/peerup/.daemon-cookie` with `0600` permissions. This follows the Bitcoin Core / Docker pattern — no plaintext passwords in config, token rotates on restart, same-user access only.

### Stale Socket Detection

No PID files. On startup, the daemon dials the existing socket:
- Connection succeeds → another daemon is alive → return error
- Connection fails → stale socket from a crash → remove and proceed

### Unix Socket API

14 HTTP endpoints over Unix domain socket. Every endpoint supports JSON (default) and plain text (`?format=text` or `Accept: text/plain`). Full API reference in [DAEMON-API.md](DAEMON-API.md).

### Dynamic Proxy Management

The daemon tracks active TCP proxies in memory. Scripts can create proxies via `POST /v1/connect` and tear them down via `DELETE /v1/connect/{id}`. All proxies are cleaned up on daemon shutdown.

### Auth Hot-Reload

`POST /v1/auth` and `DELETE /v1/auth/{peer_id}` modify the `authorized_keys` file and immediately reload the connection gater via the `GaterReloader` interface. Access grants and revocations take effect without restart.

---

## Concurrency Model

Background goroutines follow a consistent pattern for lifecycle management:

### Ticker + Select Pattern

All recurring background tasks (relay reservation, DHT advertising, status printing, stats logging) use `time.Ticker` with `select` on `ctx.Done()`:

```go
go func() {
    ticker := time.NewTicker(interval)
    defer ticker.Stop()
    for {
        select {
        case <-ctx.Done():
            return
        case <-ticker.C:
            // do work
        }
    }
}()
```

This ensures goroutines exit cleanly when the parent context is cancelled (e.g., on Ctrl+C).

### Watchdog + sd_notify

Both `peerup daemon` and `peerup relay serve` run a watchdog goroutine (`internal/watchdog`) that performs health checks every 30 seconds:

- **peerup daemon**: Checks host has listen addresses, relay reservation is active, and Unix socket is responsive
- **peerup relay serve**: Checks host has listen addresses and protocols are registered

On success, sends `WATCHDOG=1` to systemd via the `NOTIFY_SOCKET` unix datagram socket (pure Go, no CGo). On non-systemd systems (macOS), all sd_notify calls are no-ops. `READY=1` is sent after startup completes; `STOPPING=1` on shutdown.

The systemd service uses `Type=notify` and `WatchdogSec=90` (3x the 30s check interval) so systemd will restart the process if health checks stop succeeding.

### Health Check HTTP Endpoint (`/healthz`)

The relay server optionally exposes a `/healthz` HTTP endpoint for external monitoring (Prometheus, UptimeKuma, etc.). Disabled by default in config:

```yaml
health:
  enabled: true
  listen_address: "127.0.0.1:9090"
```

The endpoint returns JSON with: `status`, `peer_id`, `version`, `uptime_seconds`, `connected_peers`, `protocols`. Bound to localhost by default — not exposed to the internet. The HTTP server starts after the relay service is up and shuts down gracefully on SIGTERM.

### Commit-Confirmed Enforcement

When a commit-confirmed is active (`peerup config apply --confirm-timeout`), `serve` starts an `EnforceCommitConfirmed` goroutine that waits for the deadline. If `peerup config confirm` is not run before the timer fires, the goroutine reverts the config and calls `os.Exit(1)`. Systemd then restarts the process with the restored config.

### Graceful Shutdown

Long-running commands (`daemon`, `proxy`, `relay serve`) handle `SIGINT`/`SIGTERM` by calling `cancel()` on their root context, which propagates to all background goroutines. The daemon also accepts shutdown requests via the API (`POST /v1/shutdown`). Deferred cleanup (`net.Close()`, `listener.Close()`, socket/cookie removal) runs after goroutines stop.

### Atomic Counters

Shared counters accessed by concurrent goroutines (e.g., bootstrap peer count) use `atomic.Int32` instead of bare `int` to prevent data races.

---

## Core Concepts

### 1. Service Definition

Services are defined in configuration and registered at runtime:

```go
type Service struct {
    Name         string   // "ssh", "web", etc.
    Protocol     string   // "/peerup/ssh/1.0.0"
    LocalAddress string   // "localhost:22"
    Enabled      bool     // Enable/disable
}

type ServiceRegistry struct {
    services map[string]*Service
    host     host.Host
}

func (r *ServiceRegistry) RegisterService(svc *Service) error {
    // Set up stream handler for this service's protocol
    r.host.SetStreamHandler(svc.Protocol, func(s network.Stream) {
        // 1. Authorize peer
        if !r.isAuthorized(s.Conn().RemotePeer(), svc.Name) {
            s.Close()
            return
        }

        // 2. Dial local service
        localConn, err := net.Dial("tcp", svc.LocalAddress)
        if err != nil {
            s.Close()
            return
        }

        // 3. Bidirectional proxy
        go io.Copy(s, localConn)
        io.Copy(localConn, s)
    })
}
```

### 2. Bidirectional TCP↔Stream Proxy

```go
func ProxyStreamToTCP(stream network.Stream, tcpAddr string) error {
    // Connect to local TCP service
    tcpConn, err := net.Dial("tcp", tcpAddr)
    if err != nil {
        return err
    }
    defer tcpConn.Close()

    // Bidirectional copy
    errCh := make(chan error, 2)

    go func() {
        _, err := io.Copy(tcpConn, stream)
        errCh <- err
    }()

    go func() {
        _, err := io.Copy(stream, tcpConn)
        errCh <- err
    }()

    // Wait for either direction to finish
    return <-errCh
}
```

### 3. Name Resolution

**Currently implemented**: `LocalFileResolver` resolves friendly names (configured via `peerup invite`/`peerup join` or manual YAML) to peer IDs. Direct peer ID strings are always accepted as fallback.

```go
type LocalFileResolver struct {
    names map[string]peer.ID
}

func (r *LocalFileResolver) Resolve(name string) (peer.ID, error) {
    if id, ok := r.names[name]; ok {
        return id, nil
    }
    return "", ErrNotFound
}
```

> **Planned (Phase 4D/4I)**: The `NameResolver` interface, `DHTResolver`, multi-tier chaining, and blockchain naming are planned extensions. See [Naming System](#naming-system) below and [Roadmap Phase 4I](ROADMAP.md).

---

## Security Model

### Authentication Layers

**Layer 1: Network Level (ConnectionGater)**
- Executed during connection handshake
- Blocks unauthorized peers before any data exchange
- Fastest rejection (minimal resource usage)

**Layer 2: Protocol Level (Stream Handler)**
- Defense-in-depth validation
- Per-service authorization (optional)
- Can override global authorized_keys

### Per-Service Authorization

> **Status: Planned** — not yet implemented. Currently, all authorized peers can access all exposed services. Per-service access control is a deferred Phase 4C item. See [Roadmap](ROADMAP.md).

```yaml
# home-node.yaml (planned config format)
security:
  authorized_keys_file: "authorized_keys"  # Global default

services:
  ssh:
    enabled: true
    local_address: "localhost:22"
    authorized_keys: "ssh_authorized_keys"  # Override (planned)

  web:
    enabled: true
    local_address: "localhost:80"
    # Uses global authorized_keys
```

### Federation Trust Model

> **Status: Planned (Phase 4H)** — not yet implemented. See [Federation Model](#federation-model) and [Roadmap Phase 4H](ROADMAP.md).

```yaml
# relay-server.yaml (planned config format)
federation:
  peers:
    - network_name: "alice"
      relay: "/ip4/.../p2p/..."
      trust_level: "full"      # Bidirectional routing

    - network_name: "bob"
      relay: "/ip4/.../p2p/..."
      trust_level: "one_way"   # Only alice → grewal, not grewal → alice
```

---

## Naming System

### Multi-Tier Resolution

> **What works today**: Tier 1 (Local Override) — friendly names configured via `peerup invite`/`join` or manual YAML — and the Direct Peer ID fallback. Tiers 2-3 (Network-Scoped, Blockchain) are planned for Phase 4F/4I.

![Name resolution waterfall: Local Override → Network-Scoped → Blockchain → Direct Peer ID, with fallthrough on each tier](images/arch-naming-system.svg)

### Network-Scoped Name Format

> **Status: Planned (Phase 4F/4I)** — not yet implemented. Currently only simple names work (e.g., `home`, `laptop` as configured in local YAML). The dotted network format below is a future design.

```
Format: <hostname>.<network>[.<tld>]

Examples (planned):
laptop.grewal           # Query grewal relay
desktop.alice           # Query alice relay
phone.bob.p2p           # Query bob relay (explicit .p2p TLD)
home.grewal.local       # mDNS compatible
```

---

## Federation Model

> **Status: Planned (Phase 4H)** — not yet implemented. See [Roadmap Phase 4H](ROADMAP.md).

### Relay Peering

![Federation model: three networks (A, B, C) with relay peering — cross-network connections routed through federated relays](images/arch-federation.svg)

---

## Mobile Architecture

> **Status: Planned (Phase 4G)** — not yet implemented. See [Roadmap Phase 4G](ROADMAP.md).

![Mobile architecture: iOS uses NEPacketTunnelProvider, Android uses VPNService — both embed libp2p-go via gomobile](images/arch-mobile.svg)

---

## Performance Considerations

### Transport Preference

Both `peerup daemon` and `peerup relay serve` register transports in this order:

1. **QUIC** (preferred) — 3 RTTs to establish, native multiplexing, better for hole-punching. libp2p's smart dialing (built into v0.47.0) ranks QUIC addresses higher than TCP.
2. **TCP** — 4 RTTs, universal fallback for networks that block UDP.
3. **WebSocket** — Anti-censorship transport that looks like HTTPS to deep packet inspection (DPI). Commented out by default in sample configs.

### AutoNAT v2

Enabled on all hosts. AutoNAT v2 performs per-address reachability testing with nonce-based dial verification. This means the node knows which specific addresses (IPv4, IPv6, QUIC, TCP) are publicly reachable, rather than a single "public or private" determination. Also prevents amplification attacks by requiring the probing peer to prove it controls the claimed address.

### Version in Identify Protocol

All hosts set `libp2p.UserAgent()` so peers can discover each other's software version via the Identify protocol:
- **peerup nodes**: `peerup/<version>` (e.g., `peerup/0.1.0` or `peerup/dev`)
- **relay server**: `relay-server/<version>`

The UserAgent is stored in each peer's peerstore under the `AgentVersion` key after the Identify handshake completes (automatically on connect).

### Connection Optimization

1. **Relay vs Direct** (implemented):
   - Always attempt DCUtR for direct connection
   - Fall back to relay if hole-punching fails

2. **Connection Pooling** (planned):
   - Reuse P2P streams for multiple requests
   - Multiplex services over single connection
   - Keep-alive mechanisms

3. **Bandwidth Management** (planned):
   - QoS for different service types
   - Rate limiting per service
   - Bandwidth monitoring and alerts

> Items marked "planned" are tracked in the [Roadmap](ROADMAP.md) under Phase 4C deferred items and Phase 5+.

---

## Security Hardening

### Relay Resource Limits

The relay server enforces resource limits via libp2p's circuit relay v2 `WithResources()` and `WithLimit()` options. All limits are configurable in `relay-server.yaml` under the `resources:` section. Defaults are tuned for a private relay serving 2-10 peers with SSH/XRDP workloads:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `max_reservations` | 128 | Total active relay slots |
| `max_circuits` | 16 | Open relay connections per peer |
| `max_reservations_per_ip` | 8 | Reservations per source IP |
| `max_reservations_per_asn` | 32 | Reservations per AS number |
| `reservation_ttl` | 1h | Reservation lifetime |
| `session_duration` | 10m | Max per-session duration |
| `session_data_limit` | 64MB | Max data per session per direction |

Session duration and data limits are raised from libp2p defaults (2min/128KB) to support real workloads (SSH, XRDP, file transfers). Zero-valued fields in config are filled with defaults at load time.

### Key File Permission Verification

Private key files are verified on load to ensure they are not readable by group or others. The shared `internal/identity` package provides `CheckKeyFilePermissions()` and `LoadOrCreateIdentity()`, used by both `peerup daemon` and `peerup relay serve`:

- **Expected**: `0600` (owner read/write only)
- **On violation**: Returns error with actionable fix: `chmod 600 <path>`
- **Windows**: Check is skipped (Windows uses ACLs, not POSIX permissions)

Keys are already created with `0600` permissions, but this check catches degradation from manual `chmod`, file copies across systems, or archive extraction.

### Config Self-Healing

The config system provides three layers of protection against bad configuration:

1. **Archive/Rollback** (`internal/config/archive.go`): On each successful `daemon` or `relay serve` startup, the validated config is archived as `.{name}.last-good.yaml` next to the original. If a future edit breaks the config, `peerup config rollback` restores it. Archive writes are atomic (write temp file + rename).

2. **Commit-Confirmed** (`internal/config/confirm.go`): For remote config changes, `peerup config apply` backs up the current config, applies the new one, and writes a pending marker with a deadline. If `peerup config confirm` is not run before the deadline, the serve process reverts the config and exits. Systemd restarts with the restored config.

3. **Validation CLI** (`peerup config validate`): Check config syntax and required fields without starting the node. Useful before restarting a remote service.

### Service Name Validation

Service names are validated before use in protocol IDs to prevent injection attacks. Names flow into `fmt.Sprintf("/peerup/%s/1.0.0", name)` — without validation, a name like `ssh/../../evil` or `foo\nbar` creates ambiguous or invalid protocol IDs.

The validation logic lives in `internal/validate/validate.go` (`validate.ServiceName()`), shared by all callers.

**Validation rules** (DNS-label format):
- 1-63 characters
- Lowercase alphanumeric and hyphens only
- Must start and end with alphanumeric character
- Regex: `^[a-z0-9]([a-z0-9-]{0,61}[a-z0-9])?$`

Validated at four points:
1. `peerup service add` — rejects bad names at CLI entry
2. `ValidateNodeConfig()` — rejects bad names in config before startup
3. `ExposeService()` — rejects bad names at service registration time
4. `ConnectToService()` — rejects bad names at connection time

---

## Security Considerations

### Threat Model

**Threats Addressed**:
- ✅ Unauthorized peer access (ConnectionGater)
- ✅ Man-in-the-middle (libp2p Noise encryption)
- ✅ Replay attacks (Noise protocol nonces)
- ✅ Relay bandwidth theft (relay authentication + resource limits)
- ✅ Relay resource exhaustion (configurable per-peer/per-IP/per-ASN limits)
- ✅ Protocol ID injection (service name validation)
- ✅ Key file permission degradation (0600 check on load)
- ✅ Newline injection in authorized_keys (sanitized comments)
- ✅ YAML injection via peer names (allowlisted characters)
- ✅ OOM via unbounded stream reads (512-byte buffer limits)
- ✅ Symlink attacks on temp files (os.CreateTemp with random suffix)
- ✅ Multiaddr injection in config (validated before writing)

**Threats NOT Addressed** (out of scope):
- ❌ Relay compromise (relay can see metadata, not content)
- ❌ Peer key compromise (users must secure private keys)
- ❌ DoS attacks (rate limiting planned for future)

### Best Practices

1. **Key Management**:
   - Private keys: 0600 permissions
   - authorized_keys: 0600 permissions
   - Never commit keys to git

2. **Network Segmentation**:
   - Use per-service authorized_keys when needed
   - Limit service exposure (disable unused services)
   - Audit authorized_keys regularly

3. **Relay Security**:
   - Enable relay authentication in production
   - Monitor relay bandwidth usage
   - Use non-standard ports

---

## Scalability

### Current Limitations

- **Relay bandwidth**: Limited by VPS plan (~1TB/month)
- **Connections per relay**: Limited by file descriptors (~1000-10000)
- **DHT lookups**: Slow for large networks (10-30 seconds)

### Future Improvements

- Multiple relay failover/load balancing
- Relay-to-relay mesh for redundancy
- Optimized peer routing (shortest path)
- Distributed hash table optimization
- Connection multiplexing

---

## Technology Stack

**Core**:
- Go 1.25+
- libp2p v0.47.0 (networking)
- Private Kademlia DHT (`/peerup/kad/1.0.0` — isolated from IPFS Amino)
- Noise protocol (encryption)
- QUIC transport (preferred — 3 RTTs vs 4 for TCP)
- AutoNAT v2 (per-address reachability testing)

**Why libp2p**: peer-up's networking foundation is the same stack used by Ethereum's consensus layer (Beacon Chain), Filecoin, and Polkadot — networks collectively securing hundreds of billions in value. When Ethereum chose a P2P stack for their most critical infrastructure, they picked libp2p. Improvements driven by these ecosystems (transport optimizations, Noise hardening, gossipsub refinements) flow back to the shared codebase. See the [FAQ](FAQ.md#how-does-ethereums-p2p-network-compare-to-peer-ups) for detailed comparisons.

**Optional**:
- Ethereum (blockchain naming)
- IPFS (distributed storage)
- gomobile (iOS/Android)

---

**Last Updated**: 2026-02-20
**Architecture Version**: 2.9 (SVG diagrams, status labels for planned vs implemented sections)


---

# peer-up Development Roadmap

This document outlines the multi-phase evolution of peer-up from a simple NAT traversal tool to a comprehensive decentralized P2P network infrastructure.

## Philosophy

> **Build for 1-5 years. Make it adaptable. Don't predict 2074.**

- ✅ **Modular architecture** - Easy to add/swap components
- ✅ **Library-first** - Core logic reusable in other projects
- ✅ **Progressive enhancement** - Each phase adds value independently
- ✅ **No hard dependencies** - Works without optional features (naming, blockchain, etc.)
- ✅ **Local-first** - Offline-capable, no central services required
- ✅ **Self-sovereign** - No accounts, no telemetry, no vendor dependency
- ✅ **Automation-friendly** - Daemon API, headless onboarding, multi-language SDKs

---

## Phase 1: Configuration Infrastructure ✅ COMPLETE

**Goal**: Externalize all hardcoded values to YAML configuration files.

**Status**: ✅ Completed

**Deliverables**:
- [x] `internal/config` package for loading YAML configs
- [x] Sample configuration files in `configs/`
- [x] Updated `.gitignore` for config files
- [x] Refactored home-node/client-node/relay-server to use configs

**Key Files**:
- `internal/config/config.go` - Configuration structs
- `internal/config/loader.go` - YAML parsing
- `configs/*.sample.yaml` - Sample configurations

---

## Phase 2: Key-Based Authentication ✅ COMPLETE

**Goal**: Implement SSH-style authentication using ConnectionGater and authorized_keys files.

**Status**: ✅ Completed

**Deliverables**:
- [x] `internal/auth/gater.go` - ConnectionGater implementation (primary defense)
- [x] `internal/auth/authorized_keys.go` - Parser for authorized_keys
- [x] Integration into home-node and client-node
- [x] Protocol-level validation (defense-in-depth)
- [x] Relay server authentication (optional)

**Security Model**:
- **Layer 1**: ConnectionGater (network level - earliest rejection)
- **Layer 2**: Protocol handler validation (application level - secondary check)

---

## Phase 3: Enhanced Usability - keytool CLI ✅ COMPLETE (superseded)

**Goal**: Create production-ready CLI tool for managing Ed25519 keypairs and authorized_keys.

**Status**: ✅ Completed (keytool features merged into `peerup` subcommands in Phase 4C module consolidation; `cmd/keytool/` deleted)

**Deliverables**:
- [x] `cmd/keytool` with 5 commands: generate, peerid, validate, authorize, revoke
- [x] Comment-preserving parser for authorize/revoke
- [x] Color-coded terminal output
- [x] Integration with existing auth system
- [x] Comprehensive documentation in README

**Note**: All keytool functionality now lives in `peerup` subcommands: `peerup whoami` (peerid), `peerup auth add` (authorize), `peerup auth remove` (revoke), `peerup auth list`, `peerup auth validate` (validate). Key generation happens via `peerup init`.

---

## Phase 4: Service Exposure & Core Library

**Goal**: Transform peer-up into a reusable library and enable exposing local services through P2P connections.

### Phase 4A: Core Library & Service Registry ✅ COMPLETE

**Timeline**: 2-3 weeks
**Status**: ✅ Completed

**Deliverables**:
- [x] Create `pkg/p2pnet/` as importable package
  - [x] `network.go` - Core P2P network setup, relay helpers, name resolution
  - [x] `service.go` - Service registry and management
  - [x] `proxy.go` - Bidirectional TCP↔Stream proxy with half-close
  - [x] `naming.go` - Local name resolution (name → peer ID)
  - [x] `identity.go` - Ed25519 identity management
- [x] Extend config structs for service definitions
- [x] Update sample YAML configs with service examples
- [x] Refactor to `cmd/` layout with single Go module
- [x] Tested: SSH, XRDP, generic TCP proxy all working across LAN and 5G
- [x] **UX Streamlining**:
  - [x] Single binary — merged home-node into `peerup daemon`
  - [x] Standard config path — auto-discovery (`./peerup.yaml` → `~/.config/peerup/config.yaml` → `/etc/peerup/config.yaml`)
  - [x] `peerup init` — interactive setup wizard (generates config, keys, authorized_keys)
  - [x] All commands support `--config <path>` flag
  - [x] Unified config type (one config format for all modes)

**Key Files**:
- `cmd/peerup/` - Single binary with subcommands: init, serve, proxy, ping
- `pkg/p2pnet/` - Reusable P2P networking library
- `internal/config/loader.go` - Config discovery, loading, path resolution

---

### Phase 4B: Frictionless Onboarding ✅ COMPLETE

**Timeline**: 1-2 weeks
**Status**: ✅ Completed

**Goal**: Eliminate manual key exchange and config editing. Get two machines connected in under 60 seconds.

**Rationale**: The current flow (generate key → share peer ID → edit authorized_keys → write config) has 4 friction points before anything works. This is the single biggest adoption barrier.

**Deliverables**:
- [x] `peerup invite` — generate short-lived invite code (encodes relay address + peer ID)
- [x] `peerup join <code>` — accept invite, exchange keys, auto-configure, connect
- [x] QR code output for `peerup invite` (scannable by mobile app later)
- [x] `peerup whoami` — show own peer ID and friendly name for sharing
- [x] `peerup auth add <peer-id> --comment "friend"` — append to authorized_keys
- [x] `peerup auth list` — show authorized peers
- [x] `peerup auth remove <peer-id>` — revoke access
- [x] `peerup relay add/list/remove` — manage relay addresses without editing YAML
- [x] Flexible relay address input — accept `IP:PORT` or bare `IP` (default port 7777) in addition to full multiaddr
- [x] QR code display in `peerup init` (peer ID) and `peerup invite` (invite code)
- [x] Relay connection info + QR code in `setup.sh --check`

**Security hardening** (done as part of 4B):
- [x] Sanitize authorized_keys comments (prevent newline injection)
- [x] Sanitize YAML names from remote peers (prevent config injection)
- [x] Limit invite/join stream reads to 512 bytes (prevent OOM DoS)
- [x] Validate multiaddr before writing to config YAML
- [x] Use `os.CreateTemp` for atomic writes (prevent symlink attacks)
- [x] Reject hostnames in relay input — only IP addresses accepted (no DNS resolution / SSRF)
- [x] Config files written with 0600 permissions

**Key Files**:
- `cmd/peerup/cmd_auth.go` — auth add/list/remove subcommands
- `cmd/peerup/cmd_whoami.go` — show peer ID
- `cmd/peerup/cmd_invite.go` — generate invite code + QR + P2P handshake
- `cmd/peerup/cmd_join.go` — decode invite, connect, auto-configure
- `cmd/peerup/cmd_relay.go` — relay add/list/remove subcommands
- `cmd/peerup/relay_input.go` — flexible relay address parsing (IP, IP:PORT, multiaddr)
- `internal/auth/manage.go` — shared AddPeer/RemovePeer/ListPeers with input sanitization
- `internal/invite/code.go` — binary invite code encoding/decoding (base32)

**User Experience**:
```bash
# Machine A (home server)
$ peerup invite --name home
=== Invite Code (expires in 10m0s) ===
AEQB-XJKZ-M4NP-...
[QR code displayed]
Waiting for peer to join...

# Machine B (laptop)
$ peerup join AEQB-XJKZ-M4NP-... --name laptop
=== Joined successfully! ===
Peer "home" authorized and added to names.
Try: peerup ping home

# Or use CLI auth commands directly:
$ peerup auth add 12D3KooW... --comment "friend"
$ peerup auth list
$ peerup auth remove 12D3KooW...

# Manage relay servers:
$ peerup relay add 203.0.113.50:7777 --peer-id 12D3KooW...
$ peerup relay list
$ peerup relay remove /ip4/203.0.113.50/tcp/7777/p2p/12D3KooW...
```

**Security**:
- Invite codes are short-lived (configurable TTL, default 10 minutes)
- One-time use — code is invalidated after successful join
- Relay mediates the handshake but never sees private keys
- Both sides must be online simultaneously during join
- Stream reads capped at 512 bytes to prevent OOM attacks
- All user-facing inputs sanitized before writing to files

**Bug fixes (discovered during real-world testing)**:
- [x] Fixed invite code corruption when `--name` flag follows positional arg (`peerup join CODE --name laptop` — Go's `flag.Parse` stops at first non-flag, concatenating `--name` and `laptop` into the base32 code)
- [x] Added strict multihash length validation in invite decoder — Go's `base32.NoPadding` silently accepts trailing junk, so `Decode()` now re-encodes and compares multihash byte lengths
- [x] Fixed stream reset during invite join — inviter now flushes the OK response through the relay circuit before closing the stream
- [x] Added `reorderFlagsFirst()` to `runJoin()` so flags can appear after positional args (natural CLI usage)
- [x] First test file: `internal/invite/code_test.go` — round-trip, invalid input, and trailing junk rejection tests

---

### Phase 4C: Core Hardening & Security

**Timeline**: 6-8 weeks (batched)
**Status**: ✅ Batches A–G Complete (6 items deferred to future batches)

**Goal**: Harden every component for production reliability. Fix critical security gaps, add self-healing resilience, implement test coverage, and make the system recover from failures automatically — before wider distribution puts binaries in more hands.

**Rationale**: The relay is a public-facing VPS with no resource limits. There are near-zero tests. Connections don't survive relay restarts. A bad config change on the relay can lock you out permanently. These are unacceptable for a mission-critical system that people depend on for remote access. Industry practice for hardened infrastructure (Juniper, Cisco, Kubernetes, systemd) demands: validated configs, automatic recovery, resource isolation, and health monitoring.

**Implementation Order** (batched for incremental value):
| Batch | Focus | Key Items |
|-------|-------|-----------|
| A | **Reliability** | Reconnection with backoff, TCP dial timeout, DHT in proxy, integration tests | ✅ DONE |
| B | **Code Quality** | Proxy dedup, structured logging (`log/slog`), sentinel errors, build version embedding | ✅ DONE |
| C | **Self-Healing** | Config validation/archive/rollback, commit-confirmed, systemd watchdog | ✅ DONE |
| D | **libp2p Features** | AutoNAT v2, smart dialing, QUIC preferred, version in Identify | ✅ DONE |
| E | **New Capabilities** | `peerup status`, `/healthz` endpoint, headless invite/join, UserAgent fix | ✅ DONE |
| F | **Daemon Mode** | `peerup daemon`, Unix socket API, ping/traceroute/resolve, dynamic proxies | ✅ DONE |
| G | **Test Coverage & Documentation** | 80.3% combined coverage, Docker integration tests, relay merge, engineering journal, website | ✅ DONE |
| H | **Observability** | OpenTelemetry, metrics, audit logging, trace IDs |

**Deliverables**:

**Security (Critical)**:
- [x] Relay resource limits — replace `WithInfiniteLimits()` with configurable `WithResources()` + `WithLimit()`. Defaults tuned for SSH/XRDP (10min sessions, 64MB data). Configurable via `resources:` section in relay-server.yaml.
- [x] Auth hot-reload — daemon API `POST /v1/auth` and `DELETE /v1/auth/{peer_id}` reload `authorized_keys` at runtime. `GaterReloader` interface updates ConnectionGater in-place. *(Batch F)*
- [ ] Per-service access control — allow granting specific peers access to specific services only. Critical when home node acts as LAN gateway (e.g., `local_address: "192.168.0.5:22"` exposes another machine's SSH). Config supports per-service `authorized_keys` override. CLI: `peerup service acl <name> add/remove <peer-id>`. Without this, every authorized peer can reach every service.
- [ ] Rate limiting on incoming connections and streams — leverage go-libp2p's built-in per-IP rate limiting (1 connection per 5s default, 16-burst). Add per-peer stream throttling.
- [ ] QUIC source address verification — validate peer source IPs aren't spoofed, prevents relay from being used as DDoS reflector (built into quic-go v0.54.0+)
- [ ] OS-level rate limiting — iptables/nftables rules in `setup.sh` (SYN flood protection, `--connlimit-above` per source IP)
- [x] Config file permissions — write with 0600 (not 0644) *(done in Phase 4B)*
- [x] Key file permission check on load — refuse to load keys with permissions wider than 0600 (actionable error message with `chmod` fix)
- [x] Service name validation — DNS-label format enforced (1-63 lowercase alphanumeric + hyphens), prevents protocol ID injection
- [x] Relay address validation in `peerup init` — parse multiaddr before writing config *(done in Phase 4B)*

**libp2p Upgrade (Critical)**:
- [x] Upgrade main module go-libp2p to latest — gains AutoNAT v2, smart dialing, QUIC improvements, Resource Manager, per-IP rate limiting, source address verification *(already on v0.47.0)*
- [x] Upgrade relay-server go-libp2p to match main module *(v0.38.2 → v0.47.0, done via `go work sync`)*
- [x] Enable AutoNAT v2 — per-address reachability testing (know which specific addresses are publicly reachable; distinguish IPv4 vs IPv6 NAT state). Includes nonce-based dial verification and amplification attack prevention. *(Batch D)*
- [x] Enable smart dialing — address ranking, QUIC prioritization, sequential dial with fast failover (reduces connection churn vs old parallel-dial-all approach) *(built into v0.47.0; transport ordering set QUIC-first)*
- [x] QUIC as preferred transport — 1 fewer RTT on connection setup (3 RTTs vs 4 for TCP), native multiplexing, better for hole punching *(Batch D — transport order: QUIC → TCP → WebSocket)*
- [x] Version in Identify — `libp2p.UserAgent("peerup/<version>")` and `libp2p.UserAgent("relay-server/<version>")` set on all hosts. Peers exchange version info via Identify protocol. Integration test verifies exchange. *(Batch D)*
- [x] Private DHT — migrated from IPFS Amino DHT (`/ipfs/kad/1.0.0`) to private peerup DHT (`/peerup/kad/1.0.0`). All 3 `dht.New()` calls in peerup + relay-server now use `dht.ProtocolPrefix("/peerup")`. Relay server runs DHT in server mode as the bootstrap peer. No more polluting the IPFS routing table or getting rejected by ConnectionGater. *(Post-Batch F)*

**Self-Healing & Resilience** (inspired by Juniper JunOS, Cisco IOS, Kubernetes, systemd, MikroTik):
- [x] **Config validation command** — `peerup config validate` parses config, checks key file exists, verifies relay address reachable, dry-run before applying. Also validates relay config. *(Batch C)*
- [x] **Config archive** — `internal/config/archive.go` auto-saves last-known-good config (`.config.last-good.yaml`) on successful serve startup. Atomic write with temp+rename. *(Batch C)*
- [x] **Config rollback** — `peerup config rollback` restores from last-known-good archive. *(Batch C)*
- [x] **Commit-confirmed pattern** (Juniper JunOS / Cisco IOS) — `peerup config apply <new-config> --confirm-timeout 5m` applies a config change and auto-reverts if not confirmed via `peerup config confirm`. **Prevents permanent lockout on remote relay.** `internal/config/confirm.go` implements `ApplyCommitConfirmed()` and `EnforceCommitConfirmed()`. *(Batch C)*
- [x] **systemd watchdog integration** — `internal/watchdog/watchdog.go` sends `sd_notify("WATCHDOG=1")` every 30s with health check. `Ready()`, `Stopping()`, `Watchdog()` messages. Integrated into `serve_common.go`. Extended with Unix socket health check in Batch F. *(Batch C)*
- [x] **Health check HTTP endpoint** — relay exposes `/healthz` on a configurable port (default: disabled, `127.0.0.1:9090`). Returns JSON: peer ID, version, uptime, connected peers count, protocol count. Used by monitoring (Prometheus, UptimeKuma). *(Batch E)*
- [x] **`peerup status` command** — show local config at a glance: version, peer ID, config path, relay addresses, authorized peers, services, names. No network required — instant. *(Batch E)*

**Auto-Upgrade Groundwork** (full implementation in Phase 4E):
- [x] **Build version embedding** — compile with `-ldflags "-X main.version=..."` so every binary knows its version. `peerup version` / `peerup --version` and `relay-server version` / `relay-server --version` print build version, commit hash, build date, and Go version. Version printed in relay-server startup banner. `setup.sh` injects version from git at build time.
- [x] **Version in libp2p Identify** — set `UserAgent` to `peerup/<version>` in libp2p host config. Peers learn each other's versions automatically on connect (no new protocol needed). *(Batch D — serve/proxy/ping; Batch E — invite/join)*
- [x] **Protocol versioning policy** — documented in engineering journal (ADR-D03). Wire protocols (`/peerup/proxy/1.0.0`) are backwards-compatible within major version. Version info exchanged via libp2p Identify UserAgent.

**Automation & Integration**:
- [x] **Daemon mode** — `peerup daemon` runs in foreground (systemd/launchd managed), exposes Unix socket API (`~/.config/peerup/peerup.sock`) with cookie-based auth. JSON + plain text responses. 14 endpoints: status, peers, services, auth (add/remove/hot-reload), ping, traceroute, resolve, connect/disconnect (dynamic proxies), expose/unexpose, shutdown. CLI client auto-reads cookie. *(Batch F)*
- [x] **Headless onboarding** — `peerup invite --non-interactive` skips QR, prints bare code to stdout, progress to stderr. `peerup join --non-interactive` reads invite code from CLI arg, `PEERUP_INVITE_CODE` env var, or stdin. No TTY prompts. Essential for containerized and automated deployments (Docker, systemd, scripts). *(Batch E)*

**Reliability**:
- [x] Reconnection with exponential backoff — `DialWithRetry()` wraps proxy dial with 3 retries (1s → 2s → 4s) to recover from transient relay drops
- [ ] Connection warmup — pre-establish connection to target peer at `peerup proxy` startup (eliminates 5-15s per-session setup latency)
- [ ] Stream pooling — reuse streams instead of creating fresh ones per TCP connection (eliminates per-connection protocol negotiation)
- [x] Persistent relay reservation — `serve_common.go` keeps reservation alive with periodic `circuitv2client.Reserve()` at `cfg.Relay.ReservationInterval`. Runs as background goroutine during daemon lifetime.
- [x] DHT bootstrap in proxy command — Kademlia DHT (client mode) bootstrapped at proxy startup. Async `FindPeer()` discovers target's direct addresses, enabling DCUtR hole-punching (~70% bypass relay entirely).
- [x] Graceful shutdown — replace `os.Exit(0)` with proper cleanup, context cancellation stops background goroutines
- [x] Goroutine lifecycle — use `time.Ticker` + `select ctx.Done()` instead of bare `time.Sleep` loops
- [x] TCP dial timeout — `net.DialTimeout("tcp", addr, 10s)` for local service connections (serve side and proxy side). `ConnectToService()` uses 30s context timeout for P2P stream dial.
- [x] Fix data race in bootstrap peer counter (`atomic.Int32`)

**Observability** (Batch H):
- [ ] OpenTelemetry integration — instrument key paths with traces and metrics (invite/join flow, proxy setup, relay connection). Users pick their backend (Jaeger, Honeycomb, Prometheus, etc.)
- [ ] Metrics export — peer count, proxy throughput, relay latency, connection counts, stream utilization
- [ ] Connection quality scoring — per-path metrics (latency, jitter, throughput, stability) for direct, relayed, and multi-relay paths. Exposed via `peerup status --health` and daemon API
- [ ] Hole-punch success tracking — record success/failure/elapsed for every DCUtR attempt. Aggregate into `peerup status` summary (success rate, average RTT, failure reasons). Feeds connection quality scoring
- [ ] Audit logging — every peer auth decision logged with peer ID, action, timestamp, result (structured JSON for SIEM integration)
- [ ] Trace correlation IDs — propagate through relay path for debugging multi-hop connections

**Relay Decentralization** (future — after Batch H observability provides the data needed):
- [ ] `require_auth` relay service — enable Circuit Relay v2 service on home nodes with `require_auth: true` (only authorized peers can reserve). Config: `relay_service.enabled`, `relay_service.require_auth`, `relay_service.resources.*`. ConnectionGater enforces auth before relay protocol runs
- [ ] DHT-based relay discovery — authorized relays advertise on DHT under well-known CID. NATted nodes discover peer relays via AutoRelay. No central endpoint
- [ ] Multi-relay failover — try multiple known relays in order; health-aware selection based on connection quality scores from observability data
- [ ] Bootstrap decentralization — hardcoded seed peers in binary (ultimate fallback) → DNS seeds at `peerup.dev` → DHT peer exchange → fully self-sustaining. Same pattern as Bitcoin
- [ ] **End goal**: Relay VPS becomes **obsolete** — not just optional. Every publicly-reachable peer-up node relays for its authorized peers. No special nodes, no central coordination

**Module Consolidation** (completed — single Go module):
- [x] Merged three Go modules (main, relay-server, cmd/keytool) into a single `go.mod`
- [x] Deleted `go.work` — no workspace needed with one module
- [x] Moved relay-server source from `relay-server/main.go` to `cmd/relay-server/main.go`; `relay-server/` is now a deployment directory (setup.sh, configs, systemd)
- [x] Extracted `internal/identity/` package (from `pkg/p2pnet/identity.go`) — `CheckKeyFilePermissions()`, `LoadOrCreateIdentity()`, `PeerIDFromKeyFile()` shared by peerup and relay-server
- [x] Extracted `internal/validate/` package — `ServiceName()` for DNS-label validation of service names
- [x] Deleted `cmd/keytool/` entirely — all features exist in `peerup` subcommands (`whoami`, `auth add/list/remove/validate`)
- [x] Added `peerup auth validate` (ported from keytool validate)
- [x] CI simplified to `go build ./...`, `go vet ./...`, `go test -race -count=1 ./...` from project root

**Pre-Refactoring Foundation** (completed before main 4C work):
- [x] GitHub Actions CI — build, vet, and test on every push to `main` and `dev/next-iteration`
- [x] Config version field — `version: 1` in all configs; loader defaults missing version to 1, rejects future versions. Enables safe schema migration.
- [x] Unit tests for config package — loader, validation, path resolution, version handling, relay config
- [x] Unit tests for auth package — gater (inbound/outbound/update), authorized_keys (load/parse/comments), manage (add/remove/list/duplicate/sanitize)
- [x] Integration tests — in-process libp2p hosts verify real stream connectivity, half-close semantics, P2P-to-TCP proxy, and `DialWithRetry` behavior (6 tests in `pkg/p2pnet/integration_test.go`)

**Batch A — Reliability** (completed):
- [x] `DialWithRetry()` — exponential backoff retry (1s → 2s → 4s) for proxy dial
- [x] TCP dial timeout — 10s for local service, 30s context for P2P stream
- [x] DHT bootstrap in proxy command — Kademlia DHT (client mode) for direct peer discovery
- [x] `[DIRECT]`/`[RELAYED]` connection path indicators in logs (checks `RemoteMultiaddr()` for `/p2p-circuit`)
- [x] DCUtR hole-punch event tracer — logs hole punch STARTED/SUCCEEDED/FAILED and direct dial events

**Batch B — Code Quality** (completed):
- [x] Deduplicated bidirectional proxy — `BidirectionalProxy()` + `HalfCloseConn` interface (was 4 copies, now 1)
- [x] Sentinel errors — 8 sentinel errors across 4 packages, all using `%w` wrapping for `errors.Is()`
- [x] Build version embedding — `peerup version`, `relay-server version`, ldflags injection in setup.sh
- [x] Structured logging with `log/slog` — library code migrated (~20 call sites), CLI output unchanged

**Batch E — New Capabilities** (completed):
- [x] `peerup status` — local-only info command (version, peer ID, config, relays, authorized peers, services, names)
- [x] `/healthz` HTTP endpoint on relay-server — JSON health check for monitoring (disabled by default, binds `127.0.0.1:9090`)
- [x] `peerup invite --non-interactive` — bare invite code to stdout, progress to stderr, skip QR
- [x] `peerup join --non-interactive` — reads code from CLI arg, `PEERUP_INVITE_CODE` env var, or stdin
- [x] UserAgent fix — added `peerup/<version>` UserAgent to invite/join hosts (was missing from Batch D)

**Batch F — Daemon Mode** (completed):
- [x] `peerup daemon` — long-running P2P host with Unix socket HTTP API
- [x] Cookie-based authentication (32-byte random hex, `0600` permissions, rotated per restart)
- [x] 14 API endpoints with JSON + plain text format negotiation (`?format=text` / `Accept: text/plain`)
- [x] `serve_common.go` — extracted shared P2P runtime (zero duplication between serve and daemon)
- [x] Auth hot-reload — `POST /v1/auth` and `DELETE /v1/auth/{peer_id}` take effect immediately
- [x] Dynamic proxy management — create/destroy TCP proxies at runtime via API
- [x] P2P ping — standalone (`peerup ping`) + daemon API, continuous/single-shot, stats summary
- [x] P2P traceroute — standalone (`peerup traceroute`) + daemon API, DIRECT vs RELAYED path analysis
- [x] P2P resolve — standalone (`peerup resolve`) + daemon API, name → peer ID
- [x] Stale socket detection (dial test, no PID files)
- [x] Daemon client library (`internal/daemon/client.go`) with auto cookie reading
- [x] CLI client commands: `peerup daemon status/stop/ping/services/peers/connect/disconnect`
- [x] Service files: `deploy/peerup-daemon.service` (systemd) + `deploy/com.peerup.daemon.plist` (launchd)
- [x] Watchdog extended with Unix socket health check
- [x] Tests: auth middleware, handlers, lifecycle, stale socket, integration, ping stats
- [x] Documentation: `docs/DAEMON-API.md` (full API reference), `docs/NETWORK-TOOLS.md` (diagnostic commands)

**Batch G — Test Coverage & Documentation** (completed):

Combined coverage: **80.3%** (unit + Docker integration). Relay-server binary merged into peerup (commit 5d167b3).

Priority areas (all hit or exceeded targets):
- [x] **cmd/peerup** (4% → 80%+) — 96 test functions covering CLI commands, flag handling, config template, daemon lifecycle, error paths. Relay serve commands merged and tested. *(relay-server binary merged into peerup)*
- [x] **internal/daemon** (12% → 70%+) — all 14 API handlers tested (status, ping, traceroute, resolve, connect/disconnect, auth CRUD, services, shutdown), format negotiation, cookie auth, proxy lifecycle, client library
- [x] **pkg/p2pnet** (23% → 84%) — naming, service registry, proxy half-close, relay address parsing, identity, ping, traceroute
- [x] **internal/config** (48% → 75%+) — archive/rollback, commit-confirmed timer, loader edge cases, benchmark tests
- [x] **internal/auth** (50% → 75%+) — hot-reload, concurrent access, malformed input, gater tests
- [x] **Docker integration tests** — `test/docker/integration_test.go` with relay container, invite/join, ping through circuit. Coverage-instrumented via `test/docker/coverage.sh`
- [x] **CI coverage reporting** — `.github/workflows/pages.yaml` merges unit + Docker coverage via `go tool covdata merge`, reports combined coverage
- [x] **Engineering journal** ([`docs/ENGINEERING-JOURNAL.md`](ENGINEERING-JOURNAL.md)) — 28 architecture decision records (ADRs) covering core architecture (8) and all batches A-G. Not a changelog — documents *why* every design choice was made, what alternatives were considered, and what trade-offs were accepted.
- [x] **Website** — Hugo + Hextra site scaffolded with landing page, 7 retroactive blog posts (Batches A-G), sync-docs.sh for auto-transformation, GitHub Actions CI/CD for GitHub Pages deployment
- [x] **Security hardening** — post-audit fixes across 10 files (commit 83d02d3). CVE-2026-26014 resolved (pion/dtls v3.1.2). CI Actions pinned to commit SHAs.

**Service CLI** (completed — completes the CLI config management pattern):
- [x] `peerup service add <name> <address>` — add a service (enabled by default), optional `--protocol` flag
- [x] `peerup service remove <name>` — remove a service from config
- [x] `peerup service enable <name>` — enable a disabled service
- [x] `peerup service disable <name>` — disable a service without removing it
- [x] `peerup service list` — list configured services with status
- [x] All config sections (auth, relay, service) now manageable via CLI — no YAML editing required
- [x] `local_address` can point to any reachable host (e.g., `192.168.0.5:22`) — home node acts as LAN gateway

**Code Quality**:
- [x] Expand test coverage — 80.3% combined coverage. Naming, proxy, invite edge cases, relay input parsing all tested. *(Batch G)*
- [x] Structured logging — migrated library code (`pkg/p2pnet/`, `internal/auth/`) to `log/slog` with structured key-value fields and log levels (Info/Warn/Error). CLI commands remain `fmt.Println` for user output. *(Batch B)*
- [x] Sentinel errors — defined `ErrServiceAlreadyRegistered`, `ErrNameNotFound`, `ErrPeerAlreadyAuthorized`, `ErrPeerNotFound`, `ErrInvalidPeerID`, `ErrConfigNotFound`, `ErrConfigVersionTooNew`, `ErrInvalidServiceName` across 4 error files. All wrapped with `fmt.Errorf("%w: ...")` for `errors.Is()` support. *(Batch B)*
- [x] Deduplicate proxy pattern — extracted `BidirectionalProxy()` with `HalfCloseConn` interface and `tcpHalfCloser` adapter (was copy-pasted 4x, now single ~30-line function). *(Batch B)*
- [x] Consolidate config loaders — unified `LoadNodeConfig()` delegates to `LoadHomeNodeConfig()`, `LoadClientNodeConfig()` also delegates. Single `NodeConfig` struct.
- [x] Health/status endpoint — `/healthz` on relay (Batch E), `peerup status` (Batch E), daemon API `/v1/status` (Batch F) expose connection state, relay status, active streams.

**Industry References**:
- **Juniper JunOS `commit confirmed`**: Apply config, auto-revert if not confirmed. Standard in network equipment for 20+ years. Prevents lockout on remote devices — identical problem to a remote relay server.
- **Cisco IOS `configure replace`**: Atomic config replacement with automatic rollback on failure.
- **MikroTik Safe Mode**: Track all changes since entering safe mode; revert everything if connection drops.
- **Kubernetes liveness/readiness probes**: Health endpoints that trigger automatic restart on failure.

**libp2p Specification References**:
- **Circuit Relay v2**: [Specification](https://github.com/libp2p/specs/blob/master/relay/circuit-v2.md) — reservation-based relay with configurable resource limits
- **DCUtR**: [Specification](https://github.com/libp2p/specs/blob/master/relay/DCUtR.md) — Direct Connection Upgrade through Relay (hole punching coordination)
- **AutoNAT v2**: [Specification](https://github.com/libp2p/specs/blob/master/autonat/autonat-v2.md) — per-address reachability testing with amplification prevention
- **Hole Punching Measurement**: [Study](https://arxiv.org/html/2510.27500v1) — 4.4M traversal attempts, 85K+ networks, 167 countries, ~70% success rate
- **systemd WatchdogSec**: Process heartbeat — if the process stops responding, systemd restarts it. Used by PostgreSQL, nginx, and other production services.
- **Caddy atomic reload**: Start new config alongside old; if new config fails, keep old. Zero-downtime config changes.

---

### Phase 4D: Plugin Architecture, SDK & First Plugins

**Timeline**: 3-4 weeks
**Status**: 📋 Planned

**Goal**: Make peer-up extensible by third parties — and prove the architecture works by shipping real plugins: file transfer, service templates, and Wake-on-LAN. The plugins ARE the SDK examples.

**Rationale**: A solo developer can't build everything. Interfaces and hooks let the community add auth backends, name resolvers, service middleware, and monitoring — without forking. But empty interfaces are worthless: shipping real plugins alongside the architecture validates the design immediately and catches interface mistakes before third parties discover them. File sharing is the perfect first plugin — universal use case, builds on existing streams, proves the full `ServiceManager` lifecycle.

**Deliverables**:

**Core Interfaces** (new file: `pkg/p2pnet/interfaces.go`):
- [ ] `PeerNetwork` — interface for core network operations (expose, connect, resolve, close)
- [ ] `Resolver` — interface for name resolution (resolve, register). Enables chaining: local → DNS → DHT → blockchain
- [ ] `ServiceManager` — interface for service registration and dialing. Enables middleware.
- [ ] `Authorizer` — interface for authorization decisions. Enables pluggable auth (certs, tokens, database)
- [ ] `Logger` — interface for structured logging injection

**Extension Points**:
- [ ] Constructor injection — `Network.Config` accepts optional `Resolver`, `ConnectionGater`, `Logger`
- [ ] Event hook system — `OnEvent(handler)` for peer connected/disconnected, auth allow/deny, service registered, stream opened
- [ ] Stream middleware — `ServiceRegistry.Use(middleware)` for compression, bandwidth limiting, audit trails
- [ ] Protocol ID formatter — configurable protocol namespace and versioning

**Library Consolidation**:
- [ ] Extract DHT/relay bootstrap from CLI into `pkg/p2pnet/bootstrap.go`
- [ ] Centralize orchestration — new commands become ~20 lines instead of ~200
- [ ] Package-level documentation for `pkg/p2pnet/`

**Built-in Plugin: File Transfer** (proves `ServiceManager` + stream middleware):
- [ ] `peerup send <file> --to <peer>` — send a file to an authorized peer
- [ ] `peerup receive` — listen for incoming file transfers
- [ ] Auto-accept from authorized peers (configurable)
- [ ] Progress bar and transfer speed display (stream middleware)
- [ ] Resume interrupted transfers
- [ ] Directory transfer support (`peerup send ./folder --to laptop`)

**Built-in Plugin: Service Templates** (proves `ServiceManager` + health middleware):
- [ ] `peerup daemon --ollama` shortcut (auto-detects Ollama on localhost:11434)
- [ ] `peerup daemon --vllm` shortcut (auto-detects vLLM on localhost:8000)
- [ ] Health check middleware — verify local service is reachable before exposing
- [ ] Streaming response verification (chunked transfer for LLM output)

**Built-in Plugin: Wake-on-LAN** (proves event hooks + new protocol):
- [ ] `peerup wake <peer>` — send magic packet before connecting
- [ ] Event hook: auto-wake peer on connection attempt (optional)

**Service Discovery Protocol**:
- [ ] New protocol `/peerup/discovery/1.0.0` — query a remote peer for their exposed services
- [ ] Response includes service names and optional tags (e.g., `gpu`, `storage`, `inference`)
- [ ] `peerup discover <peer>` CLI command — list services offered by a peer
- [ ] Service tags in config: `tags: [gpu, inference]` — categorize services for discovery

**Python SDK** (`peerup-sdk`):
- [ ] Thin wrapper around daemon Unix socket API (14 endpoints already implemented in Batch F)
- [ ] `pip install peerup-sdk`
- [ ] Core operations: connect, expose_service, discover_services, proxy, status
- [ ] Async support (asyncio) for integration with event-driven applications
- [ ] Example: connect to a remote service in <10 lines of Python

**Headless Onboarding Enhancements**:
- [x] `peerup invite --non-interactive` — bare code to stdout, no QR, progress to stderr *(Phase 4C Batch E)*
- [x] `peerup join --non-interactive` — reads code from CLI arg, `PEERUP_INVITE_CODE` env var, or stdin *(Phase 4C Batch E)*
- [x] Docker-friendly: `PEERUP_INVITE_CODE=xxx peerup join --non-interactive --name node-1` *(Phase 4C Batch E)*

**SDK Documentation** (the plugins above ARE the examples):
- [ ] `docs/SDK.md` — guide for building on `pkg/p2pnet`
- [ ] Example walkthrough: how file transfer was built as a plugin
- [ ] Example walkthrough: how service templates use health middleware
- [ ] Example: custom name resolver plugin
- [ ] Example: auth middleware (rate limiting, logging)

**Plugin Interface Preview**:
```go
// Third-party resolver
type DNSResolver struct { ... }
func (r *DNSResolver) Resolve(name string) (peer.ID, error) { ... }

// Third-party auth
type DatabaseAuthorizer struct { ... }
func (a *DatabaseAuthorizer) IsAuthorized(p peer.ID) bool { ... }

// Wire it up
net, _ := p2pnet.New(&p2pnet.Config{
    Resolver:        &DNSResolver{},
    ConnectionGater: &DatabaseAuthorizer{},
    Logger:          slog.Default(),
})

// React to events
net.OnEvent(func(e p2pnet.Event) {
    if e.Type == p2pnet.EventPeerConnected {
        metrics.PeerConnections.Inc()
    }
})
```

**File Transfer Usage**:
```bash
# Send a file
$ peerup send photo.jpg --to laptop
Sending photo.jpg (4.2 MB) to laptop...
████████████████████████████ 100% — 4.2 MB/s
✓ Transfer complete

# Send to multiple peers
$ peerup send presentation.pdf --to home --to phone

# Receive mode (optional — auto-accept if peer is authorized)
$ peerup receive --save-to ~/Downloads/
Waiting for transfers...
```

---

### Phase 4E: Distribution & Launch

**Timeline**: 1-2 weeks
**Status**: 📋 Planned

**Goal**: Make peer-up installable without a Go toolchain, launch with compelling use-case content, and establish `peerup.dev` as the stable distribution anchor — independent of any single hosting provider.

**Rationale**: High impact, low effort. Prerequisite for wider adoption. GPU inference, game streaming, and IoT use cases already work — they just need documentation and a distribution channel. The domain `peerup.dev` is the one thing no third party can take away — every user-facing URL routes through it, never hardcoded to `github.com` or any other host.

**Deliverables**:

**Website & Documentation (peerup.dev)**:
- [x] Static documentation site built with [Hugo](https://gohugo.io/) + [Hextra](https://imfing.github.io/hextra/) theme — Go-based SSG, fast builds, matches the project toolchain, built-in search and dark mode
- [x] Automated docs sync (`website/sync-docs.sh`) — transforms `docs/*.md` into Hugo-ready content with front matter and link rewriting
- [x] Elegant landing page with visual storytelling — hero with problem-first hook, terminal demo section, 3-step "How It Works" grid, network diagram, tabbed install commands (macOS/Linux/source), bottom CTA grid *(enhanced post-Batch G)*
- [x] Seven retroactive blog posts for Batches A-G (outcomes-focused)
- [x] GitHub Actions CI/CD — build Hugo site and deploy to GitHub Pages on every push to `main`
- [x] GitHub Pages hosting with custom domain (`peerup.dev`) — DNS on Cloudflare, CNAME deployed, site live *(2026-02-20)*
- [x] DNS managed on Cloudflare — A/AAAA records → GitHub Pages, Cloudflare proxy enabled (CDN + DDoS protection), SSL mode "Full" *(2026-02-20)*
- [ ] CNAME `get.peerup.dev` → serves install script
- [x] Landing page — hero section, feature grid (NAT traversal, single binary, SSH trust, 60s pairing, TCP proxy, self-healing) *(Batch G)*
- [x] Existing docs rendered as site pages — `sync-docs.sh` transforms ARCHITECTURE, FAQ, TESTING, ROADMAP, DAEMON-API, NETWORK-TOOLS, ENGINEERING-JOURNAL into Hugo-ready content *(Batch G)*
- [x] Custom blog listing template — image cards with title overlay, gradient, responsive grid *(post-Batch G)*
- [x] Dark theme default + theme toggle in navbar *(post-Batch G)*
- [x] SVG images for terminal demo, how-it-works steps, network diagram *(post-Batch G)*
- [x] 11 SVG diagrams in documentation — replacing ASCII art in Architecture (7), FAQ (2), Network Tools (1), Daemon API (1) *(post-Batch G)*
- [x] Feature card icons (Heroicons), section title icons, doc index icons, about page icons *(post-Batch G)*
- [x] Doc sidebar reordered for user journey: Quick Start → Network Tools → FAQ → Trust & Security → Daemon API → Architecture → Roadmap → Testing → Engineering Journal *(post-Batch G)*
- [ ] `pkg/p2pnet` library reference (godoc-style or hand-written guides)
- [ ] Use-case guides integrated into the site (GPU inference, IoT, game servers — see Launch Content below)
- [ ] Install page with platform-specific instructions (curl, brew, apt, Docker, source)
- [x] Blog section — 7 retroactive blog posts for Batches A-G (outcomes-focused) *(Batch G)*

**AI-Agent Discoverability ([llms.txt](https://llmstxt.org/) spec)**:
- [x] `/llms.txt` — markdown index of the project: name, summary, links to detailed doc pages. ~200 tokens for an AI agent to understand the entire project. Hand-crafted static file in `website/static/llms.txt`. *(2026-02-20)*
- [x] `/llms-full.txt` — all site content concatenated into a single markdown file (243KB). Auto-generated by `sync-docs.sh` from README + all docs. One URL paste gives an AI agent full project context. *(2026-02-20)*
- [ ] `.md` variants of every page — any page URL + `.md` suffix returns clean markdown (Hugo already has the source, just serve it as a static file alongside the HTML)
- [ ] Adopted by 600+ sites including Anthropic, Cloudflare, Stripe, Cursor, Hugging Face
- [ ] **WebMCP** ([Google + Microsoft, W3C](https://developer.chrome.com/blog/webmcp-epp)) — watch for future relevance. Protocol for AI agents to *interact* with websites via structured tool contracts (Declarative API for HTML forms, Imperative API for JS). Early preview in Chrome 146 Canary (Feb 2026). Not immediately relevant for a docs site, but valuable if peerup.dev adds interactive features (e.g., invite code generator, service discovery dashboard)

**Release Manifest & Upgrade Endpoint**:
- [ ] CI generates static `releases/latest.json` on every tagged release — deployed as part of the Hugo site
- [ ] Manifest contains version, commit, date, checksums, and per-platform download URLs for all mirrors:
  ```json
  {
    "version": "1.2.0",
    "commit": "abc1234",
    "date": "2026-03-15",
    "binaries": {
      "linux-amd64": {
        "github": "https://github.com/.../peerup-linux-amd64.tar.gz",
        "gitlab": "https://gitlab.com/.../peerup-linux-amd64.tar.gz",
        "ipfs": "bafybeiabc123...",
        "sha256": "..."
      }
    }
  }
  ```
- [ ] `peerup upgrade` fetches `peerup.dev/releases/latest.json` (not GitHub API directly)
- [ ] Install script fetches the same manifest — one source of truth for all consumers
- [ ] Fallback order in binary and install script: GitHub → GitLab → IPFS gateway

**Distribution Resilience** (gradual rollout):

The domain (`peerup.dev`) is the anchor. DNS is on Cloudflare under our control. Every user-facing URL goes through the domain, never directly to a third-party host. If any host disappears, one DNS record change restores service.

| Layer | GitHub (primary) | GitLab (mirror) | IPFS (fallback) |
|-------|-----------------|-----------------|-----------------|
| Source code | Primary repo | Push-hook mirror | — |
| Release binaries | GitHub Releases | GitLab Releases (GoReleaser) | Pinned on Filebase |
| Static site | GitHub Pages | GitLab Pages | Pinned + DNSLink ready |
| DNS failover | CNAME → GitHub Pages | Manual flip to GitLab Pages | Manual flip to Cloudflare IPFS gateway |

Rollout phases:
1. **Phase 1**: GitHub Pages only. CNAME `peerup.dev` → GitHub. Simple, free, fast.
2. **Phase 2**: Mirror site + releases to GitLab Pages + GitLab Releases. Same Hugo CI. Manual DNS failover if needed (CNAME swap on Cloudflare).
3. **Phase 3**: IPFS pinning on every release. DNSLink TXT record pre-configured. Nuclear fallback if both GitHub and GitLab die — flip CNAME to Cloudflare IPFS gateway.

Deliverables:
- [ ] Git mirror to GitLab via push hook or CI (source code resilience)
- [ ] GoReleaser config to publish to both GitHub Releases and GitLab Releases
- [ ] GitLab Pages deployment (`.gitlab-ci.yml` for Hugo build)
- [ ] CI step: `ipfs add` release binaries + site → pin on [Filebase](https://filebase.com/) (S3-compatible, 5GB free)
- [ ] DNSLink TXT record at `_dnslink.peerup.dev` pointing to IPNS key (pre-configured, activated on failover)
- [ ] Document failover runbook: which DNS records to change, in what order, for each failure scenario

**Package Managers & Binaries**:
- [ ] Set up [GoReleaser](https://goreleaser.com/) config (`.goreleaser.yaml`) — publish to GitHub Releases + GitLab Releases
- [ ] GitHub Actions workflow: on tag push, build binaries for Linux/macOS/Windows (amd64 + arm64)
- [ ] Publish to GitHub Releases with Ed25519-signed checksums (release key in repo)
- [ ] Homebrew tap: `brew install satindergrewal/tap/peerup`
- [ ] One-line install script: `curl -sSL get.peerup.dev | sh` — fetches `releases/latest.json`, detects OS/arch, downloads binary (GitHub → GitLab → IPFS fallback), verifies checksum, installs to `~/.local/bin` or `/usr/local/bin`
- [ ] APT repository for Debian/Ubuntu
- [ ] AUR package for Arch Linux
- [ ] Docker image + `docker-compose.yml` for containerized deployment

**Embedded / Router Builds** (OpenWRT, Ubiquiti, GL.iNet, MikroTik):
- [ ] GoReleaser build profiles: `default` (servers/desktops, `-ldflags="-s -w"`, ~25MB) and `embedded` (routers, + UPX compression, ~8MB)
- [ ] Cross-compilation targets: `linux/mipsle` (OpenWRT), `linux/arm/v7` (Ubiquiti EdgeRouter, Banana Pi), `linux/arm64` (modern routers)
- [ ] Optional build tag `//go:build !webrtc` to exclude WebRTC/pion (~2MB savings) for router builds
- [ ] OpenWRT `.ipk` package generation for opkg install
- [ ] Guide: *"Running peer-up on your router"* — OpenWRT, Ubiquiti EdgeRouter, GL.iNet travel routers
- [ ] Binary size budget: default ≤25MB stripped, embedded ≤10MB compressed. Current: 34MB full → 25MB stripped → ~8MB UPX.

**Auto-Upgrade** (builds on commit-confirmed pattern from Phase 4C):
- [ ] `peerup upgrade --check` — fetch `peerup.dev/releases/latest.json`, compare version with running binary, show changelog
- [ ] `peerup upgrade` — download binary from manifest (GitHub → GitLab → IPFS fallback), verify Ed25519 checksum, replace binary, restart. Manual confirmation required.
- [ ] `peerup upgrade --auto` — automatic upgrade via systemd timer or cron. Downloads, verifies, applies with commit-confirmed safety:
  1. Rename current binary to `peerup.rollback`
  2. Install new binary, start with `--confirm-timeout 120`
  3. New binary runs health check (relay reachable? peers connectable?)
  4. If healthy → auto-confirm, delete rollback
  5. If unhealthy or no confirmation → systemd watchdog restarts with rollback binary
  6. **Impossible to brick a remote node** — same pattern Juniper has used for 20+ years
- [ ] `relay-server upgrade --auto` — same pattern for relay VPS. Especially critical since relay is remote.
- [ ] Version mismatch warning — when `peerup status` shows peers running different versions, warn with upgrade instructions
- [ ] Relay version announcement — relay broadcasts its version to connected peers via libp2p Identify `UserAgent`. Peers see "relay running v1.2.0, you have v1.1.0, run `peerup upgrade`"

**Use-Case Guides & Launch Content**:
- [ ] Guide: GPU inference — *"Access your home GPU from anywhere through Starlink CGNAT"*
- [ ] Guide: IoT/smart home remote access (Home Assistant, cameras behind CGNAT)
- [ ] Guide: Media server sharing (Jellyfin/Plex with friends via invite flow)
- [ ] Guide: Game server hosting (Minecraft, Valheim through CGNAT)
- [ ] Guide: Game/media streaming (Moonlight/Sunshine tunneling, latency characteristics)
- [ ] Latency/throughput benchmarks (relay vs direct via DCUtR)
- [ ] Multi-GPU / distributed inference documentation (exo, llama.cpp RPC)
- [ ] Blog post / demo: phone → relay → home 5090 → streaming LLM response

**Automation & Integration Guides**:
- [ ] Guide: *"Scripting & Automation with peer-up"* — daemon API, headless onboarding, Python SDK usage
- [ ] Guide: *"Containerized Deployments"* — Docker, env-based config, non-interactive join
- [ ] Docker compose examples for multi-service setups (GPU inference, media server, development environment)
- [ ] Python SDK published to PyPI alongside binary releases

**GPU Inference Config (already works today)**:
```yaml
services:
  ollama:
    enabled: true
    local_address: "localhost:11434"
```

```bash
# Home: peerup daemon
# Remote: peerup proxy home ollama 11434
# Then: curl http://localhost:11434/api/generate -d '{"model":"llama3",...}'
```

**Result**: Zero-dependency install on any platform. Compelling use-case content drives adoption.

---

### Phase 4F: Desktop Gateway Daemon + Private DNS

**Timeline**: 2-3 weeks
**Status**: 📋 Planned

**Goal**: Create multi-mode gateway daemon for transparent service access, backed by a private DNS zone on the relay that is never exposed to the public internet.

**Rationale**: Infrastructure-level features that make peer-up transparent — services accessed via real domain names, no manual proxy commands. The DNS resolver uses the `Resolver` interface from Phase 4D.

**Deliverables**:

**Client-side Gateway**:
- [ ] `cmd/gateway/` - Gateway daemon with multiple modes
- [ ] **Mode 1**: SOCKS5 proxy (localhost:1080)
- [ ] **Mode 2**: Local DNS server (`.p2p` TLD)
- [ ] **Mode 3**: TUN/TAP virtual network interface (requires root)
- [ ] `/etc/hosts` integration for local name overrides
- [ ] Virtual IP assignment (10.64.0.0/16 range)
- [ ] Subnet routing — route entire LAN segments through tunnel (access printers, cameras, IoT without per-device install)
- [ ] Trusted network detection — auto-disable tunneling when already on home LAN

**Relay-side Private DNS** (pluggable `Resolver` backend from 4D):
- [ ] Lightweight DNS zone on the relay server (e.g., CoreDNS or custom)
- [ ] Exposed **only** via P2P protocol — never bound to public UDP/53
- [ ] Relay operator configures a real domain (e.g., `example.com`) pointing to the VPS IP
- [ ] Subdomains (`bob.example.com`, `home.example.com`) assigned on the relay, resolvable only within the P2P network
- [ ] Public DNS returns NXDOMAIN for all subdomains — they don't exist outside the network
- [ ] Gateway daemon queries relay's private DNS as upstream resolver

**Private DNS Architecture**:
```
Public Internet:
  example.com → 123.123.123.123 (relay VPS)    ← public, A record
  bob.example.com → NXDOMAIN                    ← not in public DNS
  home.example.com → NXDOMAIN                   ← not in public DNS

Inside P2P network (via relay's private DNS):
  bob.example.com → Bob's peer ID → Bob's services
  home.example.com → Home's peer ID → SSH, XRDP, Ollama
```

**How it works**:
1. Relay operator owns `example.com`, points it to the relay VPS
2. Relay runs a private DNS zone mapping `<name>.example.com` → peer ID
3. Peers register their friendly name with the relay on connect
4. Client gateway daemon queries the relay's DNS over a P2P stream (not raw UDP)
5. Gateway translates the response into a local DNS answer for the OS
6. Subdomains stay private — no DNS records ever created on public registrars

**Usage Examples**:
```bash
# Mode 1: SOCKS proxy (no root needed)
peerup-gateway --mode socks --port 1080
# Configure apps to use SOCKS proxy

# Mode 2: DNS server (queries relay's private DNS)
peerup-gateway --mode dns --port 53
# Resolves: home.example.com → virtual IP (via relay's private zone)

# Mode 3: Virtual network (requires root)
sudo peerup-gateway --mode tun --network 10.64.0.0/16
# Creates virtual interface, transparent routing
```

**Connection Examples**:
```bash
# After gateway is running:
ssh user@home.example.com        # resolved privately via relay
curl http://bob.example.com:8080 # never touches public DNS
mount -t cifs //home.example.com/media /mnt/media
```

---

### Phase 4G: Mobile Applications

**Timeline**: 3-4 weeks
**Status**: 📋 Planned

**Goal**: Native iOS and Android apps with VPN-like functionality.

**Rationale**: Phone → relay → home GPU is the dream demo. Mobile closes the loop on "access your stuff from anywhere."

**iOS Strategy**:
- **Primary**: NEPacketTunnelProvider (VPN mode)
  - Full TUN interface
  - Virtual network support
  - Frame as "self-hosted personal network" (like WireGuard)
- **Fallback**: SOCKS proxy app (if VPN rejected by Apple)
- **Apple Review Approach**: "Connect to your own devices via relay server"

**Android Strategy**:
- VPNService API (full feature parity)
- TUN interface
- No approval process limitations

**Deliverables**:
- [ ] iOS app with NEPacketTunnelProvider
- [ ] Android app with VPNService
- [ ] Mobile-optimized config UI
- [ ] QR code scanning for `peerup invite` codes
- [ ] Background connection maintenance
- [ ] Battery optimization
- [ ] Per-app SDK for third-party integration

**User Experience**:
```
iOS/Android App Config:
├─ Scan QR Code (from peerup invite)
├─ Or enter invite code: ABCX-7KMN-P2P3
└─ Connect Button

Once connected:
- SSH clients work: ssh user@home
- Browsers work: http://laptop:8080
- Native apps work: Plex connects to home.grewal:32400
- Chat with home LLM via Ollama API
```

---

### Phase 4H: Federation - Network Peering

**Timeline**: 2-3 weeks
**Status**: 📋 Planned

**Goal**: Enable relay-to-relay federation for cross-network communication.

**Rationale**: Only matters once you have multiple users with their own networks. Deferred until adoption features ship first.

**Deliverables**:
- [ ] Relay federation configuration
- [ ] Network-scoped naming (`host.network`)
- [ ] Cross-network routing protocol
- [ ] Trust/authorization between networks
- [ ] Route advertisement and discovery
- [ ] Multi-network client support — single client connected to multiple independent networks simultaneously

**Federation Config Example**:
```yaml
# relay-server.yaml
network:
  name: "grewal"

federation:
  enabled: true
  peers:
    - network_name: "alice"
      relay: "/ip4/45.67.89.12/tcp/7777/p2p/12D3KooW..."
      trust_level: "full"

    - network_name: "bob"
      relay: "/dns4/bob-relay.com/tcp/7777/p2p/12D3KooW..."
      trust_level: "full"

  routing:
    allow_transit: true  # Let alice → bob via your relay
```

**Usage**:
```bash
# From your network, access friend's services:
ssh user@laptop.alice
curl http://desktop.bob:8080
```

**Architecture**:
```
┌─────────────────┐      ┌─────────────────┐      ┌─────────────────┐
│  Your Network   │      │  Alice Network  │      │   Bob Network   │
│    "grewal"     │◄────►│     "alice"     │◄────►│      "bob"      │
│                 │      │                 │      │                 │
│  ├─ laptop      │      │  ├─ desktop     │      │  ├─ server      │
│  └─ relay.      │      │  └─ relay.      │      │  └─ relay.      │
│     grewal      │      │     alice       │      │     bob         │
└─────────────────┘      └─────────────────┘      └─────────────────┘
```

---

### Phase 4I: Advanced Naming Systems (Optional)

**Timeline**: 2-3 weeks
**Status**: 📋 Planned

**Goal**: Pluggable naming architecture supporting multiple backends. Uses the `Resolver` interface from Phase 4D.

**Deliverables**:
- [ ] Built-in resolvers:
  - [ ] Local file (YAML/JSON)
  - [ ] DHT-based (federated)
  - [ ] mDNS (.local)
- [ ] Optional blockchain resolvers:
  - [ ] Ethereum smart contract
  - [ ] Bitcoin OP_RETURN
  - [ ] ENS (.eth domains)
- [ ] IPFS/Arweave archiving for redundancy

**Name Resolution Tiers**:

**Tier 1: Local Override** (Free, Instant)
```yaml
# ~/.peerup/names.yaml
names:
  home: "12D3KooWHome..."
  laptop: "12D3KooWLaptop..."
```

**Tier 2: Network-Scoped** (Free, Federated)
```
Format: <hostname>.<network>
Examples: laptop.grewal, desktop.alice
Resolution: Ask relay for peer ID
```

**Tier 3: Blockchain-Anchored** (Paid, Guaranteed)
```
Register on Ethereum: peerup register grewal --chain ethereum
Cost: ~$10-50 one-time
Format: <hostname>.grewal (globally unique)
```

**Tier 4: Existing Blockchain DNS** (Premium)
```
Use ENS: grewal.eth ($5-640/year)
Format: laptop.grewal.eth
```

---

## Positioning & Community

### Privacy Narrative — peer-up's Moat

peer-up is not a cheaper Tailscale. It's the **self-sovereign alternative** for people who care about owning their network.

> *Comparison based on publicly available documentation as of 2026-02. Details may be outdated — corrections welcome via [GitHub issues](https://github.com/satindergrewal/peer-up/issues).*

| | **peer-up** | **Tailscale** |
|---|---|---|
| **Accounts** | None — no email, no OAuth | Required (Google, GitHub, etc.) |
| **Telemetry** | Zero — no data leaves your network | Coordination server sees device graph |
| **Control plane** | None — relay only forwards bytes | Centralized coordination server |
| **Key custody** | You generate, you store, you control | Keys managed via their control plane |
| **Source** | Fully open, self-hosted | Open source client, proprietary control plane |

> *"Tailscale for people who don't want to trust a company with their network topology."*

### Target Audiences (in order of receptiveness)

1. **r/selfhosted** — Already run services at home, hate port forwarding, value self-sovereignty
2. **Starlink/CGNAT users** — Actively searching for solutions to reach home machines
3. **AI/ML hobbyists** — Home GPU + remote access is exactly their problem
4. **Privacy-conscious developers** — Won't use Tailscale because of the coordination server

### Launch Strategy

1. **Hacker News post**: *"Show HN: peer-up — self-hosted P2P tunnels through Starlink CGNAT (no accounts, no vendor)"*
2. **r/selfhosted post**: Focus on SSH + XRDP + GPU inference through CGNAT
3. **Blog post**: *"Access your home GPU from anywhere through Starlink CGNAT"*
4. **Demo video**: Phone → relay → home 5090 → streaming LLM response
5. **Comparisons**: Honest peer-up vs Tailscale / Zerotier / Netbird posts

### Community Infrastructure (set up at or before launch)

- [ ] **Discord server** — Real-time community channel for support, feedback, development discussion. Link from website nav bar and README
- [ ] **Showcase page** (`/showcase`) — Curated gallery of real-world peer-up deployments. Static JSON data file, rendered as cards. Add when users start sharing their setups (post-launch)
- [ ] **Shoutouts page** (`/shoutouts`) — Testimonials from users. Static JSON, rendered as quote cards with attribution. Add when genuine testimonials exist (post-launch)
- [ ] **Trust & Security page** (`/docs/trust`) — ✅ Created. Threat model, security controls, vulnerability reporting with response SLAs, audit history. Living document, community PRs welcome
- [ ] **Separate `peer-up-trust` repo** — Structured threat model in YAML format (MITRE ATLAS-based). Community can submit PRs to improve threat coverage. Rendered on the website. Fallback: if GitHub goes down, mirror to GitLab (same pattern as code distribution resilience)
- [ ] **Binary verification** — Ed25519-signed checksums + cosign/Sigstore signing for Go binaries. Stronger trust signal than most P2P projects offer
- [ ] **Integrations page** (`/integrations`) — Curated catalog of what works with peer-up: services (Ollama, Jellyfin, Home Assistant, Minecraft, Sunshine/Moonlight), platforms (Docker, systemd, launchd), clients (SSH, XRDP, any TCP). Each entry: name, category, one-liner, config snippet, "works out of the box" badge. Inspired by OpenClaw's integrations page. Add progressively as use-case guides ship.

---

## Phase 5+: Ecosystem & Polish

**Timeline**: Ongoing
**Status**: 📋 Conceptual

**Potential Features**:
- [ ] Web-based dashboard for network management
- [ ] Protocol marketplace (community-contributed service templates)
- [ ] Performance monitoring and analytics (Prometheus metrics)
- [ ] Automatic relay failover/redundancy
- [ ] Bandwidth optimization and QoS per peer/service
- [ ] Multi-relay routing for redundancy
- [ ] Integration with existing VPN clients (OpenVPN, WireGuard)
- [ ] Desktop apps (macOS, Windows, Linux)
- [ ] Browser extension for `.p2p` domain resolution
- [ ] Community relay network
- [ ] IPv6 transport testing and documentation
- [ ] Split tunneling (route only specific traffic through tunnel)
- [ ] Decentralized analytics — on-device network intelligence using statistical anomaly detection (moving average, z-score). No centralized data collection. Each node monitors its own connection quality, predicts relay degradation, and auto-switches paths before failure. Data never leaves the node. Inspired by Nokia AVA's "bring code to where the data is" philosophy. Implementation: gonum for statistics, pure Go, no ML frameworks needed for initial phases

**Protocol & Security Evolution**:
- [ ] MASQUE relay transport ([RFC 9298](https://www.ietf.org/rfc/rfc9298.html)) — HTTP/3 relay alternative to Circuit Relay v2. Looks like standard HTTPS to DPI, supports 0-RTT session resumption for instant reconnection. Could coexist with Circuit Relay v2 as user-selectable relay transport.
- [ ] Post-quantum cryptography — hybrid Noise + ML-KEM ([FIPS 203](https://csrc.nist.gov/pubs/fips/203/final)) handshakes for quantum-resistant key exchange. Implement when libp2p adopts PQC. Design cipher suite negotiation now (cryptographic agility).
- [ ] WebTransport transport — replace WebSocket anti-censorship layer with native QUIC-based WebTransport. Lower overhead, browser-compatible, native datagrams.
- [ ] Zero-RTT proxy connection resume — QUIC session tickets for instant reconnection after network switch (WiFi→cellular). No existing P2P tool provides this.
- [ ] Hardware-backed peer identity — store peer private keys in TPM 2.0 (Linux) or Secure Enclave (macOS/iOS). No existing P2P tool provides this.
- [ ] eBPF/XDP relay acceleration — kernel-bypass packet forwarding for high-throughput relay deployments. DDoS mitigation at millions of packets/sec.
- [ ] W3C DID-compatible identity — export peer IDs in [Decentralized Identifier](https://www.w3.org/TR/did-1.1/) format (`did:key`, `did:peer`) for interoperability with verifiable credential systems.
- [ ] Formal verification of invite/join protocol state machine — mathematically prove correctness of key exchange. Possible with TLA+ model or Kani (Rust).

**Performance & Language**:
- [ ] Selective Rust rewrite of hot paths — proxy loop, relay forwarding, SOCKS5 gateway via FFI. Zero GC, zero-copy, ~1.5x throughput improvement. Evaluate when performance metrics justify it.
- [ ] Rust QUIC library evaluation — [Iroh](https://github.com/n0-computer/iroh) (QUIC multipath, ~90% NAT traversal), [Quinn](https://github.com/quinn-rs/quinn) (pure Rust), [s2n-quic](https://github.com/aws/s2n-quic) (AWS, formally verified)
- [ ] Go GC tuning — profile at 100+ concurrent proxies, set GOGC, evaluate memory allocation patterns in proxy loop

---

## Timeline Summary

| Phase | Duration | Status |
|-------|----------|--------|
| Phase 1: Configuration | ✅ 1 week | Complete |
| Phase 2: Authentication | ✅ 2 weeks | Complete |
| Phase 3: keytool CLI | ✅ 1 week | Complete |
| Phase 4A: Core Library + UX | ✅ 2-3 weeks | Complete |
| Phase 4B: Frictionless Onboarding | ✅ 1-2 weeks | Complete |
| **Phase 4C: Core Hardening & Security** | ✅ 6-8 weeks | Complete (Batches A–G) |
| Phase 4D: Plugins, SDK & First Plugins | 📋 3-4 weeks | Planned |
| Phase 4E: Distribution & Launch | 📋 1-2 weeks | Planned |
| Phase 4F: Desktop Gateway + Private DNS | 📋 2-3 weeks | Planned |
| Phase 4G: Mobile Apps | 📋 3-4 weeks | Planned |
| Phase 4H: Federation | 📋 2-3 weeks | Planned |
| Phase 4I: Advanced Naming | 📋 2-3 weeks | Planned (Optional) |
| Phase 5+: Ecosystem | 📋 Ongoing | Conceptual |

**Total estimated time for Phase 4**: 18-26 weeks (5-6 months)

**Priority logic**: Onboarding first (remove friction) → harden the core (security, self-healing, reliability, tests) → make it extensible with real plugins (file sharing, service templates, WoL prove the architecture) → distribute with use-case content (GPU, IoT, gaming) → transparent access (gateway, DNS) → expand (mobile → federation → naming).

---

## Contributing

This roadmap is a living document. Phases may be reordered, combined, or adjusted based on:
- User feedback and demand
- Technical challenges discovered during implementation
- Emerging technologies (AI, quantum, blockchain alternatives)
- Community contributions

**Adaptability over perfection.** We build for the next 1-5 years, not 50.

---

## Success Metrics

**Phase 4A Success**:
- Library can be imported and used in external projects
- Services can be exposed and consumed via P2P
- At least 3 example services documented (SSH, HTTP, custom)

**Phase 4B Success**:
- Two machines connected via invite code in under 60 seconds
- Zero manual file editing required
- Invite codes expire and are single-use

**Phase 4C Success**:
- CI pipeline runs on every push (build + vet + test with `-race`)
- Config versioning enables safe schema migration across deployments
- `go test -race ./...` passes with >60% overall coverage; >70% on daemon, auth, config; >40% on CLI commands
- Relay has explicit resource limits (not infinite)
- `authorized_keys` changes take effect without restart
- Proxy command attempts DCUtR direct connection before falling back to relay
- Relay reconnection recovers automatically within 30 seconds
- `peerup validate` / `relay-server validate` catches bad configs before applying
- Config archive stores last 5 configs; `config rollback` restores any of them
- `relay-server apply --confirm-timeout` auto-reverts if not confirmed (no lockout)
- systemd watchdog restarts relay within 60s if health check fails
- `/healthz` endpoint returns relay status (monitorable by Prometheus/UptimeKuma)
- `peerup status` shows connection state, peer status, and latency
- `peerup daemon` runs in background; scripts can query status and list services via Unix socket
- `peerup join --non-interactive` works in Docker containers and CI/CD pipelines without TTY
- go-libp2p upgraded to latest in both main module and relay-server (no version gap)
- AutoNAT v2 enabled — node correctly identifies per-address reachability (IPv4 vs IPv6)
- Resource Manager replaces `WithInfiniteLimits()` — per-peer connection/bandwidth caps enforced
- Connection setup latency reduced from 5-15s toward 1-3s (persistent reservation + warmup)
- QUIC transport used by default (3 RTTs vs 4 for TCP)
- `peerup --version` shows build version, commit hash, and build date
- Peers exchange version info via libp2p Identify UserAgent — `peerup status` shows peer versions
- Protocol versioning policy documented (backwards-compatible within major version)
- Integration tests verify real libp2p host-to-host connectivity in `go test`

**Phase 4D Success**:
- Third-party code can implement custom `Resolver`, `Authorizer`, and stream middleware
- Event hooks fire for peer connect/disconnect and auth decisions
- New CLI commands require <30 lines of orchestration (bootstrap consolidated)
- File transfer works between authorized peers (first plugin)
- `peerup daemon --ollama` auto-detects and exposes Ollama (service template plugin)
- `peerup wake <peer>` sends magic packet (WoL plugin)
- Transfer speed saturates relay bandwidth; resume works after interruption
- SDK documentation published with working plugin examples
- `peerup discover <peer>` returns list of exposed services with tags
- Python SDK works: `pip install peerup-sdk` → connect to remote service in <10 lines
- `peerup invite --headless` outputs JSON; `peerup join --from-env` reads env vars

**Phase 4E Success**:
- `peerup.dev` serves a Hugo documentation site with landing page, guides, and install instructions
- Site auto-deploys on push to `main` via GitHub Actions
- `peerup.dev/llms.txt` returns markdown index; `peerup.dev/llms-full.txt` returns full site content — AI agents can understand the project in ~200 tokens
- `curl get.peerup.dev | sh` installs the correct binary for the user's OS/arch
- `peerup.dev/releases/latest.json` manifest is the single source of truth for all upgrade/install consumers
- Binary and install script try GitHub → GitLab → IPFS in order (three-tier fallback)
- Source code, releases, and site mirrored to GitLab (push hook + GoReleaser + GitLab Pages)
- Release binaries pinned on IPFS (Filebase); DNSLink pre-configured for emergency failover
- Failover runbook documented: which DNS records to change for each failure scenario
- GoReleaser builds binaries for 9+ targets (linux/mac/windows × amd64/arm64 + linux/mipsle + linux/arm/v7)
- Embedded builds ≤10MB (UPX compressed), default builds ≤25MB (stripped)
- Homebrew tap works: `brew install satindergrewal/tap/peerup`
- Docker image available
- Install-to-running in under 30 seconds
- `peerup upgrade` fetches manifest from `peerup.dev`, downloads with fallback, verifies checksum
- `peerup upgrade --auto` with commit-confirmed rollback — impossible to brick remote nodes
- Relay announces version to peers; version mismatch triggers upgrade warning
- GPU inference use-case guide published
- Router deployment guide published (OpenWRT, Ubiquiti, GL.iNet)
- Blog post / demo published
- Scripting & automation guide published
- Containerized deployment guide published with working Docker compose examples
- Python SDK available on PyPI

**Phase 4F Success**:
- Gateway daemon works in all 3 modes (SOCKS, DNS, TUN)
- Private DNS on relay resolves subdomains only within P2P network
- Public DNS queries for subdomains return NXDOMAIN (zero leakage)
- Native apps connect using real domain names (e.g., `home.example.com`)

**Phase 4G Success**:
- iOS app approved by Apple
- Android app published on Play Store
- QR code invite flow works mobile → desktop

**Phase 4H Success**:
- Two independent networks successfully federate
- Cross-network routing works transparently
- Trust model prevents unauthorized access

**Phase 4I Success**:
- At least 3 naming backends working (local, DHT, one optional)
- Plugin API documented and usable
- Migration path demonstrated when one backend fails

---

**Last Updated**: 2026-02-20
**Current Phase**: 4C Complete (Batches A–G all shipped, tested, merged to main)
**Phase count**: 4C–4I (7 phases, down from 9 — file sharing and service templates merged into plugin architecture)
**Next Milestone**: Phase 4C Batch H (Observability) — OpenTelemetry, metrics, connection quality scoring, hole-punch tracking, audit logging
**Relay elimination**: Planned post-Batch H — `require_auth` peer relays → DHT discovery → VPS becomes obsolete


---

# Testing Guide: SSH Access via P2P Network

This guide walks through testing the complete peer-up system with SSH service exposure.

## Goal

Connect to your home computer's SSH server from a client device (laptop/phone) through the P2P network, traversing CGNAT/NAT using a relay server.

```
[Client]  ──peerup proxy──▶  [Relay Server]  ◀──peerup daemon──  [Home Server]  ──TCP──▶  [SSH :22]
 (Laptop)                       (VPS)                         (Behind CGNAT)
```

## Prerequisites

### 1. Three Machines/Terminals

- **Relay Server**: VPS with public IP (Linode, DigitalOcean, AWS, etc.)
- **Home Server**: Your home computer behind CGNAT/NAT (runs `peerup daemon`)
- **Client**: Laptop or another device (runs `peerup proxy`)

### 2. SSH Server Running

On your home computer:
```bash
# Check if SSH server is running
sudo systemctl status sshd  # or ssh on macOS

# Start if not running (Linux)
sudo systemctl start sshd

# macOS - enable in System Preferences > Sharing > Remote Login
```

### 3. Build peerup

```bash
# Build peerup (single binary — handles both client and relay server)
go build -o peerup ./cmd/peerup
```

---

## Step 1: Deploy Relay Server

See [relay-server/README.md](../relay-server/README.md) for the full VPS setup guide.

Quick version:

```bash
cd relay-server
cp ../configs/relay-server.sample.yaml relay-server.yaml
# Edit relay-server.yaml if needed (defaults are fine)

# Build from project root
cd ..
go build -o relay-server/peerup ./cmd/peerup
cd relay-server && ./peerup relay serve
```

**Expected output:**
```
=== Relay Server (Circuit Relay v2) ===
🆔 Relay Peer ID: 12D3KooWABC...XYZ
📍 Listening on:
  /ip4/YOUR_VPS_IP/tcp/7777
  /ip4/YOUR_VPS_IP/udp/7777/quic-v1
✅ Relay server is running!
```

**Save these values:**
- Relay Peer ID: `12D3KooWABC...XYZ`
- VPS IP: `YOUR_VPS_IP`

---

## Step 2: Set Up Home Server

### Run the setup wizard

```bash
./peerup init
```

The wizard will:
1. Create `~/.config/peerup/` directory
2. Ask for your relay server address (accepts flexible formats):
   - Full multiaddr: `/ip4/1.2.3.4/tcp/7777/p2p/12D3KooW...`
   - IP and port: `1.2.3.4:7777` (then prompts for peer ID)
   - Bare IP: `1.2.3.4` (uses default port 7777, then prompts for peer ID)
   - IPv6: `[2600:3c00::1]:7777` or `[2600:3c00::1]`
3. Generate an Ed25519 identity key
4. Display your **Peer ID** as text + QR code (share with peers)
5. Write `config.yaml`, `identity.key`, and `authorized_keys`

**Tip**: Check your peer ID anytime with `./peerup whoami`

### Configure services

Add services via CLI (preferred) or by editing the config file:

```bash
# Add via CLI
./peerup service add ssh localhost:22
./peerup service add xrdp localhost:3389

# Or edit ~/.config/peerup/config.yaml directly
```

Ensure `force_private_reachability` is set for CGNAT:

```yaml
network:
  force_private_reachability: true  # CRITICAL for CGNAT (Starlink, etc.)
```

### Start the server

```bash
./peerup daemon
```

**Expected output:**
```
Loaded configuration from ~/.config/peerup/config.yaml
🏠 Peer ID: 12D3KooWHOME...ABC
✅ Connected to relay 12D3KooWABC...
✅ Relay address: /ip4/YOUR_VPS_IP/tcp/7777/p2p/12D3KooWABC.../p2p-circuit/p2p/12D3KooWHOME...ABC
✅ Registered service: ssh (protocol: /peerup/ssh/1.0.0, local: localhost:22)
```

**Save the Home Server Peer ID**: `12D3KooWHOME...ABC`

---

## Step 3: Set Up Client

### Run the setup wizard

```bash
./peerup init
```

### Authorize peers

**Option A: Invite/Join flow (recommended — handles both sides automatically)**

On the home server:
```bash
./peerup invite --name home
# Displays an invite code + QR code. Share the code with the client.
```

On the client:
```bash
./peerup join <invite-code> --name laptop
# Automatically: connects to inviter, exchanges peer IDs,
# adds each other to authorized_keys, adds name mapping.
```

**Option B: CLI commands**

On the client, add the home server's peer ID:
```bash
./peerup auth add 12D3KooWHOME...ABC --comment "home-server"
```

Do the same on the home server — add the client's peer ID:
```bash
./peerup auth add 12D3KooWCLIENT...XYZ --comment "laptop"
```

Verify with:
```bash
./peerup auth list
```

**Option C: Manual file edit**
```bash
# Edit ~/.config/peerup/authorized_keys
# Add the peer ID (one per line):
12D3KooWHOME...ABC  # home-server
```

### Add friendly name

If you used the invite/join flow, names are added automatically. Otherwise, edit `~/.config/peerup/config.yaml` on the client:

```yaml
# Map friendly names to peer IDs:
names:
  home: "12D3KooWHOME...ABC"  # From Step 2
```

---

## Step 4: Test SSH Connection via P2P

### Test connectivity first

```bash
./peerup ping home
```

You should see a successful ping/pong response.

### Start the SSH proxy

```bash
./peerup proxy home ssh 2222
```

This creates a local TCP listener on port 2222 that tunnels through the P2P network to the home server's SSH service.

### Connect via SSH

In another terminal:

```bash
ssh -p 2222 your_username@localhost
```

You should see your home computer's SSH prompt!

---

## Step 5: Test Other Services

### XRDP (Remote Desktop)

On the home server, enable XRDP in config:

```yaml
services:
  ssh:
    enabled: true
    local_address: "localhost:22"
  xrdp:
    enabled: true
    local_address: "localhost:3389"
```

Restart `peerup daemon`, then on the client:

```bash
./peerup proxy home xrdp 13389
# Then connect:
xfreerdp /v:localhost:13389 /u:your_username
```

### Any TCP Service

```yaml
services:
  web:
    enabled: true
    local_address: "localhost:8080"
```

```bash
./peerup proxy home web 8080
# Then: curl http://localhost:8080
```

---

## Managing Relay Addresses

After initial setup, you can add or remove relay servers:

```bash
# Add a relay (flexible formats)
./peerup relay add 1.2.3.4 --peer-id 12D3KooW...
./peerup relay add 1.2.3.4:7777 --peer-id 12D3KooW...
./peerup relay add /ip4/1.2.3.4/tcp/7777/p2p/12D3KooW...

# List configured relays
./peerup relay list

# Remove a relay
./peerup relay remove /ip4/1.2.3.4/tcp/7777/p2p/12D3KooW...
```

### Relay health check

On the VPS, verify the relay is healthy:
```bash
sudo ./setup.sh --check
```
This shows systemd status, peer ID, public IPs, full multiaddrs, and a QR code for easy sharing.

---

## Troubleshooting

### Relay Connection Failed

```
⚠️  Could not connect to relay
```

**Fix:**
- Verify VPS firewall allows TCP 7777 and UDP 7777
- Check relay server is actually running
- Verify relay peer ID is correct in config

### No Relay Address

```
⚠️  No relay addresses yet
```

**Fix:**
- Ensure `force_private_reachability: true` in home server config
- Wait 10-15 seconds for AutoRelay
- Check relay server logs for reservation requests

### SSH Service Not Found

```
Failed to connect to SSH service: protocol not supported
```

**Fix:**
- Verify `services.ssh.enabled: true` in home server config
- Check server logs for "Registered service: ssh"
- Ensure SSH protocol ID matches: `/peerup/ssh/1.0.0`

### Connection Refused on localhost:22

```
Failed to connect to local service localhost:22
```

**Fix:**
- Start SSH server on home computer
- Check: `sudo systemctl status sshd`
- Verify SSH is listening: `netstat -tlnp | grep :22`

### Cannot Resolve Target

```
Cannot resolve target "home"
```

**Fix:**
- Add name mapping to `names:` section in client config
- Or use the full peer ID directly: `peerup proxy 12D3KooW... ssh 2222`

### Discovery Not Working

```
📡 Searching for peers... (no results)
```

**Fix:**
- Verify both nodes use the same `rendezvous` string in config
- Check DHT is bootstrapped
- Wait 30-60 seconds for DHT propagation

---

## Success Criteria

- [ ] Relay server running and accessible
- [ ] Home server gets relay address with `/p2p-circuit`
- [ ] `peerup ping home` succeeds from client
- [ ] `peerup proxy home ssh 2222` creates local listener
- [ ] `ssh -p 2222 user@localhost` connects to home computer
- [ ] XRDP / other TCP services also work

---

## Unit Tests

peer-up has automated unit tests for core packages. These run in CI (GitHub Actions) on every push.

### Running Tests

All packages are in a single Go module. Run everything from the project root:

```bash
# Run all tests with race detection (same as CI)
go test -race -count=1 ./...

# Run tests for a specific package
go test -race ./internal/config/
go test -race ./internal/auth/
go test -race ./internal/invite/
go test -race ./cmd/peerup/

# Verbose output (see individual test names)
go test -race -v ./internal/auth/
```

### Test Coverage

| Package | Tests | What's covered |
|---------|-------|---------------|
| `internal/config` | `loader_test.go` | Config loading, YAML parsing, validation (all config types), path resolution, config version handling, FindConfigFile discovery |
| `internal/config` | `archive_test.go` | Archive path derivation, archive/rollback round-trip, permissions (0600), overwrite semantics, no temp file leaks, ErrNoArchive sentinel |
| `internal/config` | `confirm_test.go` | Begin/confirm lifecycle, duplicate prevention (ErrCommitConfirmedPending), ErrNoPending, ApplyCommitConfirmed file swap, EnforceCommitConfirmed timeout revert, context cancellation, expired deadline handling |
| `internal/watchdog` | `watchdog_test.go` | Health check loop execution, unhealthy check logging, context cancellation, default interval, sd_notify no-op without NOTIFY_SOCKET, sd_notify error on bad socket |
| `internal/auth` | `gater_test.go` | ConnectionGater: inbound/outbound filtering, peer authorization, hot-reload |
| `internal/auth` | `authorized_keys_test.go` | File loading, comment handling, invalid peer IDs, missing files |
| `internal/auth` | `manage_test.go` | AddPeer (with duplicate/sanitize), RemovePeer (atomic write, preserves comments), ListPeers |
| `internal/identity` | `identity_test.go` | Key creation, persistence, file permissions, PeerIDFromKeyFile |
| `internal/validate` | `service_test.go` | Service name validation (valid/invalid cases, max length) |
| `internal/invite` | `code_test.go` | Encode/decode round-trip, invalid codes, trailing junk rejection |
| `cmd/peerup` | `relay_input_test.go` | Relay address parsing (IPv4, IPv6, multiaddr detection, port validation) |
| `pkg/p2pnet` | `integration_test.go` | In-process libp2p host-to-host streaming, half-close semantics, P2P-to-TCP proxy, DialWithRetry retry/backoff, UserAgent exchange via Identify protocol |

---

## Benchmarks

Performance benchmarks establish baselines for hot-path and cold-path functions.

### Running Benchmarks

```bash
# Run all benchmarks with memory stats
go test -bench=. -benchmem ./internal/auth/
go test -bench=. -benchmem ./internal/invite/
go test -bench=. -benchmem ./internal/config/
go test -bench=. -benchmem ./pkg/p2pnet/

# For statistical comparison (3+ runs recommended)
go test -bench=. -benchmem -count=3 ./internal/auth/

# Compare before/after with benchstat
go install golang.org/x/perf/cmd/benchstat@latest
go test -bench=. -benchmem -count=5 ./internal/auth/ > old.txt
# (make changes)
go test -bench=. -benchmem -count=5 ./internal/auth/ > new.txt
benchstat old.txt new.txt
```

### Benchmark Coverage

| File | Benchmarks | Path Type | What's Measured |
|------|-----------|-----------|-----------------|
| `internal/auth/gater_bench_test.go` | `InterceptSecuredAllowed`, `InterceptSecuredDenied`, `IsAuthorized` | Hot (per-connection) | RWMutex + map lookup latency |
| `internal/auth/authorized_keys_bench_test.go` | `LoadAuthorizedKeys5`, `LoadAuthorizedKeys50` | Cold (startup/reload) | File parse + peer ID decode |
| `internal/invite/code_bench_test.go` | `Encode`, `Decode` | Mixed (per-invite) | Base32 + multihash + multiaddr ops |
| `internal/config/loader_bench_test.go` | `LoadNodeConfig`, `ValidateNodeConfig` | Cold (startup) | YAML parse, validation |
| `pkg/p2pnet/naming_bench_test.go` | `ResolveByName`, `ResolveByPeerID` | Hot (per-proxy) | Map lookup vs peer.Decode fallback |

---

### Coverage-Instrumented Docker Tests

Docker integration tests exercise the actual compiled binary end-to-end (relay server, invite/join flow, ping through circuit relay). The binary is built with `go build -cover`, so coverage data is captured when processes exit.

```bash
# Run Docker tests with coverage collection
mkdir -p coverage/integration
PEERUP_COVDIR="$PWD/coverage/integration" \
  go test -tags integration -v -timeout 5m ./test/docker/

# Run unit tests with binary-format coverage (for merging)
mkdir -p coverage/unit
go test -cover ./... -args -test.gocoverdir="$PWD/coverage/unit"

# Merge unit + Docker coverage
mkdir -p coverage/merged
go tool covdata merge -i=coverage/unit,coverage/integration -o=coverage/merged

# Generate combined report
go tool covdata textfmt -i=coverage/merged -o=coverage/combined.out
go tool cover -func=coverage/combined.out | tail -1

# HTML visualization
go tool cover -html=coverage/combined.out -o=coverage/report.html
```

This captures code paths that unit tests cannot reach: `runRelayServe`, `runDaemon`, `runInvite`, `runJoin`, `runPing` through real P2P circuits.

### CI Pipeline

GitHub Actions runs on every push to `main` and `dev/next-iteration`. All commands run from the project root against the single Go module:

1. **Build** — all packages compile (`go build ./...`)
2. **Vet** — static analysis (`go vet ./...`)
3. **Test** — all tests with race detection (`go test -race -count=1 ./...`)
4. **Coverage** — unit + Docker integration coverage merged and reported

Config: [`.github/workflows/ci.yml`](../.github/workflows/ci.yml)

---

## Logging in Tests

Library code uses `log/slog` for structured logging. In tests, slog output goes to stderr by default, which `go test` captures and only shows on failure. No special test configuration is needed.

For benchmarks that previously used `log.New(io.Discard, ...)` to suppress logging, slog's default handler is used instead — the small overhead is part of the realistic benchmark measurement.

---

**Last Updated**: 2026-02-19


---

# Engineering Journal

This document captures the **why** behind every significant architecture decision in peer-up. Each entry follows a lightweight ADR (Architecture Decision Record) format: what problem we faced, what options we considered, what we chose, and what trade-offs we accepted.

New developers, contributors, and future-us should be able to read this and understand not just what the code does, but why it's shaped the way it is.

## Reading Guide

- **ADR-0XX**: Core architecture decisions made before the batch system
- **ADR-X0Y**: Batch-specific decisions (A=reliability, B=code quality, etc.)
- Each ADR is self-contained — read any entry independently
- Entries link to source files and commits where relevant

---

## Core Architecture Decisions

### ADR-001: Why Go

**Context**: peer-up needs to compile to a single static binary, run on Linux/macOS/Windows, and interface with libp2p (which has mature Go and Rust implementations).

**Alternatives considered**:
- **Rust** — Better memory safety guarantees, smaller binaries. Rejected because rust-libp2p has less mature circuit relay v2 support, and compile times would slow iteration during early development.
- **Python/Node.js** — Faster prototyping. Rejected because distribution requires runtime dependencies, violating the "single binary, zero dependencies" principle.

**Decision**: Go. Single binary compilation, excellent cross-platform support, mature libp2p ecosystem, and fast compilation for rapid iteration.

**Consequences**: Larger binary size (~28MB stripped) compared to Rust. Accepted because distribution simplicity outweighs binary size for a CLI tool. Binary size is actively monitored and optimized (see `binary-optimization` practices).

**Reference**: `go.mod`, `cmd/peerup/main.go`

---

### ADR-002: Why libp2p (Not Raw QUIC, Not WireGuard)

**Context**: peer-up needs NAT traversal, encrypted transport, peer discovery, and circuit relay. Building these from scratch would take years.

**Alternatives considered**:
- **Raw QUIC + custom protocol** — Full control, smaller dependency tree. Rejected because we'd need to implement hole punching, relay, DHT, and peer routing from scratch.
- **WireGuard** — Excellent performance, kernel-level. Rejected because it requires root/admin privileges, doesn't solve discovery, and doesn't provide circuit relay for CGNAT.
- **Noise protocol + custom transport** — Lighter than libp2p. Rejected because discovery and relay still need to be built.

**Decision**: libp2p v0.47.0. Provides QUIC+TCP+WebSocket transports, circuit relay v2, hole punching (DCUtR), Kademlia DHT, peer identity (Ed25519), and connection gating — all battle-tested.

**Consequences**: Large dependency tree (100+ transitive deps). The binary includes WebRTC and other transports we don't directly use. Accepted because reliability > binary size, and we actively track CVEs in dependencies.

**Reference**: `go.mod`, `pkg/p2pnet/network.go`

---

### ADR-003: Why Private DHT `/peerup/kad/1.0.0`

**Context**: Initially used the public IPFS Amino DHT (`/ipfs/kad/1.0.0`). This worked but mixed peerup peers into the global IPFS routing table, leaking peer discovery to the public network.

**Alternatives considered**:
- **Keep IPFS Amino DHT** — Zero config, large bootstrap. Rejected because (a) privacy: peerup peers are discoverable by anyone on IPFS, (b) pollution: peerup's rendezvous strings pollute the global DHT, (c) reliability: depends on IPFS bootstrap nodes staying healthy.
- **No DHT, relay-only** — Simpler. Rejected because DHT enables peer discovery without centralized infrastructure.
- **mDNS only** — Local network discovery. Rejected because it doesn't work across networks.

**Decision**: Private Kademlia DHT with protocol prefix `/peerup/kad/1.0.0` (constant `p2pnet.DHTProtocolPrefix`). Peerup peers only discover and route to other peerup peers.

**Consequences**: Smaller routing table (only peerup peers), no IPFS bootstrap dependency, but requires at least one known peer (relay) to bootstrap into the DHT.

**Reference**: `pkg/p2pnet/network.go:27` (`DHTProtocolPrefix` constant), commit `d1d4336`

---

### ADR-004: Why Circuit Relay v2

**Context**: Users behind CGNAT (5G, carrier-grade NAT, double NAT) cannot receive inbound connections. This is the core problem peer-up solves.

**Alternatives considered**:
- **UPnP/NAT-PMP only** — Works for simple NAT, fails on CGNAT. Rejected as sole strategy.
- **TURN server** — WebRTC-style relay. Rejected because it's a separate protocol ecosystem; libp2p's circuit relay v2 integrates naturally with the existing transport stack.
- **Circuit relay v1** — Deprecated by libp2p. Rejected.

**Decision**: Circuit relay v2 via `libp2p.EnableAutoRelayWithStaticRelays()`. The relay server makes reservations for peers, enabling them to be reached through the relay.

**Consequences**: All traffic flows through the relay when direct connection fails. Relay becomes a critical infrastructure component — must be hardened, monitored, and eventually made redundant (see Batch I: relay elimination research).

**Reference**: `pkg/p2pnet/network.go:140`, `cmd/relay-server/`

---

### ADR-005: Why Connection Gating via `authorized_keys`

**Context**: peer-up networks are private. Only explicitly authorized peers should connect. Needed an SSH-like trust model.

**Alternatives considered**:
- **Certificate authority** — More scalable, supports expiration. Rejected because it requires PKI infrastructure (CA key management, certificate issuance), which contradicts "no central authority."
- **Pre-shared keys** — Simpler than CA. Rejected because it doesn't provide per-peer identity.
- **No gating, encryption only** — Let any peer connect but encrypt traffic. Rejected because authorization is a core security requirement, not optional.

**Decision**: `authorized_keys` file containing one peer ID per line, checked by `auth.AuthorizedPeerGater` in `InterceptSecured()`. Only inbound connections are gated; outbound (to relay, DHT) are always allowed.

**Consequences**: Simple file-based auth that users already understand from SSH. Hot-reloadable at runtime. Scales to hundreds of peers. Does not support per-peer permissions (all-or-nothing access) — acceptable for current scope.

**Reference**: `internal/auth/gater.go`, `internal/auth/keys.go`

---

### ADR-006: Why Single Binary with Subcommands

**Context**: peer-up has many functions: daemon, ping, proxy, config management, relay server (separate binary). Needed a clean CLI structure.

**Alternatives considered**:
- **Separate binaries per function** — `peerup-daemon`, `peerup-ping`, etc. Rejected because it complicates distribution and PATH management.
- **cobra/urfave CLI framework** — Feature-rich. Rejected because they add dependency weight and complexity for what's essentially a dispatch table. Standard library `flag` + manual dispatch is lighter and fully sufficient.

**Decision**: Single `peerup` binary using `os.Args[1]` dispatch (`cmd/peerup/main.go`) with standard library `flag` for each subcommand. Relay server is a separate binary (`cmd/relay-server/`) because it has different deployment concerns (VPS vs local machine).

**Consequences**: The binary includes all functionality, so it's slightly larger than specialized binaries would be. Accepted because single-binary deployment is a core principle — `curl install | sh` drops one file.

**Reference**: `cmd/peerup/main.go`

---

### ADR-007: Why YAML Config

**Context**: peer-up needs configuration for identity, network, relay, discovery, security, services, and names. Needed a human-readable, editable format.

**Alternatives considered**:
- **TOML** — Good for flat config. Rejected because nested structures (services map, relay addresses) are more natural in YAML.
- **JSON** — Universal. Rejected because no comments, poor human editability for config files users need to hand-edit.
- **HCL** — HashiCorp's format. Rejected because it adds a dependency and is unfamiliar to most users.
- **Flags/env vars only** — Simpler. Rejected because the configuration is too complex for command-line flags alone.

**Decision**: YAML via `gopkg.in/yaml.v3`. Single config file with versioning (`version: 1`), duration strings (`10m`, `1h`), and relative path resolution.

**Consequences**: YAML is sensitive to indentation, which can confuse users. Mitigated by: (a) `peerup init` generates valid config automatically, (b) `peerup config validate` catches syntax errors, (c) config templates in `config_template.go` ensure consistency.

**Reference**: `internal/config/types.go`, `internal/config/loader.go`, `cmd/peerup/config_template.go`

---

### ADR-008: Why No External Dependencies Beyond libp2p

**Context**: Every dependency is an attack surface, a binary size cost, and a maintenance burden. peer-up is infrastructure software.

**Alternatives considered**: N/A — this is a constraint, not a choice between options.

**Decision**: The only direct dependencies are `go-libp2p`, `go-libp2p-kad-dht`, `go-multiaddr`, and `gopkg.in/yaml.v3`. Everything else (logging, config, auth, watchdog, QR codes) is implemented with Go standard library.

**Consequences**: More code to maintain (e.g., pure-Go sd_notify instead of using a systemd library), but complete control over behavior, smaller binary, and zero supply chain risk beyond the libp2p ecosystem.

**Reference**: `go.mod` (4 direct dependencies)

---

## Batch A: Reliability

### ADR-A01: TCP Timeout Strategy

**Context**: TCP proxy connections through circuit relay need appropriate timeouts. Too short = drops active SSH sessions. Too long = leaked connections consume relay resources.

**Alternatives considered**:
- **No explicit timeouts** (rely on libp2p defaults) — Rejected because libp2p's default stream timeouts are too short for interactive SSH sessions.
- **Configurable per-service timeouts** — Considered for future, but adds complexity for a problem that has reasonable defaults.

**Decision**: 10-second dial timeout for initial TCP connection (`net.DialTimeout("tcp", addr, 10*time.Second)`), 30-second context timeout for service connections. No idle timeout — SSH sessions can be long-lived; the half-close proxy (`BidirectionalProxy`) cleanly handles EOF propagation.

**Consequences**: Long-lived connections are supported, but a peer that disappears without closing the stream will hold resources until the relay's session duration limit (default 10 minutes) kicks in.

**Reference**: `pkg/p2pnet/proxy.go:66`

---

### ADR-A02: Retry with Exponential Backoff

**Context**: P2P connections through relays are inherently unreliable. A single dial failure shouldn't kill a proxy session.

**Alternatives considered**:
- **No retry** — Fail immediately. Rejected because relay connections often fail transiently.
- **Fixed delay retry** — Simpler but can cause thundering herd and doesn't adapt to load.

**Decision**: `DialWithRetry()` wraps any dial function with exponential backoff: 1s, 2s, 4s, ..., capped at 60s. Default 3 retries for daemon-created proxies.

**Consequences**: A failing connection takes up to ~7 seconds before giving up (1+2+4), which is acceptable for interactive use. The cap at 60s prevents runaway delays.

**Reference**: `pkg/p2pnet/proxy.go:130-155`

---

### ADR-A03: DHT in Proxy Path

**Context**: When the daemon receives a proxy connect request, the target peer might not be directly connected. Need to find and reach them first.

**Alternatives considered**:
- **Require pre-existing connection** — Simpler but fragile. Rejected because peers reconnect through DHT discovery, and the user shouldn't need to manually reconnect before proxying.
- **DNS-based discovery** — Rejected because it requires external infrastructure.

**Decision**: `ConnectToPeer()` in the daemon runtime performs DHT lookup + relay address injection before establishing the service stream. Every proxy and ping operation calls this first.

**Consequences**: First connection to a peer may be slow (DHT walk + relay reservation). Subsequent connections reuse the existing link. This is the correct behavior — find the peer, then talk to them.

**Reference**: `cmd/peerup/serve_common.go` (`ConnectToPeer` method), `internal/daemon/handlers.go:338`

---

### ADR-A04: In-Process Integration Tests

**Context**: Need integration tests that verify multi-peer P2P scenarios without requiring Docker, LAN access, or actual network infrastructure.

**Alternatives considered**:
- **Docker-only tests** — Realistic but slow and requires Docker installed. Added later as a complement (Batch G), not a replacement.
- **Mock libp2p hosts** — Too much mocking makes tests unreliable.

**Decision**: Create real libp2p hosts in the same process, connecting through an in-process relay. Tests in `pkg/p2pnet/` create 2-3 hosts that communicate through circuit relay within a single test binary.

**Consequences**: Tests are fast (~2s) and run anywhere (`go test ./...`). They don't test actual network conditions (latency, packet loss), which is why Docker integration tests were added later as a complement.

**Reference**: `pkg/p2pnet/network_test.go`, `pkg/p2pnet/service_test.go`

---

## Batch B: Code Quality

### ADR-B01: Proxy Deduplication

**Context**: `ParseRelayAddrs()` could receive duplicate relay addresses (same peer, different multiaddrs). Without dedup, libp2p would make redundant connections.

**Alternatives considered**:
- **Let libp2p handle it** — libp2p does some dedup, but passing duplicates to `EnableAutoRelayWithStaticRelays` wastes resources.

**Decision**: `ParseRelayAddrs()` deduplicates by peer ID and merges addresses for the same relay peer. If the same relay appears twice with different addresses, all addresses are collected under one `peer.AddrInfo`.

**Consequences**: Clean relay configuration. Users can list multiple addresses for the same relay (e.g., IPv4 and IPv6) without issues.

**Reference**: `pkg/p2pnet/network.go:280-309`

---

### ADR-B02: `log/slog` over zerolog/zap

**Context**: Needed structured logging throughout the project. Many Go projects use zerolog or zap for performance.

**Alternatives considered**:
- **zerolog** — Zero-allocation, fast. Rejected because it's another dependency, and peer-up doesn't produce enough log volume to need zero-allocation logging.
- **zap** — Uber's logger, excellent performance. Rejected for the same reason — adds dependency weight for no measurable benefit.
- **log/slog** — Go 1.21+ standard library structured logging. Built-in, no dependency, sufficient performance.

**Decision**: `log/slog` everywhere. `slog.Info`, `slog.Warn`, `slog.Error` with structured key-value pairs. Default handler writes to stderr.

**Consequences**: No external logging dependency. Standard library compatibility means any future handler (JSON, OpenTelemetry) can be swapped in without changing call sites. Slightly more verbose than zerolog's fluent API, but consistency with stdlib is worth it.

**Reference**: `cmd/peerup/main.go:20-22` (handler setup), used throughout all packages

---

### ADR-B03: Sentinel Errors

**Context**: Error handling was using `fmt.Errorf("service not found")` strings that callers couldn't programmatically check.

**Alternatives considered**:
- **String matching** — `strings.Contains(err.Error(), "not found")`. Rejected because it's fragile and breaks on message changes.
- **Custom error types** — `type NotFoundError struct { Name string }`. Considered for complex errors, but sentinel variables are simpler for the common case.

**Decision**: Package-level sentinel errors using `errors.New()`: `ErrServiceNotFound`, `ErrNameNotFound`, `ErrConfigNotFound`, `ErrNoArchive`, `ErrCommitConfirmedPending`, `ErrNoPending`, `ErrDaemonAlreadyRunning`, `ErrProxyNotFound`. Callers use `errors.Is()` to check.

**Consequences**: Clean error checking, wrappable with `fmt.Errorf("%w: ...", ErrFoo)`. Error messages in two packages: `pkg/p2pnet/errors.go` and `internal/config/errors.go`.

**Reference**: `pkg/p2pnet/errors.go`, `internal/config/errors.go`, `internal/daemon/errors.go`

---

### ADR-B04: Build Version Embedding

**Context**: Need to know exactly which version and commit is running, especially when debugging relay issues remotely.

**Alternatives considered**:
- **Version file** — Read from embedded file. Rejected because it's another artifact to maintain.
- **Git describe at runtime** — Call `git describe` at startup. Rejected because the binary might not be in a git repo.

**Decision**: `ldflags` injection at build time: `-X main.version=... -X main.commit=... -X main.buildDate=...`. Defaults to `dev` and `unknown` for development builds. Also sent as libp2p Identify UserAgent (`peerup/0.1.0`).

**Consequences**: Every binary is self-identifying. `peerup version` shows exact build info. The UserAgent appears in `peerup daemon peers --all`, making it easy to verify what version each peer runs.

**Reference**: `cmd/peerup/main.go:10-17`, `pkg/p2pnet/network.go:121-123`

---

## Batch C: Self-Healing

### ADR-C01: Config Archive/Rollback (Juniper-Inspired)

**Context**: A bad config change on a remote node (e.g., wrong relay address) could make it permanently unreachable. Need a recovery mechanism.

**Alternatives considered**:
- **Git-based config history** — Track config in a git repo. Rejected because it requires git installed and adds complexity.
- **Numbered backups** (config.1, config.2, ...) — More history but harder to manage cleanup.

**Decision**: Juniper-style last-known-good: `Archive()` copies current config to `.config.last-good.yaml` with atomic write (temp file + rename). `Rollback()` restores it. Single backup slot — simple, sufficient.

**Consequences**: Only one rollback level (no multi-step undo). Accepted because the common case is "my last change broke it, undo that one change." The archive is created before daemon start and before config apply.

**Reference**: `internal/config/archive.go`

---

### ADR-C02: Commit-Confirmed Pattern

**Context**: Changing config on a remote node is dangerous — if the new config prevents connectivity, you're locked out. Network engineers solve this with "commit confirmed" — apply the change, and if you don't confirm within N minutes, it auto-reverts.

**Alternatives considered**:
- **Manual rollback only** — User must SSH in (if they can) and run `peerup config rollback`. Rejected because if the config broke SSH access, there's no way in.
- **Two-phase commit** — More complex, requires coordination. Rejected as over-engineering for a single-node config change.

**Decision**: `peerup config apply <new> --confirm-timeout 5m` backs up current config, applies new config, starts a timer. If `peerup config confirm` isn't run within the timeout, the daemon reverts to the backup and restarts via `exitFunc(1)` (systemd restarts it with the restored config).

**Consequences**: Requires systemd (or equivalent) to restart on exit. The `exitFunc` is injectable for testing (`EnforceCommitConfirmed` takes `func(int)` instead of calling `os.Exit` directly).

**Reference**: `internal/config/confirm.go`, `cmd/peerup/cmd_config.go`

---

### ADR-C03: Watchdog + sd_notify (Pure Go)

**Context**: The daemon needs to report health to systemd and restart on failure. Most Go projects use `coreos/go-systemd` for sd_notify.

**Alternatives considered**:
- **`coreos/go-systemd`** — Mature library. Rejected because it's another dependency for 30 lines of socket code. Also pulls in dbus bindings we don't need.
- **No watchdog** — Let systemd's simple restart handle failures. Rejected because watchdog provides proactive health checking, not just crash recovery.

**Decision**: Pure Go sd_notify implementation in `internal/watchdog/watchdog.go`. Three functions: `Ready()` (READY=1), `Watchdog()` (WATCHDOG=1), `Stopping()` (STOPPING=1). All send datagrams to `$NOTIFY_SOCKET`. No-op when not running under systemd (macOS, manual launch).

The watchdog loop runs configurable health checks (default 30s interval) and only sends WATCHDOG=1 when all checks pass. The daemon adds a socket health check to verify the API is still accepting connections.

**Consequences**: Zero dependency for systemd integration. Works on both Linux (systemd) and macOS (launchd, where sd_notify is a no-op). The health check framework is extensible — Batch H will add libp2p connection health.

**Reference**: `internal/watchdog/watchdog.go`, `cmd/peerup/cmd_daemon.go:158-166`

---

## Batch D: libp2p Features

### ADR-D01: AutoNAT v2

**Context**: Peers need to know if they're behind NAT to decide whether to use relay. libp2p's AutoNAT v1 had accuracy issues.

**Alternatives considered**:
- **Manual reachability flag only** (`force_private_reachability: true`) — Works but requires users to know their NAT situation.
- **AutoNAT v1** — Older protocol, less accurate with CGNAT.

**Decision**: Enable AutoNAT v2 via `libp2p.EnableAutoNATv2()` alongside the manual flag. AutoNAT v2 uses a more reliable probing mechanism to determine reachability.

**Consequences**: Slightly more network chatter (AutoNAT probes), but more accurate reachability detection. The manual `force_private_reachability` flag remains as an override for cases where AutoNAT can't determine the correct state.

**Reference**: `pkg/p2pnet/network.go:118`

---

### ADR-D02: QUIC Preferred Transport Ordering

**Context**: libp2p supports multiple transports. The order they're specified affects which is tried first during connection establishment.

**Alternatives considered**:
- **TCP first** — Most compatible, works through all middleboxes. But slower connection establishment (4 RTTs for TCP+TLS+mux vs 3 for QUIC).
- **WebSocket first** — Anti-censorship benefit. But highest overhead.

**Decision**: Transport order is QUIC first, TCP second, WebSocket third. QUIC has native multiplexing (no yamux needed), faster handshake (1-RTT after initial), and better hole-punching characteristics. TCP is the universal fallback. WebSocket is for DPI/censorship evasion.

**Consequences**: Environments that block UDP (some corporate networks) will fall back to TCP automatically. The ordering is declarative in `New()` — first transport to succeed wins.

**Reference**: `pkg/p2pnet/network.go:113-117`

---

### ADR-D03: Identify UserAgent

**Context**: When multiple peers are connected, it's hard to tell which are peerup peers vs DHT neighbors, relay servers, or random libp2p nodes.

**Alternatives considered**:
- **Custom protocol handshake** — Send version info in a custom protocol. Rejected because libp2p's Identify protocol already does this.

**Decision**: Set `libp2p.UserAgent("peerup/" + version)` on every host. The daemon's peer list filters by UserAgent prefix (`peerup/` or `relay-server/`) by default, showing only network members. `--all` flag shows everything.

**Consequences**: Version info is visible to any connected peer (including non-peerup peers). Accepted because version strings are not sensitive — they aid debugging and interoperability.

**Reference**: `pkg/p2pnet/network.go:121-123`, `internal/daemon/handlers.go:78-80`

---

### ADR-D04: Smart Dialing

**Context**: libp2p tries all known addresses for a peer simultaneously. With relay addresses in the peerstore, it might waste time on direct addresses that will fail for CGNAT peers.

**Alternatives considered**:
- **Relay-only dialing** — Only use relay. Rejected because direct connections should be preferred when available.

**Decision**: Let libp2p's default smart dialing handle address selection, but ensure relay circuit addresses are always in the peerstore via `AddRelayAddressesForPeer()`. This gives the dialer both direct and relay options, and it picks the fastest.

**Consequences**: Relies on libp2p's dialing heuristics, which generally prefer direct connections. Future Batch I work will add explicit address ranking (direct IPv6 > direct IPv4 > peer relay > VPS relay).

**Reference**: `pkg/p2pnet/network.go:260-270`

---

## Batch E: New Capabilities

### ADR-E01: `/healthz` on Relay

**Context**: The relay server is a critical public-facing service. Monitoring systems need a health endpoint.

**Alternatives considered**:
- **TCP port check only** — Just verify the port is open. Rejected because it doesn't verify the relay is actually functional.
- **Full metrics endpoint** — Prometheus-style. Planned for Batch H, but `/healthz` needed now for basic monitoring.

**Decision**: HTTP `/healthz` endpoint on configurable address (default `127.0.0.1:9090`). Returns JSON with `status`, `uptime_seconds`, and `connected_peers`. Restricted to loopback by default — reverse proxy or SSH tunnel for remote access.

**Consequences**: Minimal information exposure (no peer IDs, no version, no protocol list in the health response — hardened in the post-phase audit). Loopback-only prevents information disclosure to the public internet.

**Reference**: `cmd/peerup/cmd_relay_serve.go`

---

### ADR-E02: Headless Invite/Join

**Context**: Docker containers, CI/CD pipelines, and scripts need to create/accept invites without interactive prompts or QR codes.

**Alternatives considered**:
- **Separate CLI for scripting** — A `peerup-cli` tool. Rejected because it fragments the tool.
- **Environment variables only** — `PEERUP_INVITE_CODE=xxx peerup join`. Supported alongside the flag.

**Decision**: `--non-interactive` flag on both `invite` and `join`. In non-interactive mode: invite prints bare code to stdout (progress to stderr), join reads code from positional arg or `PEERUP_INVITE_CODE` env var. No QR code, no prompts, no color.

**Consequences**: Docker integration tests can create and exchange invite codes programmatically. The flag reuses the same code paths as interactive mode — just different I/O routing.

**Reference**: `cmd/peerup/cmd_invite.go:34`, `cmd/peerup/cmd_join.go`

---

## Batch F: Daemon Mode

### ADR-F01: Unix Socket (Not TCP)

**Context**: The daemon needs a control API for CLI subcommands (`peerup daemon status`, `peerup daemon ping`, etc.). Need an IPC mechanism.

**Alternatives considered**:
- **TCP on localhost** — Universal, works on all platforms. Rejected because (a) any local process can connect (no filesystem permissions), (b) port conflicts with other services, (c) potentially exposed if firewall misconfigured.
- **Named pipes** — Windows-friendly. Rejected because they don't support HTTP natively and complicate the implementation.
- **gRPC** — Type-safe, bi-directional streaming. Rejected because it adds protobuf dependency, code generation, and binary size. HTTP+JSON is simpler and sufficient.

**Decision**: Unix domain socket at `~/.config/peerup/peerup.sock` with HTTP/1.1 over it. Socket created with `umask(0077)` to ensure `0700` permissions atomically (no TOCTOU race between `Listen()` and `Chmod()`). Stale socket detection: try connecting first, only remove if connection fails.

**Consequences**: Unix-only (no Windows support for now). Accepted because peer-up's target users are Linux/macOS. Socket permissions enforce that only the owning user can connect. The HTTP layer means standard tools (`curl --unix-socket`) work for debugging.

**Reference**: `internal/daemon/server.go:86-138`

---

### ADR-F02: Cookie Auth (Not mTLS)

**Context**: Even with socket permissions, the API needs authentication to prevent attacks via symlink races or debugger attachment.

**Alternatives considered**:
- **mTLS** — Strong mutual authentication. Rejected because it requires certificate management, key generation, and trust store configuration — too complex for a local IPC mechanism.
- **Token in socket filename** — Embed the token in the path. Rejected because path-based auth is fragile and leaks the token in `ps` output and logs.
- **No auth** (rely on socket permissions) — Rejected because defense-in-depth requires authentication even when filesystem permissions are correct.

**Decision**: 32-byte random hex cookie written to `~/.config/peerup/.daemon-cookie` with `0600` permissions. CLI reads the cookie and sends it as `Authorization: Bearer <token>`. Cookie is rotated every daemon restart. Written AFTER socket is secured (ordering prevents clients from reading cookie before socket is ready).

**Consequences**: Simple, fast, no crypto libraries needed. The cookie file is the single secret — protect it like an SSH private key. If compromised, restart the daemon to rotate.

**Reference**: `internal/daemon/server.go:88-116`, `internal/daemon/client.go`

---

### ADR-F03: RuntimeInfo Interface

**Context**: The daemon server needs access to the P2P network, config paths, version info, and connection methods. But the daemon package shouldn't import `cmd/peerup`.

**Alternatives considered**:
- **Pass individual fields** — `NewServer(network, configPath, authKeys, version, ...)`. Rejected because the parameter list would grow with every new feature.
- **Share a struct directly** — Import the runtime struct from cmd. Rejected because it creates a circular dependency between `internal/daemon` and `cmd/peerup`.

**Decision**: `daemon.RuntimeInfo` interface with methods: `Network()`, `ConfigFile()`, `AuthKeysPath()`, `GaterForHotReload()`, `Version()`, `StartTime()`, `PingProtocolID()`, `ConnectToPeer()`. The `serveRuntime` struct in `cmd/peerup/cmd_daemon.go` implements it.

**Consequences**: Clean dependency direction (daemon depends on interface, not concrete type). Easy to mock in tests (`mockRuntime`). Adding new runtime capabilities means adding methods to the interface — intentionally explicit.

**Reference**: `internal/daemon/server.go:23-32`, `cmd/peerup/cmd_daemon.go:23-28`

---

### ADR-F04: Hot-Reload `authorized_keys`

**Context**: Adding or removing peers via `peerup daemon auth add/remove` should take effect immediately without restarting the daemon.

**Alternatives considered**:
- **File watcher (fsnotify)** — Watch the file for changes. Rejected because it adds a dependency and doesn't help with API-triggered changes (where we already know when to reload).
- **Restart required** — Simpler but terrible UX. Rejected.

**Decision**: `GaterReloader` interface with `ReloadFromFile()` method. When the daemon API adds/removes a peer from the `authorized_keys` file, it immediately calls `ReloadFromFile()`, which re-reads the file and calls `gater.UpdateAuthorizedPeers()` with the new map. The gater uses `sync.RWMutex` for concurrent safety.

**Consequences**: Changes are atomic (read file, swap map under lock). No file watching needed. The gater's `authorizedPeers` map is replaced entirely — no incremental updates. This is fine because the authorized_keys file is small (typically <100 entries).

**Reference**: `cmd/peerup/cmd_daemon.go:37-51`, `internal/auth/gater.go:74-79`

---

## Batch G: Test Coverage

### ADR-G01: Coverage-Instrumented Docker Tests

**Context**: Docker integration tests verify real binaries in containers but didn't contribute to coverage metrics. Needed to merge Docker test coverage with unit test coverage.

**Alternatives considered**:
- **Separate coverage reports** — Track Docker and unit coverage independently. Rejected because it gives an incomplete picture.
- **Coverage at the Go test level only** — Skip Docker coverage. Rejected because the Docker tests exercise critical paths (relay, invite/join) that unit tests can't.

**Decision**: Build binaries with `-cover -covermode=atomic`, set `GOCOVERDIR` in containers, extract coverage data after tests, merge with unit test profiles using `go tool covdata`. Combined coverage reported in CI.

**Consequences**: Docker tests are slower (coverage instrumentation adds overhead), but we get accurate end-to-end coverage numbers. The merged profile reveals which code paths are only exercised by integration tests.

**Reference**: `test/docker/integration_test.go`, `.github/workflows/ci.yml`

---

### ADR-G02: Relay-Server Binary in Integration Tests

**Context**: Docker integration tests need to run the relay server. The relay server is built from `cmd/relay-server/`.

**Alternatives considered**:
- **Use a public relay** — Test against a real relay. Rejected because tests must be self-contained and reproducible.
- **Mock relay in-process** — Use libp2p relay transport directly. Rejected because we want to test the actual relay-server binary.

**Decision**: Build `relay-server` binary alongside `peerup` binary for Docker tests. The compose file starts a relay container, and node containers use it for circuit relay.

**Consequences**: Tests verify the actual deployment path (binary → container → relay → circuit). Takes longer to build but catches real integration issues.

**Reference**: `test/docker/compose.yaml`, `test/docker/Dockerfile`

---

### ADR-G03: Injectable `osExit` for Testability

**Context**: Several commands call `os.Exit()` on error. This kills the test process, making those code paths untestable.

**Alternatives considered**:
- **Panic + recover** — Use `panic` instead of `os.Exit` and recover in tests. Rejected because panics have different semantics (stack traces, deferred functions).
- **Return error codes** — Refactor all commands to return errors. Considered for future, but too large a refactor for a testing improvement.

**Decision**: Package-level `var osExit = os.Exit` that tests override with a function that records the exit code instead of terminating. Applied to `cmd/peerup/` (the main binary) and `cmd/relay-server/`.

**Consequences**: Minimal code change (one variable + one test helper), enables testing of all exit paths. The variable is package-level, so tests must be careful about parallel execution (each test restores the original `osExit`).

**Reference**: `cmd/peerup/run.go`, `cmd/peerup/run_test.go`

---

### ADR-G04: Post-Phase Audit Protocol

**Context**: After completing each batch, need a systematic review to catch issues before moving to the next phase. Ad-hoc reviews miss things.

**Alternatives considered**:
- **Ad-hoc review** — Review when something feels wrong. Rejected because it's inconsistent and misses systematic issues.
- **External audit** — Hire security auditors. Planned for later stages, but too expensive for every batch.

**Decision**: Mandatory 6-category audit after every phase: source code audit, bad code scan, bug hunting, QA testing, security audit, and relay hardening review. Each category has specific checklists. Findings are compiled into a report, and fixes require explicit approval before implementation.

The Batch G audit found 10 issues (CVE in pion/dtls, TOCTOU on Unix socket, cookie ordering, body size limits, CI SHA pinning, etc.) — all fixed in commit `83d02d3`.

**Consequences**: Adds time between batches, but catches real issues. The audit that found the pion/dtls nonce-reuse CVE justified the entire protocol — that vulnerability could have compromised encrypted relay traffic.

**Reference**: Audit findings tracked in project memory, fixes in commit `83d02d3`


---

